[
  {
    "arxiv": "0805.2088",
    "counts": {
      "ConvE": 1,
      "LINE": 1,
      "NAM": 1,
      "SE": 1,
      "SME": 1
    },
    "published": "2008-05-14T15:31:20Z",
    "summary": "We provide a bestiary of public codes and other algorithmic tools that can be used for analysing supersymmetric phenomenology. We also describe the organisation of the different tools and communication between them. Tools exist that calculate supersymmetric spectra and decay widths, simulate Monte Carlo events as well as those that make predictions of dark matter relic density or that predict precision electroweak or b-observables. Some global fitting tools for use in SUSY phenomenology are also presented. In each case, a description and a link to the relevant web-site is provided. It is hoped that this review could serve as an \"entry-gate\" and map for prospective users.",
    "title": "SUSY Predictions and SUSY Tools at the LHC"
  },
  {
    "arxiv": "0905.3558",
    "counts": {
      "ComplEx": 1,
      "HypER": 1,
      "NAM": 1,
      "ProjE": 1,
      "SE": 1
    },
    "published": "2009-05-21T20:18:56Z",
    "summary": "Predictions of missing links of incomplete networks like protein-protein interaction networks or very likely but not yet existent links in evolutionary networks like friendship networks in web society can be considered as a guideline for further experiments or valuable information for web users. In this paper, we introduce a local path index to estimate the likelihood of the existence of a link between two nodes. We propose a network model with controllable density and noise strength in generating links, as well as collect data of six real networks. Extensive numerical simulations on both modeled networks and real networks demonstrated the high effectiveness and efficiency of the local path index compared with two well-known and widely used indices, the common neighbors and the Katz index. Indeed, the local path index provides competitively accurate predictions as the Katz index while requires much less CPU time and memory space, which is therefore a strong candidate for potential practical applications in data mining of huge-size networks.",
    "title": "Effective and Efficient Similarity Index for Link Prediction of Complex Networks"
  },
  {
    "arxiv": "0908.3916",
    "counts": {
      "ConvE": 1,
      "GeomE": 1,
      "SE": 1,
      "SimplE": 1
    },
    "published": "2009-08-26T23:28:23Z",
    "summary": "Many problems in computational geometry are not stated in graph-theoretic terms, but can be solved efficiently by constructing an auxiliary graph and performing a graph-theoretic algorithm on it. Often, the efficiency of the algorithm depends on the special properties of the graph constructed in this way. We survey the art gallery problem, partition into rectangles, minimum-diameter clustering, rectilinear cartogram construction, mesh stripification, angle optimization in tilings, and metric embedding from this perspective.",
    "title": "Graph-Theoretic Solutions to Computational Geometry Problems"
  },
  {
    "arxiv": "1001.0384",
    "counts": {
      "ConvE": 1,
      "FedE": 1,
      "LINE": 1,
      "NAM": 1,
      "SE": 1
    },
    "published": "2010-01-03T16:01:23Z",
    "summary": "The present paper is a review of the current state of Graph-Link Theory (graph-links are also closely related to homotopy classes of looped interlacement graphs), dealing with a generalisation of knots obtained by translating the Reidemeister moves for links into the language of intersection graphs of chord diagrams. In this paper we show how some methods of classical and virtual knot theory can be translated into the language of abstract graphs, and some theorems can be reproved and generalised to this graphical setting. We construct various invariants, prove certain minimality theorems and construct functorial mappings for graph-knots and graph-links. In this paper, we first show non-equivalence of some graph-links to virtual links.",
    "title": "Graph-Links"
  },
  {
    "arxiv": "1005.4006",
    "counts": {
      "ComplEx": 3,
      "HypER": 1,
      "LINE": 1,
      "SE": 11,
      "TransA": 1,
      "TuckER": 2
    },
    "published": "2010-05-21T17:07:35Z",
    "summary": "The data in many disciplines such as social networks, web analysis, etc. is link-based, and the link structure can be exploited for many different data mining tasks. In this paper, we consider the problem of temporal link prediction: Given link data for times 1 through T, can we predict the links at time T+1? If our data has underlying periodic structure, can we predict out even further in time, i.e., links at time T+2, T+3, etc.? In this paper, we consider bipartite graphs that evolve over time and consider matrix- and tensor-based methods for predicting future links. We present a weight-based method for collapsing multi-year data into a single matrix. We show how the well-known Katz method for link prediction can be extended to bipartite graphs and, moreover, approximated in a scalable way using a truncated singular value decomposition. Using a CANDECOMP/PARAFAC tensor decomposition of the data, we illustrate the usefulness of exploiting the natural three-dimensional structure of temporal link data. Through several numerical experiments, we demonstrate that both matrix- and tensor-based techniques are effective for temporal link prediction despite the inherent difficulty of the problem. Additionally, we show that tensor-based techniques are particularly effective for temporal data with varying periodic patterns.",
    "title": "Temporal Link Prediction using Matrix and Tensor Factorizations"
  },
  {
    "arxiv": "1007.4219",
    "counts": {
      "ConvE": 2,
      "GeomE": 2,
      "SE": 2
    },
    "published": "2010-07-23T21:17:29Z",
    "summary": "There is a well-known way to describe a link diagram as a (signed) plane graph, called its Tait graph. This concept was recently extended, providing a way to associate a set of embedded graphs (or ribbon graphs) to a link diagram. While every plane graph arises as a Tait graph of a unique link diagram, not every embedded graph represents a link diagram. Furthermore, although a Tait graph describes a unique link diagram, the same embedded graph can represent many different link diagrams. One is then led to ask which embedded graphs represent link diagrams, and how link diagrams presented by the same embedded graphs are related to one another. Here we answer these questions by characterizing the class of embedded graphs that represent link diagrams, and then using this characterization to find a move that relates all of the link diagrams that are presented by the same set of embedded graphs.",
    "title": "Partial duals of plane graphs, separability and the graphs of knots"
  },
  {
    "arxiv": "1009.0566",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "FedE": 1,
      "GeomE": 1,
      "RotH": 1,
      "SE": 1,
      "SimplE": 1
    },
    "published": "2010-09-03T01:36:57Z",
    "summary": "We study countable embedding-universal and homomorphism-universal structures and unify results related to both of these notions. We show that many universal and ultrahomogeneous structures allow a concise description (called here a finite presentation). Extending classical work of Rado (for the random graph), we find a finite presentation for each of the following classes: homogeneous undirected graphs, homogeneous tournaments and homogeneous partially ordered sets. We also give a finite presentation of the rational Urysohn metric space and some homogeneous directed graphs. We survey well known structures that are finitely presented. We focus on structures endowed with natural partial orders and prove their universality. These partial orders include partial orders on sets of words, partial orders formed by geometric objects, grammars, polynomials and homomorphism orders for various combinatorial objects. We give a new combinatorial proof of the existence of embedding-universal objects for homomorphism-defined classes of structures. This relates countable embedding-universal structures to homomorphism dualities (finite homomorphism-universal structures) and Urysohn metric spaces. Our explicit construction also allows us to show several properties of these structures.",
    "title": "Combinatorial Properties of Finite Models"
  },
  {
    "arxiv": "1104.2522",
    "counts": {
      "LINE": 1,
      "SE": 1,
      "SME": 1
    },
    "published": "2011-04-13T15:03:36Z",
    "summary": "The Schwinger-Dyson, Bethe-Salpeter system of equations are the link between coloured quarks and gluons, and colourless hadrons and their properties. This talk reviews some aspects of these studies from the infrared behaviour of ghosts to the prediction of electromagnetic form-factors.",
    "title": "Strong Coupling Continuum QCD"
  },
  {
    "arxiv": "1106.6329",
    "counts": {
      "FedE": 1,
      "SE": 1,
      "SimplE": 1
    },
    "published": "2011-06-30T18:32:43Z",
    "summary": "The one-dimensional Bose gas is an unusual superfluid. In contrast to higher spatial dimensions, the existence of non-classical rotational inertia is not directly linked to the dissipationless motion of infinitesimal impurities. Recently, experimental tests with ultracold atoms have begun and quantitative predictions for the drag force experienced by moving obstacles have become available. This topical review discusses the drag force obtained from linear response theory in relation to Landau's criterion of superfluidity. Based upon improved analytical and numerical understanding of the dynamical structure factor, results for different obstacle potentials are obtained, including single impurities, optical lattices and random potentials generated from speckle patterns. The dynamical breakdown of superfluidity in random potentials is discussed in relation to Anderson localization and the predicted superfluid-insulator transition in these systems.",
    "title": "Theory of superfluidity and drag force in the one-dimensional Bose gas"
  },
  {
    "arxiv": "1112.0106",
    "counts": {
      "LINE": 1,
      "NAM": 1,
      "ProjE": 1,
      "RotH": 1,
      "SE": 1
    },
    "published": "2011-12-01T08:32:22Z",
    "summary": "A molecular line survey has been carried out toward the carbon-rich asymptotic giant branch star CW Leo employing the HIFI instrument on board of the Herschel satellite. Numerous features from 480 GHz to beyond 1100 GHz could be assigned unambiguously to the fairly floppy SiC$_2$ molecule. However, predictions from laboratory data exhibited large deviations from the observed frequencies even after some lower frequency data from this survey were incorporated into a fit. Therefore, we present a combined fit of all available laboratory data together with data from radio-astronomical observations.",
    "title": "Spectroscopic parameters for silacyclopropynylidene, SiC$_2$, from extensive astronomical observations toward CW Leo (IRC +10216) with the Herschel satellite"
  },
  {
    "arxiv": "1204.0033",
    "counts": {
      "HypER": 1,
      "LINE": 1,
      "SE": 13,
      "SimplE": 1,
      "TransF": 10
    },
    "published": "2012-03-30T21:38:52Z",
    "summary": "Relational data representations have become an increasingly important topic due to the recent proliferation of network datasets (e.g., social, biological, information networks) and a corresponding increase in the application of statistical relational learning (SRL) algorithms to these domains. In this article, we examine a range of representation issues for graph-based relational data. Since the choice of relational data representation for the nodes, links, and features can dramatically affect the capabilities of SRL algorithms, we survey approaches and opportunities for relational representation transformation designed to improve the performance of these algorithms. This leads us to introduce an intuitive taxonomy for data representation transformations in relational domains that incorporates link transformation and node transformation as symmetric representation tasks. In particular, the transformation tasks for both nodes and links include (i) predicting their existence, (ii) predicting their label or type, (iii) estimating their weight or importance, and (iv) systematically constructing their relevant features. We motivate our taxonomy through detailed examples and use it to survey and compare competing approaches for each of these tasks. We also discuss general conditions for transforming links, nodes, and features. Finally, we highlight challenges that remain to be addressed.",
    "title": "Transforming Graph Representations for Statistical Relational Learning"
  },
  {
    "arxiv": "1204.5853",
    "counts": {
      "5*": 1,
      "ComplEx": 1,
      "ConvE": 1,
      "GeomE": 1,
      "SE": 1
    },
    "published": "2012-04-26T07:50:05Z",
    "summary": "Simultaneous embedding is concerned with simultaneously representing a series of graphs sharing some or all vertices. This forms the basis for the visualization of dynamic graphs and thus is an important field of research. Recently there has been a great deal of work investigating simultaneous embedding problems both from a theoretical and a practical point of view. We survey recent work on this topic.",
    "title": "Simultaneous Embedding of Planar Graphs"
  },
  {
    "arxiv": "1205.3322",
    "counts": {
      "NAM": 1,
      "ProjE": 1,
      "RatE": 1,
      "SE": 1
    },
    "published": "2012-05-15T11:04:44Z",
    "summary": "Several works have outlined the fact that the mobility in intermittently connected wireless networks is strongly governed by human behaviors as they are basically human-centered. It has been shown that the users' moves can be correlated and that the social ties shared by the users highly impact their mobility patterns and hence the network structure. Tracking these correlations and measuring the strength of social ties have led us to propose an efficient distributed tensor-based link prediction technique. In fact, we are convinced that the feedback provided by such a prediction mechanism can enhance communication protocols such as opportunistic routing protocols. In this paper, we aim to bring out that measuring the stabilities of the link and the proximity at two hops can improve the efficiency of the proposed link prediction technique. To quantify these two parameters, we propose an entropy estimator in order to measure the two stability aspects over successive time periods. Then, we join these entropy estimations to the tensor-based link prediction framework by designing new prediction metrics. To assess the contribution of these entropy estimations in the enhancement of tensor-based link prediction efficiency, we perform prediction on two real traces. Our simulation results show that by exploiting the information corresponding to the link stability and/or to the proximity stability, the performance of the tensor-based link prediction technique is improved. Moreover, the results attest that our proposal's ability to outperform other well-known prediction metrics.",
    "title": "Improving Link Prediction in Intermittently Connected Wireless Networks by Considering Link and Proximity Stabilities"
  },
  {
    "arxiv": "1209.0334",
    "counts": {
      "ComplEx": 1,
      "GeomE": 1,
      "HypER": 1,
      "NAM": 1,
      "SE": 1,
      "SimplE": 1
    },
    "published": "2012-09-03T12:59:44Z",
    "summary": "Ribbon graphs embedded on a Riemann surface provide a useful way to describe the double line Feynman diagrams of large N computations and a variety of other QFT correlator and scattering amplitude calculations, e.g in MHV rules for scattering amplitudes, as well as in ordinary QED. Their counting is a special case of the counting of bi-partite embedded graphs. We review and extend relevant mathematical literature and present results on the counting of some infinite classes of bi-partite graphs. Permutation groups and representations as well as double cosets and quotients of graphs are useful mathematical tools. The counting results are refined according to data of physical relevance, such as the structure of the vertices, faces and genus of the embedded graph. These counting problems can be expressed in terms of observables in three-dimensional topological field theory with S_d gauge group which gives them a topological membrane interpretation.",
    "title": "On the refined counting of graphs on surfaces"
  },
  {
    "arxiv": "1211.3169",
    "counts": {
      "ComplEx": 1,
      "FedE": 1,
      "LINE": 1,
      "RatE": 1,
      "SE": 1,
      "TransF": 1,
      "TransM": 1
    },
    "published": "2012-11-14T00:13:27Z",
    "summary": "This report reviews the conceptual and theoretical links between Granger causality and directed information theory. We begin with a short historical tour of Granger causality, concentrating on its closeness to information theory. The definitions of Granger causality based on prediction are recalled, and the importance of the observation set is discussed. We present the definitions based on conditional independence. The notion of instantaneous coupling is included in the definitions. The concept of Granger causality graphs is discussed. We present directed information theory from the perspective of studies of causal influences between stochastic processes. Causal conditioning appears to be the cornerstone for the relation between information theory and Granger causality. In the bivariate case, the fundamental measure is the directed information, which decomposes as the sum of the transfer entropies and a term quantifying instantaneous coupling. We show the decomposition of the mutual information into the sums of the transfer entropies and the instantaneous coupling measure, a relation known for the linear Gaussian case. We study the multivariate case, showing that the useful decomposition is blurred by instantaneous coupling. The links are further developed by studying how measures based on directed information theory naturally emerge from Granger causality inference frameworks as hypothesis testing.",
    "title": "The relation between Granger causality and directed information theory: a review"
  },
  {
    "arxiv": "1302.5105",
    "counts": {
      "GeomE": 1,
      "SE": 1,
      "SME": 1,
      "TransA": 1
    },
    "published": "2013-02-19T21:52:42Z",
    "summary": "Combining geometric mechanics theory, laboratory robotic experiment and numerical simulation, we study the locomotion in granular media (GM) of the simplest non-inertial swimmer, the Purcell three-link swimmer. Using granular resistive force laws as inputs, the theory relates translation and rotation of the body to shape changes (movements of the links). This allows analysis, visualization, and prediction of effective movements that are verified by experiment. The geometric approach also facilitates comparison between swimming in GM and in viscous fluids.",
    "title": "Geometric visualization of self-propulsion in a complex medium"
  },
  {
    "arxiv": "1305.0989",
    "counts": {
      "CoKE": 1,
      "FedE": 1,
      "LINE": 1,
      "SE": 1,
      "TransA": 1
    },
    "published": "2013-05-05T07:20:50Z",
    "summary": "The failure of materials and interfaces is mediated by cracks, nearly singular dissipative structures that propagate at velocities approaching the speed of sound. Crack initiation and subsequent propagation -- the dynamic process of fracture -- couples a wide range of time and length scales. Crack dynamics challenge our understanding of the fundamental physics processes that take place in the extreme conditions within the nearly singular region where material failure occurs. Here, we first briefly review the classic approach to dynamic fracture, \"Linear Elastic Fracture Mechanics\" (LEFM), and discuss its successes and limitations. We show how, on the one hand, recent experiments performed on straight cracks propagating in soft brittle materials have quantitatively confirmed the predictions of this theory to an unprecedented degree. On the other hand, these experiments show how LEFM breaks down as the singular region at the tip of a crack is approached. This breakdown naturally leads to a new theoretical framework coined \"Weakly Nonlinear Fracture Mechanics\", where weak elastic nonlinearities are incorporated. The stronger singularity predicted by this theory gives rise to a new and intrinsic length scale, $\\ell_{nl}$. These predictions are verified in detail through direct measurements. We then theoretically and experimentally review how the emergence of $\\ell_{nl}$ is linked to a new equation for crack motion, which predicts the existence of a high-speed oscillatory crack instability whose wave-length is determined by $\\ell_{nl}$. We conclude by delineating outstanding challenges in the field.",
    "title": "The Dynamics of Rapid Fracture: Instabilities, Nonlinearities and Length Scales"
  },
  {
    "arxiv": "1308.2271",
    "counts": {
      "CoKE": 1,
      "GeomE": 1,
      "SE": 1,
      "TransA": 1
    },
    "published": "2013-08-10T03:36:32Z",
    "summary": "A discussion given to the question of extending Khovanov homology from links to embedded graphs, by using the Kauffman topological invariant of embedded graphs by associating family of links and knots to a such graph by using some local replacements at each vertex in the graph. This new concept of Khovanov-Kauffman homology of an embedded graph constructed to be the sum of the Khovanov homologies of all the links and knots associated to this graph.",
    "title": "Khovanov-Kauffman Homology for embedded Graphs"
  },
  {
    "arxiv": "1310.3492",
    "counts": {
      "ConvE": 1,
      "NAM": 1,
      "SE": 1,
      "TransF": 1
    },
    "published": "2013-10-13T16:35:00Z",
    "summary": "Online social networks have gained great success in recent years and many of them involve multiple kinds of nodes and complex relationships. Among these relationships, social links among users are of great importance. Many existing link prediction methods focus on predicting social links that will appear in the future among all users based upon a snapshot of the social network. In real-world social networks, many new users are joining in the service every day. Predicting links for new users are more important. Different from conventional link prediction problems, link prediction for new users are more challenging due to the following reasons: (1) differences in information distributions between new users and the existing active users (i.e., old users); (2) lack of information from the new users in the network. We propose a link prediction method called SCAN-PS (Supervised Cross Aligned Networks link prediction with Personalized Sampling), to solve the link prediction problem for new users with information transferred from both the existing active users in the target network and other source networks through aligned accounts. We proposed a within-target-network personalized sampling method to process the existing active users' information in order to accommodate the differences in information distributions before the intra-network knowledge transfer. SCAN-PS can also exploit information in other source networks, where the user accounts are aligned with the target network. In this way, SCAN-PS could solve the cold start problem when information of these new users is total absent in the target network.",
    "title": "Predicting Social Links for New Users across Aligned Heterogeneous Social Networks"
  },
  {
    "arxiv": "1404.3752",
    "counts": {
      "GeomE": 1,
      "SE": 1,
      "TransF": 1
    },
    "published": "2014-04-14T20:40:45Z",
    "summary": "We review recent progress in Bipartite Field Theories. We cover topics such as their gauge dynamics, emergence of toric Calabi-Yau manifolds as master and moduli spaces, string theory embedding, relationships to on-shell diagrams, connections to cluster algebras and the Grassmannian, and applications to graph equivalence and stratification of the Grassmannian.",
    "title": "Bipartite Field Theories, Cluster Algebras and the Grassmannian"
  },
  {
    "arxiv": "1409.3814",
    "counts": {
      "5*": 1,
      "ConvE": 1,
      "NAM": 1,
      "SE": 2
    },
    "published": "2014-09-12T18:41:29Z",
    "summary": "We review a braid theoretic self-linking number formula and study its applications.",
    "title": "On the self-linking number of transverse links"
  },
  {
    "arxiv": "1410.5077",
    "counts": {
      "ConvE": 1,
      "SE": 1,
      "TransF": 1
    },
    "published": "2014-10-19T14:10:50Z",
    "summary": "As the amount of linked data published on the web grows, attempts are being made to describe and measure it. However even basic statistics about a graph, such as its size, are difficult to express in a uniform and predictable way. In order to be able to sensibly interpret a statistic it is necessary to know how it was calculate. In this paper we survey the nature of the problem and outline a strategy for addressing it.",
    "title": "On the Provenance of Linked Data Statistics"
  },
  {
    "arxiv": "1411.2968",
    "counts": {
      "NAM": 1,
      "ProjE": 1,
      "SE": 1
    },
    "published": "2014-11-11T21:00:00Z",
    "summary": "Current wide-area radio surveys are dominated by active galactic nuclei, yet many of these sources have no identified optical counterparts. Here we investigate whether one can constrain the nature and properties of these sources, using Fanaroff-Riley type II (FRII) radio galaxies as probes. These sources are easy to identify since the angular separation of their lobes remains almost constant at some tens of arcseconds for z>1. Using a simple algorithm applied to the FIRST survey, we obtain the largest FRII sample to date, containing over ten thousand double-lobed sources. A subset of 459 sources is matched to SDSS quasars. This sample yields a statistically meaningful description of the fraction of quasars with lobes as a function of redshift and luminosity. This relation is combined with the bolometric quasar luminosity function, as derived from surveys at IR to hard X-ray frequencies, and a disc-lobe correlation to obtain a robust prediction for the density of FRIIs on the radio sky. We find that the observed density can be explained by the population of known quasars, implying that the majority of powerful jets originate from a radiatively efficient accretion flow with a linear jet-disc coupling. Finally, we show that high-redshift jets are more often quenched within 100 kpc, suggesting a higher efficiency of jet-induced feedback into their host galaxies.",
    "title": "Nature and evolution of powerful radio galaxies and their link with the quasar luminosity function"
  },
  {
    "arxiv": "1411.5118",
    "counts": {
      "ComplEx": 1,
      "HolE": 1,
      "HypER": 1,
      "LINE": 1,
      "NAM": 1,
      "SE": 1,
      "SimplE": 1,
      "TransA": 1,
      "TransF": 1
    },
    "published": "2014-11-19T05:51:22Z",
    "summary": "In social networks, link prediction predicts missing links in current networks and new or dissolution links in future networks, is important for mining and analyzing the evolution of social networks. In the past decade, many works have been done about the link prediction in social networks. The goal of this paper is to comprehensively review, analyze and discuss the state-of-the-art of the link prediction in social networks. A systematical category for link prediction techniques and problems is presented. Then link prediction techniques and problems are analyzed and discussed. Typical applications of link prediction are also addressed. Achievements and roadmaps of some active research groups are introduced. Finally, some future challenges of the link prediction in social networks are discussed.",
    "title": "Link Prediction in Social Networks: the State-of-the-Art"
  },
  {
    "arxiv": "1412.2723",
    "counts": {
      "LINE": 1,
      "SE": 1,
      "TransA": 1
    },
    "published": "2014-12-08T20:27:42Z",
    "summary": "Signed network analysis has attracted increasing attention in recent years. This is in part because research on signed network analysis suggests that negative links have added value in the analytical process. A major impediment in their effective use is that most social media sites do not enable users to specify them explicitly. In other words, a gap exists between the importance of negative links and their availability in real data sets. Therefore, it is natural to explore whether one can predict negative links automatically from the commonly available social network data. In this paper, we investigate the novel problem of negative link prediction with only positive links and content-centric interactions in social media. We make a number of important observations about negative links, and propose a principled framework NeLP, which can exploit positive links and content-centric interactions to predict negative links. Our experimental results on real-world social networks demonstrate that the proposed NeLP framework can accurately predict negative links with positive links and content-centric interactions. Our detailed experiments also illustrate the relative importance of various factors to the effectiveness of the proposed framework.",
    "title": "Negative Link Prediction in Social Media"
  },
  {
    "arxiv": "1501.01564",
    "counts": {
      "LINE": 1,
      "NAM": 1,
      "RatE": 1,
      "SE": 1,
      "SimplE": 1
    },
    "published": "2015-01-07T17:16:04Z",
    "summary": "Theoretical galaxy formation models are an established and powerful tool for interpreting the astrophysical significance of observational data, particularly galaxy surveys. Such models have been utilised with great success by optical surveys such as 2dFGRS and SDSS, but their application to radio surveys of cold gas in galaxies has been limited. In this chapter we describe recent developments in the modelling of the cold gas properties in the models, and how these developments are essential if they are to be applied to cold gas surveys of the kind that will be carried out with the SKA. By linking explicitly a galaxy's star formation rate to the abundance of molecular hydrogen in the galaxy rather than cold gas abundance, as was assumed previously, the latest models reproduce naturally many of the global atomic and molecular hydrogen properties of observed galaxies. We review some of the key results of the latest models and highlight areas where further developments are necessary. We discuss also how model predictions can be most accurately compared with observational data, what challenges we expect when creating synthetic galaxy surveys in the SKA era, and how the SKA can be used to test models of dark matter.",
    "title": "Galaxy Formation & Dark Matter Modelling in the Era of the Square Kilometre Array"
  },
  {
    "arxiv": "1505.04094",
    "counts": {
      "ComplEx": 1,
      "HypER": 1,
      "ProjE": 1,
      "RatE": 1,
      "RotH": 1,
      "SE": 1
    },
    "published": "2015-05-15T15:28:58Z",
    "summary": "Link prediction is a popular research area with important applications in a variety of disciplines, including biology, social science, security, and medicine. The fundamental requirement of link prediction is the accurate and effective prediction of new links in networks. While there are many different methods proposed for link prediction, we argue that the practical performance potential of these methods is often unknown because of challenges in the evaluation of link prediction, which impact the reliability and reproducibility of results. We describe these challenges, provide theoretical proofs and empirical examples demonstrating how current methods lead to questionable conclusions, show how the fallacy of these conclusions is illuminated by methods we propose, and develop recommendations for consistent, standard, and applicable evaluation metrics. We also recommend the use of precision-recall threshold curves and associated areas in lieu of receiver operating characteristic curves due to complications that arise from extreme imbalance in the link prediction classification problem.",
    "title": "Evaluating Link Prediction Methods"
  },
  {
    "arxiv": "1506.00999",
    "counts": {
      "LFM": 1,
      "LINE": 1,
      "NTN": 1,
      "RESCAL": 1,
      "SE": 1,
      "SME": 1,
      "TATEC": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2015-06-02T19:34:19Z",
    "summary": "This paper tackles the problem of endogenous link prediction for Knowledge Base completion. Knowledge Bases can be represented as directed graphs whose nodes correspond to entities and edges to relationships. Previous attempts either consist of powerful systems with high capacity to model complex connectivity patterns, which unfortunately usually end up overfitting on rare relationships, or in approaches that trade capacity for simplicity in order to fairly model all relationships, frequent or not. In this paper, we propose Tatec a happy medium obtained by complementing a high-capacity model with a simpler one, both pre-trained separately and then combined. We present several variants of this model with different kinds of regularization and combination strategies and show that this approach outperforms existing methods on different types of relationships by achieving state-of-the-art results on four benchmarks of the literature.",
    "title": "Combining Two And Three-Way Embeddings Models for Link Prediction in Knowledge Bases"
  },
  {
    "arxiv": "1510.04935",
    "counts": {
      "ComplEx": 1,
      "ER-MLP": 1,
      "HolE": 1,
      "LINE": 1,
      "ProjE": 1,
      "RESCAL": 1,
      "SE": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2015-10-16T16:29:07Z",
    "summary": "Learning embeddings of entities and relations is an efficient and versatile method to perform machine learning on relational data such as knowledge graphs. In this work, we propose holographic embeddings (HolE) to learn compositional vector space representations of entire knowledge graphs. The proposed method is related to holographic models of associative memory in that it employs circular correlation to create compositional representations. By using correlation as the compositional operator HolE can capture rich interactions but simultaneously remains efficient to compute, easy to train, and scalable to very large datasets. In extensive experiments we show that holographic embeddings are able to outperform state-of-the-art methods for link prediction in knowledge graphs and relational learning benchmark datasets.",
    "title": "Holographic Embeddings of Knowledge Graphs"
  },
  {
    "arxiv": "1510.07819",
    "counts": {
      "ComplEx": 1,
      "SE": 1,
      "TransF": 1
    },
    "published": "2015-10-27T09:24:39Z",
    "summary": "Predicting missing links in incomplete complex networks efficiently and accurately is still a challenging problem. The recently proposed CAR (Cannistrai-Alanis-Ravai) index shows the power of local link/triangle information in improving link-prediction accuracy. With the information of level-2 links, which are links between common-neighbors, most classical similarity indices can be improved. Nevertheless, calculating the number of level-2 links makes CAR index not efficient enough. Inspired by the idea of employing local link/triangle information, we propose a new similarity index with more local structure information. In our method, local link/triangle structure information can be conveyed by clustering coefficient of common neighbors directly. The reason why clustering coefficient has good effectiveness in estimating the contribution of a common-neighbor is because that it employs links existing between neighbors of the common-neighbor and these links have the same structural position with the candidate link to this common-neighbor. Ten real-world networks drawn from five various fields are used to test the performance of our method against to classical similarity indices and recently proposed CAR index. Two estimators: precision and AUP, are used to evaluate the accuracy of link prediction algorithms. Generally speaking, our new index only performs competitively with CAR, but it is a good complement to CAR for networks with not very high LCP-corr, which is a measure to estimate the correlation between number of common-neighbors and number of links between common-neighbors. Besides, the proposed index is also more efficient than CAR index.",
    "title": "Link Prediction with Node Clustering Coefficient"
  },
  {
    "arxiv": "1512.01370",
    "counts": {
      "LFM": 1,
      "NAM": 1,
      "NTN": 1,
      "RESCAL": 1,
      "SE": 1,
      "SME": 1,
      "Structured Embedding": 1,
      "TransA": 1,
      "TransE": 1,
      "TransH": 1
    },
    "published": "2015-12-04T11:09:55Z",
    "summary": "Knowledge graph embedding aims to represent entities and relations in a large-scale knowledge graph as elements in a continuous vector space. Existing methods, e.g., TransE and TransH, learn embedding representation by defining a global margin-based loss function over the data. However, the optimal loss function is determined during experiments whose parameters are examined among a closed set of candidates. Moreover, embeddings over two knowledge graphs with different entities and relations share the same set of candidate loss functions, ignoring the locality of both graphs. This leads to the limited performance of embedding related applications. In this paper, we propose a locally adaptive translation method for knowledge graph embedding, called TransA, to find the optimal loss function by adaptively determining its margin over different knowledge graphs. Experiments on two benchmark data sets demonstrate the superiority of the proposed method, as compared to the-state-of-the-art ones.",
    "title": "Locally Adaptive Translation for Knowledge Graph Embedding"
  },
  {
    "arxiv": "1512.03966",
    "counts": {
      "ConvE": 1,
      "GeomE": 1,
      "SE": 1,
      "TransF": 1
    },
    "published": "2015-12-12T22:20:28Z",
    "summary": "We generalise gauge theory on a graph so that the gauge group becomes a finite-dimensional ribbon Hopf algebra, the graph becomes a ribbon graph, and gauge-theoretic concepts such as connections, gauge transformations and observables are replaced by linearised analogues. Starting from physical considerations, we derive an axiomatic definition of Hopf-algebra gauge theory, including locality conditions under which the theory for a general ribbon graph can be assembled from local data in the neighbourhood of each vertex. For a vertex neighbourhood with n incoming edge ends, the algebra of non-commutative \"functions\" of connections is dual to a two-sided twist deformation of the n-fold tensor power of the gauge Hopf algebra. We show these algebras assemble to give an algebra of functions and gauge-invariant subalgebra of \"observables\" that coincide with those obtained in the combinatorial quantisation of Chern-Simons theory, thus providing an axiomatic derivation of the latter. We then discuss holonomy in a Hopf algebra gauge theory and show that for semisimple Hopf algebras this gives, for each path in the embedded graph, a map from connections into the gauge Hopf algebra, depending functorially on the path. Curvatures---holonomies around the faces canonically associated to the ribbon graph---then correspond to central elements of the algebra of observables, and define a set of commuting projectors onto the subalgebra of observables on flat connections. The algebras of observables for all connections or for flat connections are topological invariants, depending only on the topology, respectively, of the punctured or closed surface canonically obtained by gluing annuli or discs along edges of the ribbon graph.",
    "title": "Hopf algebra gauge theory on a ribbon graph"
  },
  {
    "arxiv": "1601.03778",
    "counts": {
      "ComplEx": 1,
      "LINE": 1,
      "RESCAL": 1,
      "RatE": 1,
      "SE": 1
    },
    "published": "2016-01-14T23:13:00Z",
    "summary": "Link prediction, or predicting the likelihood of a link in a knowledge graph based on its existing state is a key research task. It differs from a traditional link prediction task in that the links in a knowledge graph are categorized into different predicates and the link prediction performance of different predicates in a knowledge graph generally varies widely. In this work, we propose a latent feature embedding based link prediction model which considers the prediction task for each predicate disjointly. To learn the model parameters it utilizes a Bayesian personalized ranking based optimization technique. Experimental results on large-scale knowledge bases such as YAGO2 show that our link prediction approach achieves substantially higher performance than several state-of-art approaches. We also show that for a given predicate the topological properties of the knowledge graph induced by the given predicate edges are key indicators of the link prediction performance of that predicate in the knowledge graph.",
    "title": "Trust from the past: Bayesian Personalized Ranking based Link Prediction in Knowledge Graphs"
  },
  {
    "arxiv": "1602.06778",
    "counts": {
      "GeomE": 1,
      "HypER": 1,
      "LINE": 1,
      "NAM": 1,
      "ProjE": 1,
      "SE": 1
    },
    "published": "2016-02-22T13:58:39Z",
    "summary": "The classical theorem of F\\'{a}ry states that every planar graph can be represented by an embedding in which every edge is represented by a straight line segment. We consider generalizations of F\\'{a}ry's theorem to surfaces equipped with Riemannian metrics. In this setting, we require that every edge is drawn as a shortest path between its two endpoints and we call an embedding with this property a shortest path embedding. The main question addressed in this paper is whether given a closed surface S, there exists a Riemannian metric for which every topologically embeddable graph admits a shortest path embedding. This question is also motivated by various problems regarding crossing numbers on surfaces. We observe that the round metrics on the sphere and the projective plane have this property. We provide flat metrics on the torus and the Klein bottle which also have this property. Then we show that for the unit square flat metric on the Klein bottle there exists a graph without shortest path embeddings. We show, moreover, that for large g, there exist graphs G embeddable into the orientable surface of genus g, such that with large probability a random hyperbolic metric does not admit a shortest path embedding of G, where the probability measure is proportional to the Weil-Petersson volume on moduli space. Finally, we construct a hyperbolic metric on every orientable surface S of genus g, such that every graph embeddable into S can be embedded so that every edge is a concatenation of at most O(g) shortest paths.",
    "title": "Shortest path embeddings of graphs on surfaces"
  },
  {
    "arxiv": "1603.08861",
    "counts": {
      "LINE": 1,
      "SE": 5,
      "TransD": 4,
      "TransE": 1
    },
    "published": "2016-03-29T17:46:16Z",
    "summary": "We present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models.",
    "title": "Revisiting Semi-Supervised Learning with Graph Embeddings"
  },
  {
    "arxiv": "1604.03221",
    "counts": {
      "NAM": 1,
      "RatE": 1,
      "SE": 1,
      "SimplE": 1
    },
    "published": "2016-04-08T20:46:13Z",
    "summary": "The aim of link prediction is to forecast connections that are most likely to occur in the future, based on examples of previously observed links. A key insight is that it is useful to explicitly model network dynamics, how frequently links are created or destroyed when doing link prediction. In this paper, we introduce a new supervised link prediction framework, RPM (Rate Prediction Model). In addition to network similarity measures, RPM uses the predicted rate of link modifications, modeled using time series data; it is implemented in Spark-ML and trained with the original link distribution, rather than a small balanced subset. We compare the use of this network dynamics model to directly creating time series of network similarity measures. Our experiments show that RPM, which leverages predicted rates, outperforms the use of network similarity measures, either individually or within a time series.",
    "title": "Leveraging Network Dynamics for Improved Link Prediction"
  },
  {
    "arxiv": "1606.00191",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "HypER": 1,
      "LINE": 1,
      "NAM": 1,
      "ProjE": 1,
      "RatE": 1,
      "SE": 1,
      "SimplE": 1,
      "TACT": 1,
      "TransF": 1,
      "TransM": 1
    },
    "published": "2016-06-01T09:35:50Z",
    "summary": "A growing trend for information technology is to not just react to changes, but anticipate them as much as possible. This paradigm made modern solutions, such as recommendation systems, a ubiquitous presence in today's digital transactions. Anticipatory networking extends the idea to communication technologies by studying patterns and periodicity in human behavior and network dynamics to optimize network performance. This survey collects and analyzes recent papers leveraging context information to forecast the evolution of network conditions and, in turn, to improve network performance. In particular, we identify the main prediction and optimization tools adopted in this body of work and link them with objectives and constraints of the typical applications and scenarios. Finally, we consider open challenges and research directions to make anticipatory networking part of next generation networks.",
    "title": "A Survey of Anticipatory Mobile Networking: Context-Based Classification, Prediction Methodologies, and Optimization Techniques"
  },
  {
    "arxiv": "1606.06357",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "GeomE": 1,
      "HolE": 1,
      "NAM": 1,
      "NTN": 1,
      "RESCAL": 1,
      "SE": 1,
      "SME": 1,
      "SimplE": 1,
      "TransE": 1
    },
    "published": "2016-06-20T22:52:48Z",
    "summary": "In statistical relational learning, the link prediction problem is key to automatically understand the structure of large knowledge bases. As in previous studies, we propose to solve this problem through latent factorization. However, here we make use of complex valued embeddings. The composition of complex embeddings can handle a large variety of binary relations, among them symmetric and antisymmetric relations. Compared to state-of-the-art models such as Neural Tensor Network and Holographic Embeddings, our approach based on complex embeddings is arguably simpler, as it only uses the Hermitian dot product, the complex counterpart of the standard dot product between real vectors. Our approach is scalable to large datasets as it remains linear in both space and time, while consistently outperforming alternative approaches on standard link prediction benchmarks.",
    "title": "Complex Embeddings for Simple Link Prediction"
  },
  {
    "arxiv": "1607.07330",
    "counts": {
      "LINE": 1,
      "ProjE": 1,
      "SE": 1
    },
    "published": "2016-07-25T16:00:32Z",
    "summary": "The task of predicting future relationships in a social network, known as link prediction, has been studied extensively in the literature. Many link prediction methods have been proposed, ranging from common neighbors to probabilistic models. Recent work by Yang et al. has highlighted several challenges in evaluating link prediction accuracy. In dynamic networks where edges are both added and removed over time, the link prediction problem is more complex and involves predicting both newly added and newly removed edges. This results in new challenges in the evaluation of dynamic link prediction methods, and the recommendations provided by Yang et al. are no longer applicable, because they do not address edge removal. In this paper, we investigate several metrics currently used for evaluating accuracies of dynamic link prediction methods and demonstrate why they can be misleading in many cases. We provide several recommendations on evaluating dynamic link prediction accuracy, including separation into two categories of evaluation. Finally we propose a unified metric to characterize link prediction accuracy effectively using a single number.",
    "title": "Evaluating Link Prediction Accuracy on Dynamic Networks with Added and Removed Edges"
  },
  {
    "arxiv": "1608.02087",
    "counts": {
      "GeomE": 1,
      "NAM": 1,
      "SE": 1
    },
    "published": "2016-08-06T09:46:54Z",
    "summary": "A (possibly denerate) drawing of a graph $G$ in the plane is approximable by an embedding if it can be turned into an embedding by an arbitrarily small perturbation. We show that testing, whether a straight-line drawing of a planar graph $G$ in the plane is approximable by an embedding, can be carried out in polynomial time, if a desired embedding of $G$ belongs to a fixed isotopy class. In other words, we show that c-planarity with embedded pipes is tractable for graphs with fixed embeddings. To the best of our knowledge an analogous result was previously known essentially only when $G$ is a cycle.",
    "title": "Embedding graphs into embedded graphs"
  },
  {
    "arxiv": "1609.03946",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "NAM": 1,
      "SE": 1
    },
    "published": "2016-09-13T17:34:33Z",
    "summary": "Networks extracted from social media platforms frequently include multiple types of links that dynamically change over time; these links can be used to represent dyadic interactions such as economic transactions, communications, and shared activities. Organizing this data into a dynamic multiplex network, where each layer is composed of a single edge type linking the same underlying vertices, can reveal interesting cross-layer interaction patterns. In coevolving networks, links in one layer result in an increased probability of other types of links forming between the same node pair. Hence we believe that a holistic approach in which all the layers are simultaneously considered can outperform a factored approach in which link prediction is performed separately in each layer. This paper introduces a comprehensive framework, MLP (Multilayer Link Prediction), in which link existence likelihoods for the target layer are learned from the other network layers. These likelihoods are used to reweight the output of a single layer link prediction method that uses rank aggregation to combine a set of topological metrics. Our experiments show that our reweighting procedure outperforms other methods for fusing information across network layers.",
    "title": "A Holistic Approach for Predicting Links in Coevolving Multilayer Networks"
  },
  {
    "arxiv": "1610.08722",
    "counts": {
      "ProjE": 1,
      "SE": 1,
      "TransA": 1
    },
    "published": "2016-10-27T11:49:52Z",
    "summary": "Community detection is a classical problem in the field of graph mining. While most algorithms work on the entire graph, it is often interesting in practice to recover only the community containing some given set of seed nodes. In this paper, we propose a novel approach to this problem, using some low-dimensional embedding of the graph based on random walks starting from the seed nodes. From this embedding, we propose some simple yet efficient versions of the PageRank algorithm as well as a novel algorithm, called WalkSCAN, that is able to detect multiple communities, possibly overlapping. We provide insights into the performance of these algorithms through the theoretical analysis of a toy network and show that WalkSCAN outperforms existing algorithms on real networks.",
    "title": "Improving PageRank for Local Community Detection"
  },
  {
    "arxiv": "1611.06961",
    "counts": {
      "ComplEx": 1,
      "HypER": 1,
      "SE": 1,
      "SimplE": 1,
      "TransA": 1
    },
    "published": "2016-11-21T19:20:32Z",
    "summary": "Novelty attracts attention like popularity. Hence predicting novelty is as important as popularity. Novelty is the side effect of competition and aging in evolving systems. Recent behavior or recent link gain in networks plays an important role in emergence or trend. We exploited this wisdom and came up with two models considering different scenarios and systems. Where recent behavior dominates over total behavior (total link gain) in the first one, and recent behavior is as important as total behavior for future link gain in second one. It suppose that random walker walks on a network and can jump to any node, the probablity of jumping or making connection to other node is based on which node is recently more active or receiving more links. In our assumption random walker can also jump to node which is already popular but recently not popular. We are able to predict rising novelties or popular nodes which is generally suppressed under preferential attachment effect. To show performance of our model we have conducted experiments on four real data sets namely, MovieLens, Netflix, Facebook and Arxiv High Energy Physics paper citation. For testing our model we used four information retrieval indices namely Precision, Novelty, Area Under Receiving Operating Characteristic(AUC) and Kendal's rank correlation coefficient. We have used four benchmark models for validating our proposed models. Although our model doesn't perform better in all the cases but, it has theoretical significance in working better for recent behavior dominant systems.",
    "title": "Rising Novelties on Evolving Networks: Recent Behavior Dominant and Non-Dominant Model"
  },
  {
    "arxiv": "1702.00156",
    "counts": {
      "ComplEx": 1,
      "LINE": 2,
      "ProjE": 2,
      "SE": 2,
      "TransA": 2
    },
    "published": "2017-02-01T08:16:03Z",
    "summary": "Graph-based methods are known to be successful in many machine learning and pattern classification tasks. These methods consider semi-structured data as graphs where nodes correspond to primitives (parts, interest points, segments, etc.) and edges characterize the relationships between these primitives. However, these non-vectorial graph data cannot be straightforwardly plugged into off-the-shelf machine learning algorithms without a preliminary step of -- explicit/implicit -- graph vectorization and embedding. This embedding process should be resilient to intra-class graph variations while being highly discriminant. In this paper, we propose a novel high-order stochastic graphlet embedding (SGE) that maps graphs into vector spaces. Our main contribution includes a new stochastic search procedure that efficiently parses a given graph and extracts/samples unlimitedly high-order graphlets. We consider these graphlets, with increasing orders, to model local primitives as well as their increasingly complex interactions. In order to build our graph representation, we measure the distribution of these graphlets into a given graph, using particular hash functions that efficiently assign sampled graphlets into isomorphic sets with a very low probability of collision. When combined with maximum margin classifiers, these graphlet-based representations have positive impact on the performance of pattern comparison and recognition as corroborated through extensive experiments using standard benchmark databases.",
    "title": "Stochastic Graphlet Embedding"
  },
  {
    "arxiv": "1702.05358",
    "counts": {
      "ConvE": 1,
      "GeomE": 1,
      "LINE": 2,
      "ProjE": 1,
      "SE": 1,
      "TransF": 1,
      "TuckER": 1
    },
    "published": "2017-02-17T14:34:08Z",
    "summary": "Computational topology is an area that revisits topological problems from an algorithmic point of view, and develops topological tools for improved algorithms. We survey results in computational topology that are concerned with graphs drawn on surfaces. Typical questions include representing surfaces and graphs embedded on them computationally, deciding whether a graph embeds on a surface, solving computational problems related to homotopy, optimizing curves and graphs on surfaces, and solving standard graph algorithm problems more efficiently in the case of surface-embedded graphs.",
    "title": "Computational topology of graphs on surfaces"
  },
  {
    "arxiv": "1702.06879",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "HolE": 1,
      "NAM": 1,
      "NTN": 1,
      "RESCAL": 1,
      "SE": 1,
      "SME": 1,
      "TransE": 1
    },
    "published": "2017-02-22T16:28:11Z",
    "summary": "In statistical relational learning, knowledge graph completion deals with automatically understanding the structure of large knowledge graphs---labeled directed graphs---and predicting missing relationships---labeled edges. State-of-the-art embedding models propose different trade-offs between modeling expressiveness, and time and space complexity. We reconcile both expressiveness and complexity through the use of complex-valued embeddings and explore the link between such complex-valued embeddings and unitary diagonalization. We corroborate our approach theoretically and show that all real square matrices---thus all possible relation/adjacency matrices---are the real part of some unitarily diagonalizable matrix. This results opens the door to a lot of other applications of square matrices factorization. Our approach based on complex embeddings is arguably simple, as it only involves a Hermitian dot product, the complex counterpart of the standard dot product between real vectors, whereas other methods resort to more and more complicated composition functions to increase their expressiveness. The proposed complex embeddings are scalable to large data sets as it remains linear in both space and time, while consistently outperforming alternative approaches on standard link prediction benchmarks.",
    "title": "Knowledge Graph Completion via Complex Tensor Factorization"
  },
  {
    "arxiv": "1703.03862",
    "counts": {
      "GeomE": 2,
      "ProjE": 2,
      "SE": 4,
      "SimplE": 2
    },
    "published": "2017-03-10T22:46:09Z",
    "summary": "Feature extraction and dimension reduction for networks is critical in a wide variety of domains. Efficiently and accurately learning features for multiple graphs has important applications in statistical inference on graphs. We propose a method to jointly embed multiple undirected graphs. Given a set of graphs, the joint embedding method identifies a linear subspace spanned by rank one symmetric matrices and projects adjacency matrices of graphs into this subspace. The projection coefficients can be treated as features of the graphs, while the embedding components can represent vertex features. We also propose a random graph model for multiple graphs that generalizes other classical models for graphs. We show through theory and numerical experiments that under the model, the joint embedding method produces estimates of parameters with small errors. Via simulation experiments, we demonstrate that the joint embedding method produces features which lead to state of the art performance in classifying graphs. Applying the joint embedding method to human brain graphs, we find it extracts interpretable features with good prediction accuracy in different tasks.",
    "title": "Joint Embedding of Graphs"
  },
  {
    "arxiv": "1705.02801",
    "counts": {
      "ComplEx": 1,
      "FedE": 1,
      "HypER": 1,
      "LINE": 1,
      "NAM": 1,
      "SDNE": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2017-05-08T09:47:38Z",
    "summary": "Graphs, such as social networks, word co-occurrence networks, and communication networks, occur naturally in various real-world applications. Analyzing them yields insight into the structure of society, language, and different patterns of communication. Many approaches have been proposed to perform the analysis. Recently, methods which use the representation of graph nodes in vector space have gained traction from the research community. In this survey, we provide a comprehensive and structured analysis of various graph embedding techniques proposed in the literature. We first introduce the embedding task and its challenges such as scalability, choice of dimensionality, and features to be preserved, and their possible solutions. We then present three categories of approaches based on factorization methods, random walks, and deep learning, with examples of representative algorithms in each category and analysis of their performance on various tasks. We evaluate these state-of-the-art methods on a few common datasets and compare their performance against one another. Our analysis concludes by suggesting some potential applications and future directions. We finally present the open-source Python library we developed, named GEM (Graph Embedding Methods, available at https://github.com/palash1992/GEM), which provides all presented algorithms within a unified interface to foster and facilitate research on the topic.",
    "title": "Graph Embedding Techniques, Applications, and Performance: A Survey"
  },
  {
    "arxiv": "1706.02216",
    "counts": {
      "GraphSAGE": 3,
      "HypER": 2,
      "LINE": 3,
      "NAM": 2,
      "RatE": 1,
      "SE": 7,
      "node2vec": 4
    },
    "published": "2017-06-07T14:51:05Z",
    "summary": "Low-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general, inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node's local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions.",
    "title": "Inductive Representation Learning on Large Graphs"
  },
  {
    "arxiv": "1707.01475",
    "counts": {
      "ComplEx": 1,
      "HolE": 1,
      "SE": 1
    },
    "published": "2017-07-05T17:17:34Z",
    "summary": "Embeddings of knowledge graphs have received significant attention due to their excellent performance for tasks like link prediction and entity resolution. In this short paper, we are providing a comparison of two state-of-the-art knowledge graph embeddings for which their equivalence has recently been established, i.e., ComplEx and HolE [Nickel, Rosasco, and Poggio, 2016; Trouillon et al., 2016; Hayashi and Shimbo, 2017]. First, we briefly review both models and discuss how their scoring functions are equivalent. We then analyze the discrepancy of results reported in the original articles, and show experimentally that they are likely due to the use of different loss functions. In further experiments, we evaluate the ability of both models to embed symmetric and antisymmetric patterns. Finally, we discuss advantages and disadvantages of both models and under which conditions one would be preferable to the other.",
    "title": "Complex and Holographic Embeddings of Knowledge Graphs: A Comparison"
  },
  {
    "arxiv": "1707.07596",
    "counts": {
      "ComplEx": 3,
      "DistMult": 3,
      "HypER": 1,
      "LINE": 1,
      "ProjE": 1,
      "SE": 6,
      "SimplE": 2,
      "TransE": 2,
      "TransH": 1,
      "TransR": 1,
      "TuckER": 1
    },
    "published": "2017-07-24T15:00:55Z",
    "summary": "In adversarial training, a set of models learn together by pursuing competing goals, usually defined on single data instances. However, in relational learning and other non-i.i.d domains, goals can also be defined over sets of instances. For example, a link predictor for the is-a relation needs to be consistent with the transitivity property: if is-a(x_1, x_2) and is-a(x_2, x_3) hold, is-a(x_1, x_3) needs to hold as well. Here we use such assumptions for deriving an inconsistency loss, measuring the degree to which the model violates the assumptions on an adversarially-generated set of examples. The training objective is defined as a minimax problem, where an adversary finds the most offending adversarial examples by maximising the inconsistency loss, and the model is trained by jointly minimising a supervised loss and the inconsistency loss on the adversarial examples. This yields the first method that can use function-free Horn clauses (as in Datalog) to regularise any neural link predictor, with complexity independent of the domain size. We show that for several link prediction models, the optimisation problem faced by the adversary has efficient closed-form solutions. Experiments on link prediction benchmarks indicate that given suitable prior knowledge, our method can significantly improve neural link predictors on all relevant metrics.",
    "title": "Adversarial Sets for Regularising Neural Link Predictors"
  },
  {
    "arxiv": "1708.02083",
    "counts": {
      "NAM": 1,
      "RotH": 1,
      "SE": 1
    },
    "published": "2017-08-07T12:03:46Z",
    "summary": "After reviewing the description of an unstable state in the framework of Lee Hamiltonians (valid both for Quantum Mechanics (QM) and Quantum Field Theory (QFT)), we consider some theoretical aspects of non-exponential decays: the case of two decay channels, the broadening of the energy spectrum at short times, the effect of an imperfect measurement, the link to QFT, and the decay of an unstable moving particle with definite momentum. All the presented effects were not confirmed in experiments, hence are at the present stage predictions.",
    "title": "Time evolution of an unstable quantum system"
  },
  {
    "arxiv": "1708.07201",
    "counts": {
      "ConvE": 1,
      "GeomE": 2,
      "HAKE": 3,
      "HypER": 5,
      "SE": 5
    },
    "published": "2017-08-23T22:09:04Z",
    "summary": "We survey some tools and techniques for determining geometric properties of a link complement from a link diagram. In particular, we survey the tools used to estimate geometric invariants in terms of basic diagrammatic link invariants. We focus on determining when a link is hyperbolic, estimating its volume, and bounding its cusp shape and cusp area. We give sample applications and state some open questions and conjectures.",
    "title": "A survey of hyperbolic knot theory"
  },
  {
    "arxiv": "1708.08720",
    "counts": {
      "GeomE": 1,
      "SE": 1,
      "TuckER": 1
    },
    "published": "2017-08-29T12:10:49Z",
    "summary": "It is known that graphs cellularly embedded into surfaces are equivalent to ribbon graphs. In this work, we generalize this statement to broader classes of graphs and surfaces. Half-edge graphs extend abstract graphs and are useful in quantum field theory in physics. On the other hand, ribbon graphs with half-edges generalize ribbon graphs and appear in a different type of field theory emanating from matrix models. We then give a sense of embeddings of half-edge graphs in punctured surfaces and determine (minimal/maximal) conditions for an equivalence between these embeddings and half-edge ribbon graphs. Given some assumptions on the embedding, the geometric dual of a cellularly embedded half-edge graph is also identified.",
    "title": "Embedding Half-Edge Graphs in Punctured Surfaces"
  },
  {
    "arxiv": "1709.01148",
    "counts": {
      "ConvE": 1,
      "LINE": 1,
      "SE": 2
    },
    "published": "2017-09-04T20:36:14Z",
    "summary": "In this paper, we study learning visual classifiers from unstructured text descriptions at part precision with no training images. We propose a learning framework that is able to connect text terms to its relevant parts and suppress connections to non-visual text terms without any part-text annotations. For instance, this learning process enables terms like \"beak\" to be sparsely linked to the visual representation of parts like head, while reduces the effect of non-visual terms like \"migrate\" on classifier prediction. Images are encoded by a part-based CNN that detect bird parts and learn part-specific representation. Part-based visual classifiers are predicted from text descriptions of unseen visual classifiers to facilitate classification without training images (also known as zero-shot recognition). We performed our experiments on CUBirds 2011 dataset and improves the state-of-the-art text-based zero-shot recognition results from 34.7\\% to 43.6\\%. We also created large scale benchmarks on North American Bird Images augmented with text descriptions, where we also show that our approach outperforms existing methods. Our code, data, and models are publically available.",
    "title": "Link the head to the \"beak\": Zero Shot Learning from Noisy Text Description at Part Precision"
  },
  {
    "arxiv": "1709.05454",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "LINE": 1,
      "NAM": 1,
      "ProjE": 1,
      "SE": 2,
      "SimplE": 1
    },
    "published": "2017-09-16T04:22:57Z",
    "summary": "The random dot product graph (RDPG) is an independent-edge random graph that is analytically tractable and, simultaneously, either encompasses or can successfully approximate a wide range of random graphs, from relatively simple stochastic block models to complex latent position graphs. In this survey paper, we describe a comprehensive paradigm for statistical inference on random dot product graphs, a paradigm centered on spectral embeddings of adjacency and Laplacian matrices. We examine the analogues, in graph inference, of several canonical tenets of classical Euclidean inference: in particular, we summarize a body of existing results on the consistency and asymptotic normality of the adjacency and Laplacian spectral embeddings, and the role these spectral embeddings can play in the construction of single- and multi-sample hypothesis tests for graph data. We investigate several real-world applications, including community detection and classification in large social networks and the determination of functional and biologically relevant network properties from an exploratory data analysis of the Drosophila connectome. We outline requisite background and current open problems in spectral graph inference.",
    "title": "Statistical inference on random dot product graphs: a survey"
  },
  {
    "arxiv": "1710.03059",
    "counts": {
      "ComplEx": 1,
      "LINE": 1,
      "SE": 1,
      "TransE": 1,
      "node2vec": 1
    },
    "published": "2017-10-09T12:43:56Z",
    "summary": "We propose Embedding Propagation (EP), an unsupervised learning framework for graph-structured data. EP learns vector representations of graphs by passing two types of messages between neighboring nodes. Forward messages consist of label representations such as representations of words and other attributes associated with the nodes. Backward messages consist of gradients that result from aggregating the label representations and applying a reconstruction loss. Node representations are finally computed from the representation of their labels. With significantly fewer parameters and hyperparameters an instance of EP is competitive with and often outperforms state of the art unsupervised and semi-supervised learning methods on a range of benchmark data sets.",
    "title": "Learning Graph Representations with Embedding Propagation"
  },
  {
    "arxiv": "1802.03638",
    "counts": {
      "ANALOGY": 1,
      "ComplEx": 1,
      "DistMult": 1,
      "HolE": 1,
      "LINE": 1,
      "SE": 1,
      "TransE": 1
    },
    "published": "2018-02-10T18:46:54Z",
    "summary": "Graph representations of large knowledge bases may comprise billions of edges. Usually built upon human-generated ontologies, several knowledge bases do not feature declared ontological rules and are far from being complete. Current rule mining approaches rely on schemata or store the graph in-memory, which can be unfeasible for large graphs. In this paper, we introduce HornConcerto, an algorithm to discover Horn clauses in large graphs without the need of a schema. Using a standard fact-based confidence score, we can mine close Horn rules having an arbitrary body size. We show that our method can outperform existing approaches in terms of runtime and memory consumption and mine high-quality rules for the link prediction task, achieving state-of-the-art results on a widely-used benchmark. Moreover, we find that rules alone can perform inference significantly faster than embedding-based methods and achieve accuracies on link prediction comparable to resource-demanding approaches such as Markov Logic Networks.",
    "title": "Beyond Markov Logic: Efficient Mining of Prediction Rules in Large Graphs"
  },
  {
    "arxiv": "1802.04407",
    "counts": {
      "LINE": 1,
      "SDNE": 1,
      "SE": 2,
      "node2vec": 1
    },
    "published": "2018-02-13T00:29:11Z",
    "summary": "Graph embedding is an effective method to represent graph data in a low dimensional space for graph analytics. Most existing embedding algorithms typically focus on preserving the topological structure or minimizing the reconstruction errors of graph data, but they have mostly ignored the data distribution of the latent codes from the graphs, which often results in inferior embedding in real-world graph data. In this paper, we propose a novel adversarial graph embedding framework for graph data. The framework encodes the topological structure and node content in a graph to a compact representation, on which a decoder is trained to reconstruct the graph structure. Furthermore, the latent representation is enforced to match a prior distribution via an adversarial training scheme. To learn a robust embedding, two variants of adversarial approaches, adversarially regularized graph autoencoder (ARGA) and adversarially regularized variational graph autoencoder (ARVGA), are developed. Experimental studies on real-world graphs validate our design and demonstrate that our algorithms outperform baselines by a wide margin in link prediction, graph clustering, and graph visualization tasks.",
    "title": "Adversarially Regularized Graph Autoencoder for Graph Embedding"
  },
  {
    "arxiv": "1802.06368",
    "counts": {
      "HypER": 1,
      "LINE": 1,
      "NAM": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2018-02-18T13:03:08Z",
    "summary": "Embedding graph nodes into a vector space can allow the use of machine learning to e.g. predict node classes, but the study of node embedding algorithms is immature compared to the natural language processing field because of a diverse nature of graphs. We examine the performance of node embedding algorithms with respect to graph centrality measures that characterize diverse graphs, through systematic experiments with four node embedding algorithms, four or five graph centralities, and six datasets. Experimental results give insights into the properties of node embedding algorithms, which can be a basis for further research on this topic.",
    "title": "Node Centralities and Classification Performance for Characterizing Node Embedding Algorithms"
  },
  {
    "arxiv": "1802.06902",
    "counts": {
      "ConvE": 1,
      "GeomE": 1,
      "RatE": 1,
      "SE": 1
    },
    "published": "2018-02-19T22:58:41Z",
    "summary": "Industrial automation deployments constitute challenging environments where moving IoT machines may produce high-definition video and other heavy sensor data during surveying and inspection operations. Transporting massive contents to the edge network infrastructure and then eventually to the remote human operator requires reliable and high-rate radio links supported by intelligent data caching and delivery mechanisms. In this work, we address the challenges of contents dissemination in characteristic factory automation scenarios by proposing to engage moving industrial machines as device-to-device (D2D) caching helpers. With the goal to improve reliability of high-rate millimeter-wave (mmWave) data connections, we introduce the alternative contents dissemination modes and then construct a novel mobility-aware methodology that helps develop predictive mode selection strategies based on the anticipated radio link conditions. We also conduct a thorough system-level evaluation of representative data dissemination strategies to confirm the benefits of predictive solutions that employ D2D-enabled collaborative caching at the wireless edge to lower contents delivery latency and improve data acquisition reliability.",
    "title": "Caching-Aided Collaborative D2D Operation for Predictive Data Dissemination in Industrial IoT"
  },
  {
    "arxiv": "1802.06916",
    "counts": {
      "5*": 21,
      "LINE": 14,
      "SE": 4,
      "SimplE": 25,
      "node2vec": 1
    },
    "published": "2018-02-20T00:05:25Z",
    "summary": "Networks provide a powerful formalism for modeling complex systems by using a model of pairwise interactions. But much of the structure within these systems involves interactions that take place among more than two nodes at once; for example, communication within a group rather than person-to person, collaboration among a team rather than a pair of coauthors, or biological interaction between a set of molecules rather than just two. Such higher-order interactions are ubiquitous, but their empirical study has received limited attention, and little is known about possible organizational principles of such structures. Here we study the temporal evolution of 19 datasets with explicit accounting for higher-order interactions. We show that there is a rich variety of structure in our datasets but datasets from the same system types have consistent patterns of higher-order structure. Furthermore, we find that tie strength and edge density are competing positive indicators of higher-order organization, and these trends are consistent across interactions involving differing numbers of nodes. To systematically further the study of theories for such higher-order structures, we propose higher-order link prediction as a benchmark problem to assess models and algorithms that predict higher-order structure. We find a fundamental differences from traditional pairwise link prediction, with a greater role for local rather than long-range information in predicting the appearance of new interactions.",
    "title": "Simplicial Closure and higher-order link prediction"
  },
  {
    "arxiv": "1802.08352",
    "counts": {
      "HypER": 1,
      "LINE": 1,
      "NAM": 1,
      "RatE": 1,
      "SDNE": 1,
      "SE": 1,
      "TransA": 1,
      "TransF": 1,
      "node2vec": 1
    },
    "published": "2018-02-23T00:02:59Z",
    "summary": "We examine two fundamental tasks associated with graph representation learning: link prediction and semi-supervised node classification. We present a novel autoencoder architecture capable of learning a joint representation of both local graph structure and available node features for the multi-task learning of link prediction and node classification. Our autoencoder architecture is efficiently trained end-to-end in a single learning stage to simultaneously perform link prediction and node classification, whereas previous related methods require multiple training steps that are difficult to optimize. We provide a comprehensive empirical evaluation of our models on nine benchmark graph-structured datasets and demonstrate significant improvement over related methods for graph representation learning. Reference code and data are available at https://github.com/vuptran/graph-representation-learning",
    "title": "Learning to Make Predictions on Graphs with Autoencoders"
  },
  {
    "arxiv": "1802.09612",
    "counts": {
      "ComplEx": 3,
      "GeomE": 1,
      "GraphSAGE": 3,
      "HypER": 1,
      "LINE": 8,
      "ProjE": 3,
      "SDNE": 3,
      "SE": 7,
      "SimplE": 3,
      "metapath2vec": 1,
      "node2vec": 3
    },
    "published": "2018-02-26T21:18:43Z",
    "summary": "Recently there has been a surge of interest in designing graph embedding methods. Few, if any, can scale to a large-sized graph with millions of nodes due to both computational complexity and memory requirements. In this paper, we relax this limitation by introducing the MultI-Level Embedding (MILE) framework -- a generic methodology allowing contemporary graph embedding methods to scale to large graphs. MILE repeatedly coarsens the graph into smaller ones using a hybrid matching technique to maintain the backbone structure of the graph. It then applies existing embedding methods on the coarsest graph and refines the embeddings to the original graph through a graph convolution neural network that it learns. The proposed MILE framework is agnostic to the underlying graph embedding techniques and can be applied to many existing graph embedding methods without modifying them. We employ our framework on several popular graph embedding techniques and conduct embedding for real-world graphs. Experimental results on five large-scale datasets demonstrate that MILE significantly boosts the speed (order of magnitude) of graph embedding while generating embeddings of better quality, for the task of node classification. MILE can comfortably scale to a graph with 9 million nodes and 40 million edges, on which existing methods run out of memory or take too long to compute on a modern workstation. Our code and data are publicly available with detailed instructions for adding new base embedding methods: \\url{https://github.com/jiongqian/MILE}.",
    "title": "MILE: A Multi-Level Framework for Scalable Graph Embedding"
  },
  {
    "arxiv": "1803.00425",
    "counts": {
      "ComplEx": 1,
      "LINE": 1,
      "SE": 1
    },
    "published": "2018-02-28T12:37:41Z",
    "summary": "Graph-based methods are known to be successful in many machine learning and pattern classification tasks. These methods consider semi-structured data as graphs where nodes correspond to primitives (parts, interest points, segments, etc.) and edges characterize the relationships between these primitives. However, these non-vectorial graph data cannot be straightforwardly plugged into off-the-shelf machine learning algorithms without a preliminary step of -- explicit/implicit -- graph vectorization and embedding. This embedding process should be resilient to intra-class graph variations while being highly discriminant. In this paper, we propose a novel high-order stochastic graphlet embedding (SGE) that maps graphs into vector spaces. Our main contribution includes a new stochastic search procedure that efficiently parses a given graph and extracts/samples unlimitedly high-order graphlets. We consider these graphlets, with increasing orders, to model local primitives as well as their increasingly complex interactions. In order to build our graph representation, we measure the distribution of these graphlets into a given graph, using particular hash functions that efficiently assign sampled graphlets into isomorphic sets with a very low probability of collision. When combined with maximum margin classifiers, these graphlet-based representations have positive impact on the performance of pattern comparison and recognition as corroborated through extensive experiments using standard benchmark databases.",
    "title": "Graph Kernels based on High Order Graphlet Parsing and Hashing"
  },
  {
    "arxiv": "1803.04742",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "LINE": 1,
      "SDNE": 1,
      "SE": 1,
      "node2vec": 1,
      "struc2Vec": 1
    },
    "published": "2018-03-13T12:05:58Z",
    "summary": "Embedding a web-scale information network into a low-dimensional vector space facilitates tasks such as link prediction, classification, and visualization. Past research has addressed the problem of extracting such embeddings by adopting methods from words to graphs, without defining a clearly comprehensible graph-related objective. Yet, as we show, the objectives used in past works implicitly utilize similarity measures among graph nodes. In this paper, we carry the similarity orientation of previous works to its logical conclusion; we propose VERtex Similarity Embeddings (VERSE), a simple, versatile, and memory-efficient method that derives graph embeddings explicitly calibrated to preserve the distributions of a selected vertex-to-vertex similarity measure. VERSE learns such embeddings by training a single-layer neural network. While its default, scalable version does so via sampling similarity information, we also develop a variant using the full information per vertex. Our experimental study on standard benchmarks and real-world datasets demonstrates that VERSE, instantiated with diverse similarity measures, outperforms state-of-the-art methods in terms of precision and recall in major data mining tasks and supersedes them in time and space efficiency, while the scalable sampling-based variant achieves equally good results as the non-scalable full variant.",
    "title": "VERSE: Versatile Graph Embeddings from Similarity Measures"
  },
  {
    "arxiv": "1804.05281",
    "counts": {
      "ConvE": 1,
      "GeomE": 1,
      "SE": 1
    },
    "published": "2018-04-14T21:49:00Z",
    "summary": "State surfaces are spanning surfaces of links that are obtained from link diagrams guided by the combinatorics underlying Kauffman's construction of the Jones polynomial via state models. Geometric properties of such surfaces are often dictated by simple link diagrammatic criteria, and the surfaces themselves carry important information about geometric structures of link complements. State surfaces also provide a tool for studying relations between Jones polynomials and topological invariants, such as the crosscap number or invariants coming from geometric structures on link complements (e.g. hyperbolic volume). This article is brief survey on some of the recent applications of state surfaces.",
    "title": "State Surfaces of Links"
  },
  {
    "arxiv": "1804.10637",
    "counts": {
      "ComplEx": 1,
      "HypER": 1,
      "NAM": 1,
      "SE": 1
    },
    "published": "2018-04-27T18:28:24Z",
    "summary": "Entity linking involves aligning textual mentions of named entities to their corresponding entries in a knowledge base. Entity linking systems often exploit relations between textual mentions in a document (e.g., coreference) to decide if the linking decisions are compatible. Unlike previous approaches, which relied on supervised systems or heuristics to predict these relations, we treat relations as latent variables in our neural entity-linking model. We induce the relations without any supervision while optimizing the entity-linking system in an end-to-end fashion. Our multi-relational model achieves the best reported scores on the standard benchmark (AIDA-CoNLL) and substantially outperforms its relation-agnostic version. Its training also converges much faster, suggesting that the injected structural bias helps to explain regularities in the training data.",
    "title": "Improving Entity Linking by Modeling Latent Relations between Mentions"
  },
  {
    "arxiv": "1805.11182",
    "counts": {
      "5*": 1,
      "GraphSAGE": 1,
      "LINE": 1,
      "SDNE": 1,
      "SE": 1,
      "metapath2vec": 1,
      "node2vec": 1
    },
    "published": "2018-05-28T21:49:54Z",
    "summary": "Graph embedding is a central problem in social network analysis and many other applications, aiming to learn the vector representation for each node. While most existing approaches need to specify the neighborhood and the dependence form to the neighborhood, which may significantly degrades the flexibility of representation, we propose a novel graph node embedding method (namely GESF) via the set function technique. Our method can 1) learn an arbitrary form of representation function from neighborhood, 2) automatically decide the significance of neighbors at different distances, and 3) be applied to heterogeneous graph embedding, which may contain multiple types of nodes. Theoretical guarantee for the representation capability of our method has been proved for general homogeneous and heterogeneous graphs and evaluation results on benchmark data sets show that the proposed GESF outperforms the state-of-the-art approaches on producing node vectors for classification tasks.",
    "title": "GESF: A Universal Discriminative Mapping Mechanism for Graph Representation Learning"
  },
  {
    "arxiv": "1806.01973",
    "counts": {
      "GraphSAGE": 3,
      "LINE": 1,
      "SE": 4,
      "node2vec": 3
    },
    "published": "2018-06-06T01:26:33Z",
    "summary": "Recent advancements in deep neural networks for graph-structured data have led to state-of-the-art performance on recommender system benchmarks. However, making these methods practical and scalable to web-scale recommendation tasks with billions of items and hundreds of millions of users remains a challenge. Here we describe a large-scale deep recommendation engine that we developed and deployed at Pinterest. We develop a data-efficient Graph Convolutional Network (GCN) algorithm PinSage, which combines efficient random walks and graph convolutions to generate embeddings of nodes (i.e., items) that incorporate both graph structure as well as node feature information. Compared to prior GCN approaches, we develop a novel method based on highly efficient random walks to structure the convolutions and design a novel training strategy that relies on harder-and-harder training examples to improve robustness and convergence of the model. We also develop an efficient MapReduce model inference algorithm to generate embeddings using a trained model. We deploy PinSage at Pinterest and train it on 7.5 billion examples on a graph with 3 billion nodes representing pins and boards, and 18 billion edges. According to offline metrics, user studies and A/B tests, PinSage generates higher-quality recommendations than comparable deep learning and graph-based alternatives. To our knowledge, this is the largest application of deep graph embeddings to date and paves the way for a new generation of web-scale recommender systems based on graph convolutional architectures.",
    "title": "Graph Convolutional Neural Networks for Web-Scale Recommender Systems"
  },
  {
    "arxiv": "1806.07464",
    "counts": {
      "ComplEx": 1,
      "HypER": 1,
      "LINE": 1,
      "ProjE": 1,
      "RatE": 1,
      "SDNE": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2018-06-19T21:06:32Z",
    "summary": "Graph embeddings have become a key and widely used technique within the field of graph mining, proving to be successful across a broad range of domains including social, citation, transportation and biological. Graph embedding techniques aim to automatically create a low-dimensional representation of a given graph, which captures key structural elements in the resulting embedding space. However, to date, there has been little work exploring exactly which topological structures are being learned in the embeddings process. In this paper, we investigate if graph embeddings are approximating something analogous with traditional vertex level graph features. If such a relationship can be found, it could be used to provide a theoretical insight into how graph embedding approaches function. We perform this investigation by predicting known topological features, using supervised and unsupervised methods, directly from the embedding space. If a mapping between the embeddings and topological features can be found, then we argue that the structural information encapsulated by the features is represented in the embedding space. To explore this, we present extensive experimental evaluation from five state-of-the-art unsupervised graph embedding techniques, across a range of empirical graph datasets, measuring a selection of topological features. We demonstrate that several topological features are indeed being approximated by the embedding space, allowing key insight into how graph embeddings create good representations.",
    "title": "Exploring the Semantic Content of Unsupervised Graph Embeddings: An Empirical Study"
  },
  {
    "arxiv": "1807.02839",
    "counts": {
      "ComplEx": 1,
      "LINE": 1,
      "ProjE": 1,
      "SE": 1
    },
    "published": "2018-07-08T15:33:22Z",
    "summary": "Despite being very successful within the pattern recognition and machine learning community, graph-based methods are often unusable because of the lack of mathematical operations defined in graph domain. Graph embedding, which maps graphs to a vectorial space, has been proposed as a way to tackle these difficulties enabling the use of standard machine learning techniques. However, it is well known that graph embedding functions usually suffer from the loss of structural information. In this paper, we consider the hierarchical structure of a graph as a way to mitigate this loss of information. The hierarchical structure is constructed by topologically clustering the graph nodes, and considering each cluster as a node in the upper hierarchical level. Once this hierarchical structure is constructed, we consider several configurations to define the mapping into a vector space given a classical graph embedding, in particular, we propose to make use of the Stochastic Graphlet Embedding (SGE). Broadly speaking, SGE produces a distribution of uniformly sampled low to high order graphlets as a way to embed graphs into the vector space. In what follows, the coarse-to-fine structure of a graph hierarchy and the statistics fetched by the SGE complements each other and includes important structural information with varied contexts. Altogether, these two techniques substantially cope with the usual information loss involved in graph embedding techniques, obtaining a more robust graph representation. This fact has been corroborated through a detailed experimental evaluation on various benchmark graph datasets, where we outperform the state-of-the-art methods.",
    "title": "Hierarchical stochastic graphlet embedding for graph-based pattern recognition"
  },
  {
    "arxiv": "1807.05044",
    "counts": {
      "ComplEx": 1,
      "ProjE": 1,
      "SE": 1
    },
    "published": "2018-07-13T13:05:07Z",
    "summary": "Focusing on coupling between edges, we generalize the relationship between the normalized graph Laplacian and random walks on graphs by devising an appropriate normalization for the Hodge Laplacian -- the generalization of the graph Laplacian for simplicial complexes -- and relate this to a random walk on edges. Importantly, these random walks are intimately connected to the topology of the simplicial complex, just as random walks on graphs are related to the topology of the graph. This serves as a foundational step towards incorporating Laplacian-based analytics for higher-order interactions. We demonstrate how to use these dynamics for data analytics that extract information about the edge-space of a simplicial complex that complements and extends graph-based analysis. Specifically, we use our normalized Hodge Laplacian to derive spectral embeddings for examining trajectory data of ocean drifters near Madagascar and also develop a generalization of personalized PageRank for the edge-space of simplicial complexes to analyze a book co-purchasing dataset.",
    "title": "Random Walks on Simplicial Complexes and the normalized Hodge 1-Laplacian"
  },
  {
    "arxiv": "1807.05127",
    "counts": {
      "ComplEx": 3,
      "DistMult": 1,
      "RESCAL": 1,
      "SE": 5
    },
    "published": "2018-07-13T15:15:41Z",
    "summary": "Extraction from raw text to a knowledge base of entities and fine-grained types is often cast as prediction into a flat set of entity and type labels, neglecting the rich hierarchies over types and entities contained in curated ontologies. Previous attempts to incorporate hierarchical structure have yielded little benefit and are restricted to shallow ontologies. This paper presents new methods using real and complex bilinear mappings for integrating hierarchical information, yielding substantial improvement over flat predictions in entity linking and fine-grained entity typing, and achieving new state-of-the-art results for end-to-end models on the benchmark FIGER dataset. We also present two new human-annotated datasets containing wide and deep hierarchies which we will release to the community to encourage further research in this direction: MedMentions, a collection of PubMed abstracts in which 246k mentions have been mapped to the massive UMLS ontology; and TypeNet, which aligns Freebase types with the WordNet hierarchy to obtain nearly 2k entity types. In experiments on all three datasets we show substantial gains from hierarchy-aware training.",
    "title": "Hierarchical Losses and New Resources for Fine-grained Entity Typing and Linking"
  },
  {
    "arxiv": "1807.07984",
    "counts": {
      "LINE": 1,
      "NAM": 1,
      "SE": 1,
      "metapath2vec": 1,
      "node2vec": 1
    },
    "published": "2018-07-20T18:11:07Z",
    "summary": "Graph-structured data arise naturally in many different application domains. By representing data as graphs, we can capture entities (i.e., nodes) as well as their relationships (i.e., edges) with each other. Many useful insights can be derived from graph-structured data as demonstrated by an ever-growing body of work focused on graph mining. However, in the real-world, graphs can be both large - with many complex patterns - and noisy which can pose a problem for effective graph mining. An effective way to deal with this issue is to incorporate \"attention\" into graph mining solutions. An attention mechanism allows a method to focus on task-relevant parts of the graph, helping it to make better decisions. In this work, we conduct a comprehensive and focused survey of the literature on the emerging field of graph attention models. We introduce three intuitive taxonomies to group existing work. These are based on problem setting (type of input and output), the type of attention mechanism used, and the task (e.g., graph classification, link prediction, etc.). We motivate our taxonomies through detailed examples and use each to survey competing approaches from a unique standpoint. Finally, we highlight several challenges in the area and discuss promising directions for future work.",
    "title": "Attention Models in Graphs: A Survey"
  },
  {
    "arxiv": "1807.10511",
    "counts": {
      "ConvE": 1,
      "MuRP": 1,
      "SE": 4,
      "SimplE": 1,
      "node2vec": 1
    },
    "published": "2018-07-27T09:45:04Z",
    "summary": "We focus our attention on the link prediction problem for knowledge graphs, which is treated herein as a binary classification task on neural embeddings of the entities. By comparing, combining and extending different methodologies for link prediction on graph-based data coming from different domains, we formalize a unified methodology for the quality evaluation benchmark of neural embeddings for knowledge graphs. This benchmark is then used to empirically investigate the potential of training neural embeddings globally for the entire graph, as opposed to the usual way of training embeddings locally for a specific relation. This new way of testing the quality of the embeddings evaluates the performance of binary classifiers for scalable link prediction with limited data. Our evaluation pipeline is made open source, and with this we aim to draw more attention of the community towards an important issue of transparency and reproducibility of the neural embeddings evaluations.",
    "title": "Global and local evaluation of link prediction tasks with neural embeddings"
  },
  {
    "arxiv": "1808.02590",
    "counts": {
      "LINE": 1,
      "SDNE": 1,
      "SE": 1,
      "metapath2vec": 1,
      "node2vec": 1
    },
    "published": "2018-08-08T00:54:01Z",
    "summary": "Network embedding methods aim at learning low-dimensional latent representation of nodes in a network. These representations can be used as features for a wide range of tasks on graphs such as classification, clustering, link prediction, and visualization. In this survey, we give an overview of network embeddings by summarizing and categorizing recent advancements in this research field. We first discuss the desirable properties of network embeddings and briefly introduce the history of network embedding algorithms. Then, we discuss network embedding methods under different scenarios, such as supervised versus unsupervised learning, learning embeddings for homogeneous networks versus for heterogeneous networks, etc. We further demonstrate the applications of network embeddings, and conclude the survey with future work in this area.",
    "title": "A Tutorial on Network Embeddings"
  },
  {
    "arxiv": "1808.06354",
    "counts": {
      "GraphSAGE": 1,
      "NAM": 1,
      "SE": 5
    },
    "published": "2018-08-20T09:13:53Z",
    "summary": "Due to the fact much of today's data can be represented as graphs, there has been a demand for generalizing neural network models for graph data. One recent direction that has shown fruitful results, and therefore growing interest, is the usage of graph convolutional neural networks (GCNs). They have been shown to provide a significant improvement on a wide range of tasks in network analysis, one of which being node representation learning. The task of learning low-dimensional node representations has shown to increase performance on a plethora of other tasks from link prediction and node classification, to community detection and visualization. Simultaneously, signed networks (or graphs having both positive and negative links) have become ubiquitous with the growing popularity of social media. However, since previous GCN models have primarily focused on unsigned networks (or graphs consisting of only positive links), it is unclear how they could be applied to signed networks due to the challenges presented by negative links. The primary challenges are based on negative links having not only a different semantic meaning as compared to positive links, but their principles are inherently different and they form complex relations with positive links. Therefore we propose a dedicated and principled effort that utilizes balance theory to correctly aggregate and propagate the information across layers of a signed GCN model. We perform empirical experiments comparing our proposed signed GCN against state-of-the-art baselines for learning node representations in signed networks. More specifically, our experiments are performed on four real-world datasets for the classical link sign prediction problem that is commonly used as the benchmark for signed network embeddings algorithms.",
    "title": "Signed Graph Convolutional Network"
  },
  {
    "arxiv": "1808.06560",
    "counts": {
      "RatE": 1,
      "SE": 1,
      "SimplE": 1,
      "TuckER": 1
    },
    "published": "2018-08-20T16:40:35Z",
    "summary": "Real-world data sets often provide multiple types of information about the same set of entities. This data is well represented by multi-view graphs, which consist of several distinct sets of edges over the same nodes. These can be used to analyze how entities interact from different viewpoints. Combining multiple views improves the quality of inferences drawn from the underlying data, which has increased interest in developing efficient multi-view graph embedding methods. We propose an algorithm, C-RSP, that generates a common (C) embedding of a multi-view graph using Randomized Shortest Paths (RSP). This algorithm generates a dissimilarity measure between nodes by minimizing the expected cost of a random walk between any two nodes across all views of a multi-view graph, in doing so encoding both the local and global structure of the graph. We test C-RSP on both real and synthetic data and show that it outperforms benchmark algorithms at embedding and clustering tasks while remaining computationally efficient.",
    "title": "Multi-View Graph Embedding Using Randomized Shortest Paths"
  },
  {
    "arxiv": "1808.06619",
    "counts": {
      "ComplEx": 1,
      "GeomE": 1,
      "LINE": 1,
      "ProjE": 1,
      "SE": 1
    },
    "published": "2018-08-20T18:00:06Z",
    "summary": "Many materials crystallize in structure types that feature a square-net of atoms. While these compounds can exhibit many different properties, some members of this family are topological materials. Within the square-net-based topological materials, the observed properties are rich, ranging for example from nodal-line semimetals to a bulk half-integer quantum Hall effect. Hence, the potential for guided design of topological properties is enormous. Here we provide an overview of the crystallographic and electronic properties of these phases and show how they are linked, with the goal of understanding which square-net materials can be topological, and to predict additional examples. We close the review by discussing the experimentally observed electronic properties in this family.",
    "title": "Topological Semimetals in Square-Net Materials"
  },
  {
    "arxiv": "1808.07712",
    "counts": {
      "LINE": 1,
      "NAM": 2,
      "SE": 3
    },
    "published": "2018-08-23T12:11:06Z",
    "summary": "In this work, we present a method to predict an entire `action tube' (a set of temporally linked bounding boxes) in a trimmed video just by observing a smaller subset of it. Predicting where an action is going to take place in the near future is essential to many computer vision based applications such as autonomous driving or surgical robotics. Importantly, it has to be done in real-time and in an online fashion. We propose a Tube Prediction network (TPnet) which jointly predicts the past, present and future bounding boxes along with their action classification scores. At test time TPnet is used in a (temporal) sliding window setting, and its predictions are put into a tube estimation framework to construct/predict the video long action tubes not only for the observed part of the video but also for the unobserved part. Additionally, the proposed action tube predictor helps in completing action tubes for unobserved segments of the video. We quantitatively demonstrate the latter ability, and the fact that TPnet improves state-of-the-art detection performance, on one of the standard action detection benchmarks - J-HMDB-21 dataset.",
    "title": "Predicting Action Tubes"
  },
  {
    "arxiv": "1809.05912",
    "counts": {
      "ComplEx": 1,
      "SE": 1,
      "TransF": 1
    },
    "published": "2018-09-16T16:56:14Z",
    "summary": "In social networks, by removing some target-sensitive links, privacy protection might be achieved. However, some hidden links can still be re-observed by link prediction methods on observable networks. In this paper, the conventional link prediction method named Resource Allocation Index (RA) is adopted for privacy attacks. Several defense methods are proposed, including heuristic and evolutionary approaches, to protect targeted links from RA attacks via evolutionary perturbations. This is the first time to study privacy protection on targeted links against link-prediction-based attacks. Some links are randomly selected from the network as targeted links for experimentation. The simulation results on six real-world networks demonstrate the superiority of the evolutionary perturbation approach for target defense against RA attacks. Moreover, transferring experiments show that, although the evolutionary perturbation approach is designed to against RA attacks, it is also effective against other link-prediction-based attacks.",
    "title": "Target Defense Against Link-Prediction-Based Attacks via Evolutionary Perturbations"
  },
  {
    "arxiv": "1809.08472",
    "counts": {
      "ComplEx": 1,
      "HypER": 1,
      "LINE": 1,
      "SE": 1
    },
    "published": "2018-09-22T18:48:52Z",
    "summary": "In this survey, we have attempted to show some developmental milestones on the characterizations of intersection graphs of hypergraphs. The theory of intersection graphs of hypergraphs has been a classical topic in the theory of special graphs. To conclude, at the end, we have listed some open problems posed by various authors whose work has contributed to this survey and also the new trends coming out of intersection graphs. Keywords: Hypergraphs, Intersection graphs, Line graphs, Representative graphs, Derived graphs, Algorithms (ALG), Forbidden induced subgraphs (FIS), Krausz partitions, Eigenvalues.",
    "title": "On Intersection Graphs of Graphs and Hypergraphs: A Survey"
  },
  {
    "arxiv": "1810.00717",
    "counts": {
      "ComplEx": 3,
      "ConvE": 1,
      "LINE": 1,
      "RotH": 1,
      "SE": 10
    },
    "published": "2018-10-01T14:21:33Z",
    "summary": "Link prediction in a graph is the problem of detecting the missing links that would be formed in the near future. Using a graph representation of the data, we can convert the problem of classification to the problem of link prediction which aims at finding the missing links between the unlabeled data (unlabeled nodes) and their classes. To our knowledge, despite the fact that numerous algorithms use the graph representation of the data for classification, none are using link prediction as the heart of their classifying procedure. In this work, we propose a novel algorithm called CULP (Classification Using Link Prediction) which uses a new structure namely Label Embedded Graph or LEG and a link predictor to find the class of the unlabeled data. Different link predictors along with Compatibility Score - a new link predictor we proposed that is designed specifically for our settings - has been used and showed promising results for classifying different datasets. This paper further improved CULP by designing an extension called CULM which uses a majority vote (hence the M in the acronym) procedure with weights proportional to the predictions' confidences to use the predictive power of multiple link predictors and also exploits the low level features of the data. Extensive experimental evaluations shows that both CULP and CULM are highly accurate and competitive with the cutting edge graph classifiers and general classifiers.",
    "title": "Classification Using Link Prediction"
  },
  {
    "arxiv": "1811.01287",
    "counts": {
      "ConvE": 1,
      "GraphSAGE": 1,
      "SE": 1
    },
    "published": "2018-11-03T21:39:43Z",
    "summary": "Recent advances in representation learning on graphs, mainly leveraging graph convolutional networks, have brought a substantial improvement on many graph-based benchmark tasks. While novel approaches to learning node embeddings are highly suitable for node classification and link prediction, their application to graph classification (predicting a single label for the entire graph) remains mostly rudimentary, typically using a single global pooling step to aggregate node features or a hand-designed, fixed heuristic for hierarchical coarsening of the graph structure. An important step towards ameliorating this is differentiable graph coarsening---the ability to reduce the size of the graph in an adaptive, data-dependent manner within a graph neural network pipeline, analogous to image downsampling within CNNs. However, the previous prominent approach to pooling has quadratic memory requirements during training and is therefore not scalable to large graphs. Here we combine several recent advances in graph neural network design to demonstrate that competitive hierarchical graph classification results are possible without sacrificing sparsity. Our results are verified on several established graph classification benchmarks, and highlight an important direction for future research in graph-based neural networks.",
    "title": "Towards Sparse Hierarchical Graph Classifiers"
  },
  {
    "arxiv": "1811.02798",
    "counts": {
      "HypER": 1,
      "NAM": 1,
      "RatE": 1,
      "SDNE": 1,
      "SE": 1,
      "TransF": 1
    },
    "published": "2018-11-07T08:27:52Z",
    "summary": "We examine two fundamental tasks associated with graph representation learning: link prediction and node classification. We present a new autoencoder architecture capable of learning a joint representation of local graph structure and available node features for the simultaneous multi-task learning of unsupervised link prediction and semi-supervised node classification. Our simple, yet effective and versatile model is efficiently trained end-to-end in a single stage, whereas previous related deep graph embedding methods require multiple training steps that are difficult to optimize. We provide an empirical evaluation of our model on five benchmark relational, graph-structured datasets and demonstrate significant improvement over three strong baselines for graph representation learning. Reference code and data are available at https://github.com/vuptran/graph-representation-learning",
    "title": "Multi-Task Graph Autoencoders"
  },
  {
    "arxiv": "1811.03508",
    "counts": {
      "ComplEx": 1,
      "GraphSAGE": 1,
      "HypER": 1,
      "LINE": 1,
      "SE": 1,
      "SimplE": 1
    },
    "published": "2018-11-08T15:53:37Z",
    "summary": "Graphs are complex objects that do not lend themselves easily to typical learning tasks. Recently, a range of approaches based on graph kernels or graph neural networks have been developed for graph classification and for representation learning on graphs in general. As the developed methodologies become more sophisticated, it is important to understand which components of the increasingly complex methods are necessary or most effective. As a first step, we develop a simple yet meaningful graph representation, and explore its effectiveness in graph classification. We test our baseline representation for the graph classification task on a range of graph datasets. Interestingly, this simple representation achieves similar performance as the state-of-the-art graph kernels and graph neural networks for non-attributed graph classification. Its performance on classifying attributed graphs is slightly weaker as it does not incorporate attributes. However, given its simplicity and efficiency, we believe that it still serves as an effective baseline for attributed graph classification. Our graph representation is efficient (linear-time) to compute. We also provide a simple connection with the graph neural networks. Note that these observations are only for the task of graph classification while existing methods are often designed for a broader scope including node embedding and link prediction. The results are also likely biased due to the limited amount of benchmark datasets available. Nevertheless, the good performance of our simple baseline calls for the development of new, more comprehensive benchmark datasets so as to better evaluate and analyze different graph learning methods. Furthermore, given the computational efficiency of our graph summary, we believe that it is a good candidate as a baseline method for future graph classification (or even other graph learning) studies.",
    "title": "A simple yet effective baseline for non-attributed graph classification"
  },
  {
    "arxiv": "1812.04206",
    "counts": {
      "GeomE": 1,
      "LINE": 1,
      "NAM": 1,
      "ProjE": 1,
      "RatE": 1,
      "SE": 1,
      "TACT": 1,
      "node2vec": 1
    },
    "published": "2018-12-11T03:38:52Z",
    "summary": "Dynamic link prediction is a research hot in complex networks area, especially for its wide applications in biology, social network, economy and industry. Compared with static link prediction, dynamic one is much more difficult since network structure evolves over time. Currently most researches focus on static link prediction which cannot achieve expected performance in dynamic network. Aiming at low AUC, high Error Rate, add/remove link prediction difficulty, we propose GC-LSTM, a Graph Convolution Network (GC) embedded Long Short Term Memory network (LTSM), for end-to-end dynamic link prediction. To the best of our knowledge, it is the first time that GCN embedded LSTM is put forward for link prediction of dynamic networks. GCN in this new deep model is capable of node structure learning of network snapshot for each time slide, while LSTM is responsible for temporal feature learning for network snapshot. Besides, current dynamic link prediction method can only handle removed links, GC-LSTM can predict both added or removed link at the same time. Extensive experiments are carried out to testify its performance in aspects of prediction accuracy, Error Rate, add/remove link prediction and key link prediction. The results prove that GC-LSTM outperforms current state-of-art method.",
    "title": "GC-LSTM: Graph Convolution Embedded LSTM for Dynamic Link Prediction"
  },
  {
    "arxiv": "1902.04528",
    "counts": {
      "SE": 1,
      "SimplE": 1,
      "TransF": 1
    },
    "published": "2019-02-12T18:09:53Z",
    "summary": "The richness that characterizes relationships is often absent when they are modeled using computational methods in network science. Typically, relationships are represented simply as links, perhaps with weights. The lack of finer granularity is due in part to the fact that, aside from linkage and strength, no fundamental or immediately obvious dimensions exist along which to categorize relationships. Here we propose a set of dimensions that capture major components of many relationships -- derived both from relevant academic literature and people's everyday descriptions of their relationships. We first review prominent findings in sociology and social psychology, highlighting dimensions that have been widely used to categorize social relationships. Next, we examine the validity of these dimensions empirically in two crowd-sourced experiments. Ultimately, we arrive at a set of ten major dimensions that can be used to categorize relationships: similarity, trust, romance, social support, identity, respect, knowledge exchange, power, fun, and conflict. These ten dimensions, while not dispositive, offer higher resolution than existing models. Indeed, we show that one can more accurately predict missing links in a social graph by using these dimensions than by using a state-of-the-art link embeddedness method. We also describe tinghy.org, an online platform we built to collect data about how social media users perceive their online relationships, allowing us to examine these dimensions at scale. Overall, by proposing a new way of modeling social graphs, our work aims to contribute both to theory in network science and practice in the design of social-networking applications.",
    "title": "Coloring in the Links: Capturing Social Ties as They are Perceived"
  },
  {
    "arxiv": "1902.08329",
    "counts": {
      "ConvE": 1,
      "GeomE": 1,
      "LINE": 1,
      "ProjE": 1,
      "RatE": 1,
      "SDNE": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2019-02-22T01:40:51Z",
    "summary": "Predicting the potential relations between nodes in networks, known as link prediction, has long been a challenge in network science. However, most studies just focused on link prediction of static network, while real-world networks always evolve over time with the occurrence and vanishing of nodes and links. Dynamic network link prediction thus has been attracting more and more attention since it can better capture the evolution nature of networks, but still most algorithms fail to achieve satisfied prediction accuracy. Motivated by the excellent performance of Long Short-Term Memory (LSTM) in processing time series, in this paper, we propose a novel Encoder-LSTM-Decoder (E-LSTM-D) deep learning model to predict dynamic links end to end. It could handle long term prediction problems, and suits the networks of different scales with fine-tuned structure. To the best of our knowledge, it is the first time that LSTM, together with an encoder-decoder architecture, is applied to link prediction in dynamic networks. This new model is able to automatically learn structural and temporal features in a unified framework, which can predict the links that never appear in the network before. The extensive experiments show that our E-LSTM-D model significantly outperforms newly proposed dynamic network link prediction methods and obtain the state-of-the-art results.",
    "title": "E-LSTM-D: A Deep Learning Framework for Dynamic Network Link Prediction"
  },
  {
    "arxiv": "1902.10837",
    "counts": {
      "ConvE": 1,
      "HypER": 1,
      "NAM": 1,
      "ProjE": 1,
      "SE": 1
    },
    "published": "2019-02-27T23:59:02Z",
    "summary": "The total mass of a galaxy cluster is one of its most fundamental properties. Together with the redshift, the mass links observation and theory, allowing us to use the cluster population to test models of structure formation and to constrain cosmological parameters. Building on the rich heritage from X-ray surveys, new results from Sunyaev-Zeldovich and optical surveys have stimulated a resurgence of interest in cluster cosmology. These studies have generally found fewer clusters than predicted by the baseline Planck LCDM model, prompting a renewed effort on the part of the community to obtain a definitive measure of the true cluster mass scale. Here we review recent progress on this front. Our theoretical understanding continues to advance, with numerical simulations being the cornerstone of this effort. On the observational side, new, sophisticated techniques are being deployed in individual mass measurements and to account for selection biases in cluster surveys. We summarise the state of the art in cluster mass estimation methods and the systematic uncertainties and biases inherent in each approach, which are now well identified and understood, and explore how current uncertainties propagate into the cosmological parameter analysis. We discuss the prospects for improvements to the measurement of the mass scale using upcoming multi-wavelength data, and the future use of the cluster population as a cosmological probe.",
    "title": "The galaxy cluster mass scale and its impact on cosmological constraints from the cluster population"
  },
  {
    "arxiv": "1903.02125",
    "counts": {
      "ComplEx": 1,
      "HypER": 1,
      "NAM": 1,
      "SE": 1
    },
    "published": "2019-03-06T00:22:21Z",
    "summary": "Predicting signed links in social networks often faces the problem of signed link data sparsity, i.e., only a small percentage of signed links are given. The problem is exacerbated when the number of negative links is much smaller than that of positive links. Boosting signed link prediction necessitates additional information to compensate for data sparsity. According to psychology theories, one rich source of such information is user's personality such as optimism and pessimism that can help determine her propensity in establishing positive and negative links. In this study, we investigate how personality information can be obtained, and if personality information can help alleviate the data sparsity problem for signed link prediction. We propose a novel signed link prediction model that enables empirical exploration of user personality via social media data. We evaluate our proposed model on two datasets of real-world signed link networks. The results demonstrate the complementary role of personality information in the signed link prediction problem. Experimental results also indicate the effectiveness of different levels of personality information for signed link data sparsity problem.",
    "title": "Signed Link Prediction with Sparse Data: The Role of Personality Information"
  },
  {
    "arxiv": "1903.04477",
    "counts": {
      "HypER": 1,
      "LINE": 1,
      "NAM": 1,
      "NagE": 1,
      "SE": 1
    },
    "published": "2019-03-11T17:53:47Z",
    "summary": "The Levine-Tristram signature associates to each oriented link $L$ in $S^3$ a function $\\sigma_L \\colon S^1 \\to \\mathbb{Z}.$ This invariant can be defined in a variety of ways, and its numerous applications include the study of unlinking numbers and link concordance. In this survey, we recall the three and four dimensional definitions of $\\sigma_L$, list its main properties and applications, and give comprehensive references for the proofs of these statements.",
    "title": "The Levine-Tristram signature: a survey"
  },
  {
    "arxiv": "1903.08810",
    "counts": {
      "ANALOGY": 1,
      "ComplEx": 1,
      "ConvE": 1,
      "GeomE": 1,
      "HypER": 1,
      "ProjE": 1,
      "RotH": 1,
      "SE": 1,
      "SME": 1
    },
    "published": "2019-03-21T02:35:33Z",
    "summary": "Link prediction is a paradigmatic problem in network science with a variety of applications. In latent space network models this problem boils down to ranking pairs of nodes in the order of increasing latent distances between them. The network model with hyperbolic latent spaces has a number of attractive properties suggesting it must be a powerful tool to predict links, but the past work in this direction reported mixed results. Here we perform systematic investigation of the utility of latent hyperbolic geometry for link prediction in networks. We first show that some measures of link prediction accuracy are extremely sensitive with respect to inaccuracies in the inference of latent hyperbolic coordinates of nodes, so that we develop a new coordinate inference method that maximizes the accuracy of such inference. Applying this method to synthetic and real networks, we then find that while there exists a multitude of competitive methods to predict obvious easy-to-predict links, among which hyperbolic link prediction is rarely the best but often competitive, it is the best, often by far, when the task is to predict less obvious missing links that are really hard to predict. These links include missing links in incomplete networks with large fractions of missing links, missing links between nodes that do not have any common neighbors, and missing links between dissimilar nodes at large latent distances. Overall these results suggest that the harder a specific link prediction task is, the more seriously one should consider using hyperbolic geometry.",
    "title": "Link prediction with hyperbolic geometry"
  },
  {
    "arxiv": "1903.11406",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "ER-MLP": 1,
      "NTN": 1,
      "QuatE": 1,
      "RESCAL": 1,
      "SE": 2,
      "TransA": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2019-03-27T13:09:16Z",
    "summary": "Knowledge graph is a popular format for representing knowledge, with many applications to semantic search engines, question-answering systems, and recommender systems. Real-world knowledge graphs are usually incomplete, so knowledge graph embedding methods, such as Canonical decomposition/Parallel factorization (CP), DistMult, and ComplEx, have been proposed to address this issue. These methods represent entities and relations as embedding vectors in semantic space and predict the links between them. The embedding vectors themselves contain rich semantic information and can be used in other applications such as data analysis. However, mechanisms in these models and the embedding vectors themselves vary greatly, making it difficult to understand and compare them. Given this lack of understanding, we risk using them ineffectively or incorrectly, particularly for complicated models, such as CP, with two role-based embedding vectors, or the state-of-the-art ComplEx model, with complex-valued embedding vectors. In this paper, we propose a multi-embedding interaction mechanism as a new approach to uniting and generalizing these models. We derive them theoretically via this mechanism and provide empirical analyses and comparisons between them. We also propose a new multi-embedding model based on quaternion algebra and show that it achieves promising results using popular benchmarks. Source code is available on github at https://github.com/tranhungnghiep/AnalyzingKGEmbeddings",
    "title": "Analyzing Knowledge Graph Embedding Methods from a Multi-Embedding Interaction Perspective"
  },
  {
    "arxiv": "1904.06491",
    "counts": {
      "GeomE": 1,
      "LINE": 1,
      "NAM": 1,
      "SE": 1,
      "TransF": 1
    },
    "published": "2019-04-13T06:37:34Z",
    "summary": "A brain can detect outlier just by using only normal samples. Similarly, one-class classification (OCC) also uses only normal samples to train the model and trained model can be used for outlier detection. In this paper, a multi-layer architecture for OCC is proposed by stacking various Graph-Embedded Kernel Ridge Regression (KRR) based Auto-Encoders in a hierarchical fashion. These Auto-Encoders are formulated under two types of Graph-Embedding, namely, local and global variance-based embedding. This Graph-Embedding explores the relationship between samples and multi-layers of Auto-Encoder project the input features into new feature space. The last layer of this proposed architecture is Graph-Embedded regression-based one-class classifier. The Auto-Encoders use an unsupervised approach of learning and the final layer uses semi-supervised (trained by only positive samples and obtained closed-form solution) approach to learning. The proposed method is experimentally evaluated on 21 publicly available benchmark datasets. Experimental results verify the effectiveness of the proposed one-class classifiers over 11 existing state-of-the-art kernel-based one-class classifiers. Friedman test is also performed to verify the statistical significance of the claim of the superiority of the proposed one-class classifiers over the existing state-of-the-art methods. By using two types of Graph-Embedding, 4 variants of Graph-Embedded multi-layer KRR-based one-class classifier has been presented in this paper. All 4 variants performed better than the existing one-class classifiers in terms of various discussed criteria in this paper. Hence, it can be a viable alternative for OCC task. In the future, various other types of Auto-Encoders can be explored within proposed architecture.",
    "title": "Graph-Embedded Multi-layer Kernel Extreme Learning Machine for One-class Classification or (Graph-Embedded Multi-layer Kernel Ridge Regression for One-class Classification)"
  },
  {
    "arxiv": "1904.12052",
    "counts": {
      "ComplEx": 2,
      "DistMult": 2,
      "RESCAL": 2,
      "SE": 3,
      "TransA": 2,
      "TransD": 2,
      "TransE": 2,
      "TransF": 2,
      "TransH": 2,
      "TransR": 2
    },
    "published": "2019-04-26T21:12:19Z",
    "summary": "Knowledge graph embedding (KGE) is a technique for learning continuous embeddings for entities and relations in the knowledge graph.Due to its benefit to a variety of downstream tasks such as knowledge graph completion, question answering and recommendation, KGE has gained significant attention recently. Despite its effectiveness in a benign environment, KGE' robustness to adversarial attacks is not well-studied. Existing attack methods on graph data cannot be directly applied to attack the embeddings of knowledge graph due to its heterogeneity. To fill this gap, we propose a collection of data poisoning attack strategies, which can effectively manipulate the plausibility of arbitrary targeted facts in a knowledge graph by adding or deleting facts on the graph. The effectiveness and efficiency of the proposed attack strategies are verified by extensive evaluations on two widely-used benchmarks.",
    "title": "Data Poisoning Attack against Knowledge Graph Embedding"
  },
  {
    "arxiv": "1904.12211",
    "counts": {
      "ComplEx": 1,
      "DistMult": 1,
      "SE": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2019-04-27T20:40:03Z",
    "summary": "Knowledge graphs (KGs), i.e. representation of information as a semantic graph, provide a significant test bed for many tasks including question answering, recommendation, and link prediction. Various amount of scholarly metadata have been made vailable as knowledge graphs from the diversity of data providers and agents. However, these high-quantities of data remain far from quality criteria in terms of completeness while growing at a rapid pace. Most of the attempts in completing such KGs are following traditional data digitization, harvesting and collaborative curation approaches. Whereas, advanced AI-related approaches such as embedding models - specifically designed for such tasks - are usually evaluated for standard benchmarks such as Freebase and Wordnet. The tailored nature of such datasets prevents those approaches to shed the lights on more accurate discoveries. Application of such models on domain-specific KGs takes advantage of enriched meta-data and provides accurate results where the underlying domain can enormously benefit. In this work, the TransE embedding model is reconciled for a specific link prediction task on scholarly metadata. The results show a significant shift in the accuracy and performance evaluation of the model on a dataset with scholarly metadata. The newly proposed version of TransE obtains 99.9% for link prediction task while original TransE gets 95%. In terms of accuracy and Hit@10, TransE outperforms other embedding models such as ComplEx, TransH and TransR experimented over scholarly knowledge graphs",
    "title": "Soft Marginal TransE for Scholarly Knowledge Graph Completion"
  },
  {
    "arxiv": "1904.12694",
    "counts": {
      "ConvE": 1,
      "LINE": 2,
      "NAM": 1,
      "SE": 3,
      "node2vec": 2
    },
    "published": "2019-04-22T08:38:02Z",
    "summary": "Networks are powerful data structures, but are challenging to work with for conventional machine learning methods. Network Embedding (NE) methods attempt to resolve this by learning vector representations for the nodes, for subsequent use in downstream machine learning tasks. Link Prediction (LP) is one such downstream machine learning task that is an important use case and popular benchmark for NE methods. Unfortunately, while NE methods perform exceedingly well at this task, they are lacking in transparency as compared to simpler LP approaches. We introduce ExplaiNE, an approach to offer counterfactual explanations for NE-based LP methods, by identifying existing links in the network that explain the predicted links. ExplaiNE is applicable to a broad class of NE algorithms. An extensive empirical evaluation for the NE method `Conditional Network Embedding' in particular demonstrates its accuracy and scalability.",
    "title": "ExplaiNE: An Approach for Explaining Network Embedding-based Link Predictions"
  },
  {
    "arxiv": "1905.08108",
    "counts": {
      "ComplEx": 1,
      "GraphSAGE": 4,
      "SE": 5,
      "TransA": 1,
      "TransR": 2,
      "node2vec": 1
    },
    "published": "2019-05-20T13:41:16Z",
    "summary": "Learning vector representations (aka. embeddings) of users and items lies at the core of modern recommender systems. Ranging from early matrix factorization to recently emerged deep learning based methods, existing efforts typically obtain a user's (or an item's) embedding by mapping from pre-existing features that describe the user (or the item), such as ID and attributes. We argue that an inherent drawback of such methods is that, the collaborative signal, which is latent in user-item interactions, is not encoded in the embedding process. As such, the resultant embeddings may not be sufficient to capture the collaborative filtering effect. In this work, we propose to integrate the user-item interactions -- more specifically the bipartite graph structure -- into the embedding process. We develop a new recommendation framework Neural Graph Collaborative Filtering (NGCF), which exploits the user-item graph structure by propagating embeddings on it. This leads to the expressive modeling of high-order connectivity in user-item graph, effectively injecting the collaborative signal into the embedding process in an explicit manner. We conduct extensive experiments on three public benchmarks, demonstrating significant improvements over several state-of-the-art models like HOP-Rec and Collaborative Memory Network. Further analysis verifies the importance of embedding propagation for learning better user and item representations, justifying the rationality and effectiveness of NGCF. Codes are available at https://github.com/xiangwang1223/neural_graph_collaborative_filtering.",
    "title": "Neural Graph Collaborative Filtering"
  },
  {
    "arxiv": "1905.08900",
    "counts": {
      "ConvE": 1,
      "LINE": 1,
      "NAM": 1,
      "SE": 1
    },
    "published": "2019-05-21T23:31:45Z",
    "summary": "We present a novel method named Latent Semantic Imputation (LSI) to transfer external knowledge into semantic space for enhancing word embedding. The method integrates graph theory to extract the latent manifold structure of the entities in the affinity space and leverages non-negative least squares with standard simplex constraints and power iteration method to derive spectral embeddings. It provides an effective and efficient approach to combining entity representations defined in different Euclidean spaces. Specifically, our approach generates and imputes reliable embedding vectors for low-frequency words in the semantic space and benefits downstream language tasks that depend on word embedding. We conduct comprehensive experiments on a carefully designed classification problem and language modeling and demonstrate the superiority of the enhanced embedding via LSI over several well-known benchmark embeddings. We also confirm the consistency of the results under different parameter settings of our method.",
    "title": "Enhancing Domain Word Embedding via Latent Semantic Imputation"
  },
  {
    "arxiv": "1905.10674",
    "counts": {
      "ComplEx": 1,
      "RESCAL": 1,
      "SE": 4,
      "TransD": 3,
      "TransE": 2,
      "node2vec": 1
    },
    "published": "2019-05-25T21:13:27Z",
    "summary": "Learning high-quality node embeddings is a key building block for machine learning models that operate on graph data, such as social networks and recommender systems. However, existing graph embedding techniques are unable to cope with fairness constraints, e.g., ensuring that the learned representations do not correlate with certain attributes, such as age or gender. Here, we introduce an adversarial framework to enforce fairness constraints on graph embeddings. Our approach is compositional---meaning that it can flexibly accommodate different combinations of fairness constraints during inference. For instance, in the context of social recommendations, our framework would allow one user to request that their recommendations are invariant to both their age and gender, while also allowing another user to request invariance to just their age. Experiments on standard knowledge graph and recommender system benchmarks highlight the utility of our proposed framework.",
    "title": "Compositional Fairness Constraints for Graph Embeddings"
  },
  {
    "arxiv": "1905.11691",
    "counts": {
      "5*": 1,
      "LINE": 1,
      "SE": 1,
      "TransE": 1,
      "metapath2vec": 1,
      "node2vec": 1
    },
    "published": "2019-05-28T09:11:12Z",
    "summary": "Graph embedding techniques allow to learn high-quality feature vectors from graph structures and are useful in a variety of tasks, from node classification to clustering. Existing approaches have only focused on learning feature vectors for the nodes in a (knowledge) graph. To the best of our knowledge, none of them has tackled the problem of embedding of graph edges, that is, knowledge graph triples. The approaches that are closer to this task have focused on homogeneous graphs involving only one type of edge and obtain edge embeddings by applying some operation (e.g., average) on the embeddings of the endpoint nodes. The goal of this paper is to introduce Triple2Vec, a new technique to directly embed edges in (knowledge) graphs. Trple2Vec builds upon three main ingredients. The first is the notion of line graph. The line graph of a graph is another graph representing the adjacency between edges of the original graph. In particular, the nodes of the line graph are the edges of the original graph. We show that directly applying existing embedding techniques on the nodes of the line graph to learn edge embeddings is not enough in the context of knowledge graphs. Thus, we introduce the notion of triple line graph. The second is an edge weighting mechanism both for line graphs derived from knowledge graphs and homogeneous graphs. The third is a strategy based on graph walks on the weighted triple line graph that can preserve proximity between nodes. Embeddings are finally generated by adopting the SkipGram model, where sentences are replaced with graph walks. We evaluate our approach on different real world (knowledge) graphs and compared it with related work.",
    "title": "Triple2Vec: Learning Triple Embeddings from Knowledge Graphs"
  },
  {
    "arxiv": "1905.13129",
    "counts": {
      "GraphSAGE": 1,
      "R-GCN": 1,
      "SE": 1,
      "TransD": 1
    },
    "published": "2019-05-27T12:21:33Z",
    "summary": "We propose a new STAcked and Reconstructed Graph Convolutional Networks (STAR-GCN) architecture to learn node representations for boosting the performance in recommender systems, especially in the cold start scenario. STAR-GCN employs a stack of GCN encoder-decoders combined with intermediate supervision to improve the final prediction performance. Unlike the graph convolutional matrix completion model with one-hot encoding node inputs, our STAR-GCN learns low-dimensional user and item latent factors as the input to restrain the model space complexity. Moreover, our STAR-GCN can produce node embeddings for new nodes by reconstructing masked input node embeddings, which essentially tackles the cold start problem. Furthermore, we discover a label leakage issue when training GCN-based models for link prediction tasks and propose a training strategy to avoid the issue. Empirical results on multiple rating prediction benchmarks demonstrate our model achieves state-of-the-art performance in four out of five real-world datasets and significant improvements in predicting ratings in the cold start scenario. The code implementation is available in https://github.com/jennyzhang0215/STAR-GCN.",
    "title": "STAR-GCN: Stacked and Reconstructed Graph Convolutional Networks for Recommender Systems"
  },
  {
    "arxiv": "1905.13649",
    "counts": {
      "LINE": 1,
      "NAM": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2019-05-31T14:49:30Z",
    "summary": "Online reviews play a crucial role in deciding the quality before purchasing any product. Unfortunately, spammers often take advantage of online review forums by writing fraud reviews to promote/demote certain products. It may turn out to be more detrimental when such spammers collude and collectively inject spam reviews as they can take complete control of users' sentiment due to the volume of fraud reviews they inject. Group spam detection is thus more challenging than individual-level fraud detection due to unclear definition of a group, variation of inter-group dynamics, scarcity of labeled group-level spam data, etc. Here, we propose DeFrauder, an unsupervised method to detect online fraud reviewer groups. It first detects candidate fraud groups by leveraging the underlying product review graph and incorporating several behavioral signals which model multi-faceted collaboration among reviewers. It then maps reviewers into an embedding space and assigns a spam score to each group such that groups comprising spammers with highly similar behavioral traits achieve high spam score. While comparing with five baselines on four real-world datasets (two of them were curated by us), DeFrauder shows superior performance by outperforming the best baseline with 17.11% higher NDCG@50 (on average) across datasets.",
    "title": "Spotting Collective Behaviour of Online Frauds in Customer Reviews"
  },
  {
    "arxiv": "1906.00120",
    "counts": {
      "LINE": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2019-05-31T23:49:34Z",
    "summary": "Consensus clustering fuses diverse basic partitions (i.e., clustering results obtained from conventional clustering methods) into an integrated one, which has attracted increasing attention in both academic and industrial areas due to its robust and effective performance. Tremendous research efforts have been made to thrive this domain in terms of algorithms and applications. Although there are some survey papers to summarize the existing literature, they neglect to explore the underlying connection among different categories. Differently, in this paper we aim to provide an embedding prospective to illustrate the consensus mechanism, which transfers categorical basic partitions to other representations (e.g., binary coding, spectral embedding, etc) for the clustering purpose. To this end, we not only unify two major categories of consensus clustering, but also build an intuitive connection between consensus clustering and graph embedding. Moreover, we elaborate several extensions of classical consensus clustering from different settings and problems. Beyond this, we demonstrate how to leverage consensus clustering to address other tasks, such as constrained clustering, domain adaptation, feature selection, and outlier detection. Finally, we conclude this survey with future work in terms of interpretability, learnability and theoretical analysis.",
    "title": "Consensus Clustering: An Embedding Perspective, Extension and Beyond"
  },
  {
    "arxiv": "1906.00137",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "HypER": 1,
      "MuRP": 1,
      "SE": 1,
      "SimplE": 1,
      "TransE": 1,
      "TransH": 1
    },
    "published": "2019-06-01T03:03:15Z",
    "summary": "Knowledge graphs store facts using relations between two entities. In this work, we address the question of link prediction in knowledge hypergraphs where relations are defined on any number of entities. While techniques exist (such as reification) that convert non-binary relations into binary ones, we show that current embedding-based methods for knowledge graph completion do not work well out of the box for knowledge graphs obtained through these techniques. To overcome this, we introduce HSimplE and HypE, two embedding-based methods that work directly with knowledge hypergraphs. In both models, the prediction is a function of the relation embedding, the entity embeddings and their corresponding positions in the relation. We also develop public datasets, benchmarks and baselines for hypergraph prediction and show experimentally that the proposed models are more effective than the baselines.",
    "title": "Knowledge Hypergraphs: Prediction Beyond Binary Relations"
  },
  {
    "arxiv": "1906.12330",
    "counts": {
      "DistMult": 1,
      "SE": 1,
      "TransF": 1
    },
    "published": "2019-06-21T03:05:17Z",
    "summary": "In this work, we present graph star net (GraphStar), a novel and unified graph neural net architecture which utilizes message-passing relay and attention mechanism for multiple prediction tasks - node classification, graph classification and link prediction. GraphStar addresses many earlier challenges facing graph neural nets and achieves non-local representation without increasing the model depth or bearing heavy computational costs. We also propose a new method to tackle topic-specific sentiment analysis based on node classification and text classification as graph classification. Our work shows that 'star nodes' can learn effective graph-data representation and improve on current methods for the three tasks. Specifically, for graph classification and link prediction, GraphStar outperforms the current state-of-the-art models by 2-5% on several key benchmarks.",
    "title": "Graph Star Net for Generalized Multi-Task Learning"
  },
  {
    "arxiv": "1907.01068",
    "counts": {
      "ComplEx": 6,
      "ConvE": 1,
      "DistMult": 6,
      "HypER": 3,
      "SE": 8,
      "TransE": 1
    },
    "published": "2019-07-01T20:40:37Z",
    "summary": "Knowledge graph embeddings rank among the most successful methods for link prediction in knowledge graphs, i.e., the task of completing an incomplete collection of relational facts. A downside of these models is their strong sensitivity to model hyperparameters, in particular regularizers, which have to be extensively tuned to reach good performance [Kadlec et al., 2017]. We propose an efficient method for large scale hyperparameter tuning by interpreting these models in a probabilistic framework. After a model augmentation that introduces per-entity hyperparameters, we use a variational expectation-maximization approach to tune thousands of such hyperparameters with minimal additional cost. Our approach is agnostic to details of the model and results in a new state of the art in link prediction on standard benchmark data.",
    "title": "Augmenting and Tuning Knowledge Graph Embeddings"
  },
  {
    "arxiv": "1908.01297",
    "counts": {
      "LINE": 1,
      "NAM": 1,
      "ProjE": 1,
      "SE": 1
    },
    "published": "2019-08-04T09:03:20Z",
    "summary": "With the great success of graph embedding model on both academic and industry area, the robustness of graph embedding against adversarial attack inevitably becomes a central problem in graph learning domain. Regardless of the fruitful progress, most of the current works perform the attack in a white-box fashion: they need to access the model predictions and labels to construct their adversarial loss. However, the inaccessibility of model predictions in real systems makes the white-box attack impractical to real graph learning system. This paper promotes current frameworks in a more general and flexible sense -- we demand to attack various kinds of graph embedding model with black-box driven. To this end, we begin by investigating the theoretical connections between graph signal processing and graph embedding models in a principled way and formulate the graph embedding model as a general graph signal process with corresponding graph filter. As such, a generalized adversarial attacker: GF-Attack is constructed by the graph filter and feature matrix. Instead of accessing any knowledge of the target classifiers used in graph embedding, GF-Attack performs the attack only on the graph filter in a black-box attack fashion. To validate the generalization of GF-Attack, we construct the attacker on four popular graph embedding models. Extensive experimental results validate the effectiveness of our attacker on several benchmark datasets. Particularly by using our attack, even small graph perturbations like one-edge flip is able to consistently make a strong attack in performance to different graph embedding models.",
    "title": "A Restricted Black-box Adversarial Framework Towards Attacking Graph Embedding Models"
  },
  {
    "arxiv": "1908.06203",
    "counts": {
      "SE": 1,
      "TransE": 1,
      "TransR": 1
    },
    "published": "2019-08-16T23:27:25Z",
    "summary": "External knowledge is often useful for natural language understanding tasks. We introduce a contextual text representation model called Conceptual-Contextual (CC) embeddings, which incorporates structured knowledge into text representations. Unlike entity embedding methods, our approach encodes a knowledge graph into a context model. CC embeddings can be easily reused for a wide range of tasks just like pre-trained language models. Our model effectively encodes the huge UMLS database by leveraging semantic generalizability. Experiments on electronic health records (EHRs) and medical text processing benchmarks showed our model gives a major boost to the performance of supervised medical NLP tasks.",
    "title": "Learning Conceptual-Contextual Embeddings for Medical Text"
  },
  {
    "arxiv": "1908.06543",
    "counts": {
      "ComplEx": 1,
      "GeomE": 1,
      "HypER": 1,
      "LINE": 1,
      "ProjE": 1,
      "SDNE": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2019-08-19T00:19:57Z",
    "summary": "Graph embedding is the task of representing nodes of a graph in a low-dimensional space and its applications for graph tasks have gained significant traction in academia and industry. The primary difference among the many recently proposed graph embedding methods is the way they preserve the inherent properties of the graphs. However, in practice, comparing these methods is very challenging. The majority of methods report performance boosts on few selected real graphs. Therefore, it is difficult to generalize these performance improvements to other types of graphs. Given a graph, it is currently impossible to quantify the advantages of one approach over another. In this work, we introduce a principled framework to compare graph embedding methods. Our goal is threefold: (i) provide a unifying framework for comparing the performance of various graph embedding methods, (ii) establish a benchmark with real-world graphs that exhibit different structural properties, and (iii) provide users with a tool to identify the best graph embedding method for their data. This paper evaluates 4 of the most influential graph embedding methods and 4 traditional link prediction methods against a corpus of 100 real-world networks with varying properties. We organize the 100 networks in terms of their properties to get a better understanding of the embedding performance of these popular methods. We use the comparisons on our 100 benchmark graphs to define GFS-score, that can be applied to any embedding method to quantify its performance. We rank the state-of-the-art embedding approaches using the GFS-score and show that it can be used to understand and evaluate novel embedding approaches. We envision that the proposed framework (https://www.github.com/palash1992/GEM-Benchmark) will serve the community as a benchmarking platform to test and compare the performance of future graph embedding techniques.",
    "title": "Benchmarks for Graph Embedding Evaluation"
  },
  {
    "arxiv": "1908.08037",
    "counts": {
      "HypER": 1,
      "RatE": 1,
      "SDNE": 1,
      "SE": 2,
      "node2vec": 1
    },
    "published": "2019-08-21T02:45:43Z",
    "summary": "Representation learning has recently been successfully used to create vector representations of entities in language learning, recommender systems and in similarity learning. Graph embeddings exploit the locality structure of a graph and generate embeddings for nodes which could be words in a language, products of a retail website; and the nodes are connected based on a context window. In this paper, we consider graph embeddings with an error-free associative learning update rule, which models the embedding vector of node as a non-convex Gaussian mixture of the embeddings of the nodes in its immediate vicinity with some constant variance that is reduced as iterations progress. It is very easy to parallelize our algorithm without any form of shared memory, which makes it possible to use it on very large graphs with a much higher dimensionality of the embeddings. We study the efficacy of proposed method on several benchmark data sets and favorably compare with state of the art methods. Further, proposed method is applied to generate relevant recommendations for a large retailer.",
    "title": "Hebbian Graph Embeddings"
  },
  {
    "arxiv": "1908.10611",
    "counts": {
      "ConvE": 1,
      "GraphSAGE": 1,
      "LINE": 1,
      "ProjE": 1,
      "SE": 1,
      "STransE": 1,
      "TransD": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1,
      "node2vec": 1
    },
    "published": "2019-08-28T09:49:15Z",
    "summary": "Low-dimensional embeddings of knowledge graphs and behavior graphs have proved remarkably powerful in varieties of tasks, from predicting unobserved edges between entities to content recommendation. The two types of graphs can contain distinct and complementary information for the same entities/nodes. However, previous works focus either on knowledge graph embedding or behavior graph embedding while few works consider both in a unified way. Here we present BEM , a Bayesian framework that incorporates the information from knowledge graphs and behavior graphs. To be more specific, BEM takes as prior the pre-trained embeddings from the knowledge graph, and integrates them with the pre-trained embeddings from the behavior graphs via a Bayesian generative model. BEM is able to mutually refine the embeddings from both sides while preserving their own topological structures. To show the superiority of our method, we conduct a range of experiments on three benchmark datasets: node classification, link prediction, triplet classification on two small datasets related to Freebase, and item recommendation on a large-scale e-commerce dataset.",
    "title": "Bayes EMbedding (BEM): Refining Representation by Integrating Knowledge Graphs and Behavior-specific Networks"
  },
  {
    "arxiv": "1908.11561",
    "counts": {
      "LINE": 3,
      "SE": 3,
      "metapath2vec": 3,
      "node2vec": 3
    },
    "published": "2019-08-30T06:38:55Z",
    "summary": "The task of Chinese text spam detection is very challenging due to both glyph and phonetic variations of Chinese characters. This paper proposes a novel framework to jointly model Chinese variational, semantic, and contextualized representations for Chinese text spam detection task. In particular, a Variation Family-enhanced Graph Embedding (VFGE) algorithm is designed based on a Chinese character variation graph. The VFGE can learn both the graph embeddings of the Chinese characters (local) and the latent variation families (global). Furthermore, an enhanced bidirectional language model, with a combination gate function and an aggregation learning function, is proposed to integrate the graph and text information while capturing the sequential information. Extensive experiments have been conducted on both SMS and review datasets, to show the proposed method outperforms a series of state-of-the-art models for Chinese spam detection.",
    "title": "Detect Camouflaged Spam Content via StoneSkipping: Graph and Text Joint Embedding for Chinese Character Variation Representation"
  },
  {
    "arxiv": "1909.00958",
    "counts": {
      "ComplEx": 1,
      "GraphSAGE": 1,
      "HypER": 1,
      "LINE": 1,
      "ProjE": 1,
      "SDNE": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2019-09-03T05:21:31Z",
    "summary": "Research on graph representation learning has received a lot of attention in recent years since many data in real-world applications come in form of graphs. High-dimensional graph data are often in irregular form, which makes them more difficult to analyze than image/video/audio data defined on regular lattices. Various graph embedding techniques have been developed to convert the raw graph data into a low-dimensional vector representation while preserving the intrinsic graph properties. In this review, we first explain the graph embedding task and its challenges. Next, we review a wide range of graph embedding techniques with insights. Then, we evaluate several state-of-the-art methods against small and large datasets and compare their performance. Finally, potential applications and future directions are presented.",
    "title": "Graph Representation Learning: A Survey"
  },
  {
    "arxiv": "1909.01515",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "RESCAL": 1,
      "SE": 1,
      "TransE": 1,
      "TransF": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2019-09-04T01:35:47Z",
    "summary": "Link prediction is an important way to complete knowledge graphs (KGs), while embedding-based methods, effective for link prediction in KGs, perform poorly on relations that only have a few associative triples. In this work, we propose a Meta Relational Learning (MetaR) framework to do the common but challenging few-shot link prediction in KGs, namely predicting new triples about a relation by only observing a few associative triples. We solve few-shot link prediction by focusing on transferring relation-specific meta information to make model learn the most important knowledge and learn faster, corresponding to relation meta and gradient meta respectively in MetaR. Empirically, our model achieves state-of-the-art results on few-shot link prediction KG benchmarks.",
    "title": "Meta Relational Learning for Few-Shot Link Prediction in Knowledge Graphs"
  },
  {
    "arxiv": "1909.02930",
    "counts": {
      "ComplEx": 1,
      "LINE": 1,
      "ProjE": 1,
      "SE": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2019-09-06T14:29:00Z",
    "summary": "In order to facilitate the accesses of general users to knowledge graphs, an increasing effort is being exerted to construct graph-structured queries of given natural language questions. At the core of the construction is to deduce the structure of the target query and determine the vertices/edges which constitute the query. Existing query construction methods rely on question understanding and conventional graph-based algorithms which lead to inefficient and degraded performances facing complex natural language questions over knowledge graphs with large scales. In this paper, we focus on this problem and propose a novel framework standing on recent knowledge graph embedding techniques. Our framework first encodes the underlying knowledge graph into a low-dimensional embedding space by leveraging generalized local knowledge graphs. Given a natural language question, the learned embedding representations of the knowledge graph are utilized to compute the query structure and assemble vertices/edges into the target query. Extensive experiments were conducted on the benchmark dataset, and the results demonstrate that our framework outperforms state-of-the-art baseline models regarding effectiveness and efficiency.",
    "title": "Structured Query Construction via Knowledge Graph Embedding"
  },
  {
    "arxiv": "1909.02977",
    "counts": {
      "GraphSAGE": 1,
      "LINE": 1,
      "SE": 1,
      "TransA": 1,
      "node2vec": 1
    },
    "published": "2019-09-06T15:41:44Z",
    "summary": "Graph embedding aims at learning a vector-based representation of vertices that incorporates the structure of the graph. This representation then enables inference of graph properties. Existing graph embedding techniques, however, do not scale well to large graphs. We therefore propose a framework for parallel computation of a graph embedding using a cluster of compute nodes with resource constraints. We show how to distribute any existing embedding technique by first splitting a graph for any given set of constrained compute nodes and then reconciling the embedding spaces derived for these subgraphs. We also propose a new way to evaluate the quality of graph embeddings that is independent of a specific inference task. Based thereon, we give a formal bound on the difference between the embeddings derived by centralised and parallel computation. Experimental results illustrate that our approach for parallel computation scales well, while largely maintaining the embedding quality.",
    "title": "Parallel Computation of Graph Embeddings"
  },
  {
    "arxiv": "1909.03821",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "RESCAL": 1,
      "SE": 1,
      "TorusE": 1,
      "TransA": 1,
      "TransAt": 1,
      "TransD": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2019-09-09T12:58:16Z",
    "summary": "Knowledge graphs are useful for many artificial intelligence tasks but often have missing data. Hence, a method for completing knowledge graphs is required. Existing approaches include embedding models, the Path Ranking Algorithm, and rule evaluation models. However, these approaches have limitations. For example, all the information is mixed and difficult to interpret in embedding models, and traditional rule evaluation models are basically slow. In this paper, we provide an integrated view of various approaches and combine them to compensate for their limitations. We first unify state-of-the-art embedding models, such as ComplEx and TorusE, reinterpreting them as a variant of translation-based models. Then, we show that these models utilize paths for link prediction and propose a method for evaluating rules based on this idea. Finally, we combine an embedding model and observed feature models to predict missing triples. This is possible because all of these models utilize paths. We also conduct experiments, including link prediction tasks, with standard datasets to evaluate our method and framework. The experiments show that our method can evaluate rules faster than traditional methods and that our framework outperforms state-of-the-art models in terms of link prediction.",
    "title": "Combination of Unified Embedding Model and Observed Features for Knowledge Graph Completion"
  },
  {
    "arxiv": "1909.10086",
    "counts": {
      "ComplEx": 1,
      "SE": 1,
      "TransF": 1,
      "node2vec": 1
    },
    "published": "2019-09-22T20:21:15Z",
    "summary": "Learning powerful data embeddings has become a center piece in machine learning, especially in natural language processing and computer vision domains. The crux of these embeddings is that they are pretrained on huge corpus of data in a unsupervised fashion, sometimes aided with transfer learning. However currently in the graph learning domain, embeddings learned through existing graph neural networks (GNNs) are task dependent and thus cannot be shared across different datasets. In this paper, we present a first powerful and theoretically guaranteed graph neural network that is designed to learn task-independent graph embeddings, thereafter referred to as deep universal graph embedding (DUGNN). Our DUGNN model incorporates a novel graph neural network (as a universal graph encoder) and leverages rich Graph Kernels (as a multi-task graph decoder) for both unsupervised learning and (task-specific) adaptive supervised learning. By learning task-independent graph embeddings across diverse datasets, DUGNN also reaps the benefits of transfer learning. Through extensive experiments and ablation studies, we show that the proposed DUGNN model consistently outperforms both the existing state-of-art GNN models and Graph Kernels by an increased accuracy of 3% - 8% on graph classification benchmark datasets.",
    "title": "Learning Universal Graph Neural Network Embeddings With Aid Of Transfer Learning"
  },
  {
    "arxiv": "1909.11042",
    "counts": {
      "ConvE": 1,
      "HolE": 1,
      "HypER": 1,
      "ProjE": 1,
      "SE": 1,
      "TransE": 1
    },
    "published": "2019-09-24T16:52:18Z",
    "summary": "Deep learning currently dominates the benchmarks for various NLP tasks and, at the basis of such systems, words are frequently represented as embeddings --vectors in a low dimensional space-- learned from large text corpora and various algorithms have been proposed to learn both word and concept embeddings. One of the claimed benefits of such embeddings is that they capture knowledge about semantic relations. Such embeddings are most often evaluated through tasks such as predicting human-rated similarity and analogy which only test a few, often ill-defined, relations. In this paper, we propose a method for (i) reliably generating word and concept pair datasets for a wide number of relations by using a knowledge graph and (ii) evaluating to what extent pre-trained embeddings capture those relations. We evaluate the approach against a proprietary and a public knowledge graph and analyze the results, showing which lexico-semantic relational knowledge is captured by current embedding learning approaches.",
    "title": "Assessing the Lexico-Semantic Relational Knowledge Captured by Word and Concept Embeddings"
  },
  {
    "arxiv": "1909.12903",
    "counts": {
      "GraphSAGE": 1,
      "HypER": 1,
      "SDNE": 1,
      "SE": 2,
      "metapath2vec": 1,
      "node2vec": 1,
      "struc2Vec": 1
    },
    "published": "2019-09-25T18:35:03Z",
    "summary": "Graph node embedding aims at learning a vector representation for all nodes given a graph. It is a central problem in many machine learning tasks (e.g., node classification, recommendation, community detection). The key problem in graph node embedding lies in how to define the dependence to neighbors. Existing approaches specify (either explicitly or implicitly) certain dependencies on neighbors, which may lead to loss of subtle but important structural information within the graph and other dependencies among neighbors. This intrigues us to ask the question: can we design a model to give the maximal flexibility of dependencies to each node's neighborhood. In this paper, we propose a novel graph node embedding (named PINE) via a novel notion of partial permutation invariant set function, to capture any possible dependence. Our method 1) can learn an arbitrary form of the representation function from the neighborhood, withour losing any potential dependence structures, and 2) is applicable to both homogeneous and heterogeneous graph embedding, the latter of which is challenged by the diversity of node types. Furthermore, we provide theoretical guarantee for the representation capability of our method for general homogeneous and heterogeneous graphs. Empirical evaluation results on benchmark data sets show that our proposed PINE method outperforms the state-of-the-art approaches on producing node vectors for various learning tasks of both homogeneous and heterogeneous graphs.",
    "title": "PINE: Universal Deep Embedding for Graph Nodes via Partial Permutation Invariant Set Functions"
  },
  {
    "arxiv": "1910.00942",
    "counts": {
      "HypER": 2,
      "LINE": 2,
      "SE": 2,
      "SimplE": 1,
      "node2vec": 1
    },
    "published": "2019-10-02T13:30:08Z",
    "summary": "Graph autoencoders (AE) and variational autoencoders (VAE) recently emerged as powerful node embedding methods, with promising performances on challenging tasks such as link prediction and node clustering. Graph AE, VAE and most of their extensions rely on graph convolutional networks (GCN) to learn vector space representations of nodes. In this paper, we propose to replace the GCN encoder by a simple linear model w.r.t. the adjacency matrix of the graph. For the two aforementioned tasks, we empirically show that this approach consistently reaches competitive performances w.r.t. GCN-based models for numerous real-world graphs, including the widely used Cora, Citeseer and Pubmed citation networks that became the de facto benchmark datasets for evaluating graph AE and VAE. This result questions the relevance of repeatedly using these three datasets to compare complex graph AE and VAE models. It also emphasizes the effectiveness of simple node encoding schemes for many real-world applications.",
    "title": "Keep It Simple: Graph Autoencoders Without Graph Convolutional Networks"
  },
  {
    "arxiv": "1910.02370",
    "counts": {
      "GraphSAGE": 9,
      "LINE": 2,
      "NAM": 2,
      "SE": 8,
      "TransD": 3,
      "node2vec": 6
    },
    "published": "2019-10-06T04:43:46Z",
    "summary": "Graph embedding techniques have been increasingly deployed in a multitude of different applications that involve learning on non-Euclidean data. However, existing graph embedding models either fail to incorporate node attribute information during training or suffer from node attribute noise, which compromises the accuracy. Moreover, very few of them scale to large graphs due to their high computational complexity and memory usage. In this paper we propose GraphZoom, a multi-level framework for improving both accuracy and scalability of unsupervised graph embedding algorithms. GraphZoom first performs graph fusion to generate a new graph that effectively encodes the topology of the original graph and the node attribute information. This fused graph is then repeatedly coarsened into much smaller graphs by merging nodes with high spectral similarities. GraphZoom allows any existing embedding methods to be applied to the coarsened graph, before it progressively refine the embeddings obtained at the coarsest level to increasingly finer graphs. We have evaluated our approach on a number of popular graph datasets for both transductive and inductive tasks. Our experiments show that GraphZoom can substantially increase the classification accuracy and significantly accelerate the entire graph embedding process by up to 40.8x, when compared to the state-of-the-art unsupervised embedding methods.",
    "title": "GraphZoom: A multi-level spectral approach for accurate and scalable graph embedding"
  },
  {
    "arxiv": "1910.03483",
    "counts": {
      "GeomE": 1,
      "LINE": 1,
      "SE": 1,
      "SME": 1,
      "TransA": 1,
      "TransF": 1,
      "node2vec": 1
    },
    "published": "2019-10-08T15:48:50Z",
    "summary": "Recently, self-supervised learning has proved to be effective to learn representations of events suitable for temporal segmentation in image sequences, where events are understood as sets of temporally adjacent images that are semantically perceived as a whole. However, although this approach does not require expensive manual annotations, it is data hungry and suffers from domain adaptation problems. As an alternative, in this work, we propose a novel approach for learning event representations named Dynamic Graph Embedding (DGE). The assumption underlying our model is that a sequence of images can be represented by a graph that encodes both semantic and temporal similarity. The key novelty of DGE is to learn jointly the graph and its graph embedding. At its core, DGE works by iterating over two steps: 1) updating the graph representing the semantic and temporal similarity of the data based on the current data representation, and 2) updating the data representation to take into account the current data graph structure. The main advantage of DGE over state-of-the-art self-supervised approaches is that it does not require any training set, but instead learns iteratively from the data itself a low-dimensional embedding that reflects their temporal and semantic similarity. Experimental results on two benchmark datasets of real image sequences captured at regular time intervals demonstrate that the proposed DGE leads to event representations effective for temporal segmentation. In particular, it achieves robust temporal segmentation on the EDUBSeg and EDUBSeg-Desc benchmark datasets, outperforming the state of the art. Additional experiments on two Human Motion Segmentation benchmark datasets demonstrate the generalization capabilities of the proposed DGE.",
    "title": "Learning event representations for temporal segmentation of image sequences by dynamic graph embedding"
  },
  {
    "arxiv": "1910.04807",
    "counts": {
      "GraphSAGE": 1,
      "LINE": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2019-10-10T18:41:54Z",
    "summary": "Link prediction aims to infer missing links or predicting the future ones based on currently observed partial networks, it is a fundamental problem in network science with tremendous real-world applications. However, conventional link prediction approaches neither have high prediction accuracy nor being capable of revealing the hidden information behind links. To address this problem, we generalize the latest techniques in deep learning on graphs and present a new link prediction model - DeepLinker. Instead of learning node representation with the node label information, DeepLinker uses the links as supervised information. Experiments on five graphs show that DeepLinker can not only achieve the state-of-the-art link prediction accuracy, but also acquire the efficient node representations and node centrality ranking as the byproducts. Although the representations are obtained without any supervised node label information, they still perform well on node ranking and node classification tasks.",
    "title": "Link Prediction via Graph Attention Network"
  },
  {
    "arxiv": "1910.05736",
    "counts": {
      "ConvE": 1,
      "HypER": 1,
      "ProjE": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2019-10-13T12:09:12Z",
    "summary": "To enjoy more social network services, users nowadays are usually involved in multiple online sites at the same time. Aligned social networks provide more information to alleviate the problem of data insufficiency. In this paper, we target on the collective link prediction problem and aim to predict both the intra-network social links as well as the inter-network anchor links across multiple aligned social networks. It is not an easy task, and the major challenges involve the network characteristic difference problem and different directivity properties of the social and anchor links to be predicted. To address the problem, we propose an application oriented network embedding framework, Hierarchical Graph Attention based Network Embedding (HGANE), for collective link prediction over directed aligned networks. Very different from the conventional general network embedding models, HGANE effectively incorporates the collective link prediction task objectives into consideration. It learns the representations of nodes by aggregating information from both the intra-network neighbors (connected by social links) and inter-network partners (connected by anchor links). What's more, we introduce a hierarchical graph attention mechanism for the intra-network neighbors and inter-network partners respectively, which resolves the network characteristic differences and the link directivity challenges effectively. Extensive experiments have been conducted on real-world aligned networks datasets to demonstrate that our model outperformed the state-of-the-art baseline methods in addressing the collective link prediction problem by a large margin.",
    "title": "Collective Link Prediction Oriented Network Embedding with Hierarchical Graph Attention"
  },
  {
    "arxiv": "1911.00055",
    "counts": {
      "ComplEx": 1,
      "ComplEx-N3": 1,
      "ConvE": 1,
      "DistMult": 1,
      "HolE": 1,
      "R-GCN": 1,
      "RESCAL": 1,
      "RotatE": 1,
      "SE": 1,
      "TransD": 1,
      "TransE": 1,
      "TuckER": 1
    },
    "published": "2019-10-31T18:51:33Z",
    "summary": "In this paper, we study the problem of learning probabilistic logical rules for inductive and interpretable link prediction. Despite the importance of inductive link prediction, most previous works focused on transductive link prediction and cannot manage previously unseen entities. Moreover, they are black-box models that are not easily explainable for humans. We propose DRUM, a scalable and differentiable approach for mining first-order logical rules from knowledge graphs which resolves these problems. We motivate our method by making a connection between learning confidence scores for each rule and low-rank tensor approximation. DRUM uses bidirectional RNNs to share useful information across the tasks of learning rules for different relations. We also empirically demonstrate the efficiency of DRUM over existing rule mining methods for inductive link prediction on a variety of benchmark datasets.",
    "title": "DRUM: End-To-End Differentiable Rule Mining On Knowledge Graphs"
  },
  {
    "arxiv": "1911.04053",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "HypER": 1,
      "RESCAL": 1,
      "RotatE": 1,
      "SE": 1,
      "TransE": 1
    },
    "published": "2019-11-11T03:15:22Z",
    "summary": "This paper studies the problem of predicting missing relationships between entities in knowledge graphs through learning their representations. Currently, the majority of existing link prediction models employ simple but intuitive scoring functions and relatively small embedding size so that they could be applied to large-scale knowledge graphs. However, these properties also restrict the ability to learn more expressive and robust features. Therefore, diverging from most of the prior works which focus on designing new objective functions, we propose, DeCom, a simple but effective mechanism to boost the performance of existing link predictors such as DistMult, ComplEx, etc, through extracting more expressive features while preventing overfitting by adding just a few extra parameters. Specifically, embeddings of entities and relationships are first decompressed to a more expressive and robust space by decompressing functions, then knowledge graph embedding models are trained in this new feature space. Experimental results on several benchmark knowledge graphs and advanced link prediction systems demonstrate the generalization and effectiveness of our method. Especially, RESCAL + DeCom achieves state-of-the-art performance on the FB15k-237 benchmark across all evaluation metrics. In addition, we also show that compared with DeCom, explicitly increasing the embedding size significantly increase the number of parameters but could not achieve promising performance improvement.",
    "title": "Decompressing Knowledge Graph Representations for Link Prediction"
  },
  {
    "arxiv": "1911.04910",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "ConvKB": 1,
      "DistMult": 1,
      "GeomE": 1,
      "HypER": 1,
      "LINE": 1,
      "QuatE": 1,
      "R-GCN": 1,
      "RotatE": 1,
      "SACN": 1,
      "SE": 1,
      "TransD": 1,
      "TransE": 1,
      "TransF": 1,
      "TransH": 1,
      "TransR": 1,
      "TuckER": 1
    },
    "published": "2019-11-09T07:02:33Z",
    "summary": "Translational distance-based knowledge graph embedding has shown progressive improvements on the link prediction task, from TransE to the latest state-of-the-art RotatE. However, N-1, 1-N and N-N predictions still remain challenging. In this work, we propose a novel translational distance-based approach for knowledge graph link prediction. The proposed method includes two-folds, first we extend the RotatE from 2D complex domain to high dimension space with orthogonal transforms to model relations for better modeling capacity. Second, the graph context is explicitly modeled via two directed context representations. These context representations are used as part of the distance scoring function to measure the plausibility of the triples during training and inference. The proposed approach effectively improves prediction accuracy on the difficult N-1, 1-N and N-N cases for knowledge graph link prediction task. The experimental results show that it achieves better performance on two benchmark data sets compared to the baseline RotatE, especially on data set (FB15k-237) with many high in-degree connection nodes.",
    "title": "Orthogonal Relation Transforms with Graph Context Modeling for Knowledge Graph Embedding"
  },
  {
    "arxiv": "1911.10232",
    "counts": {
      "GraphSAGE": 3,
      "RatE": 1,
      "SE": 4,
      "node2vec": 3
    },
    "published": "2019-11-22T19:51:58Z",
    "summary": "Recent advancements in deep neural networks for graph-structured data have led to state-of-the-art performance on recommender system benchmarks. In this work, we present a Graph Convolutional Network (GCN) algorithm SWAG (Sample Weight and AGgregate), which combines efficient random walks and graph convolutions on weighted graphs to generate embeddings for nodes (items) that incorporate both graph structure as well as node feature information such as item-descriptions and item-images. The three important SWAG operations that enable us to efficiently generate node embeddings based on graph structures are (a) Sampling of graph to homogeneous structure, (b) Weighting the sampling, walks and convolution operations, and (c) using AGgregation functions for generating convolutions. The work is an adaptation of graphSAGE over weighted graphs. We deploy SWAG at Target and train it on a graph of more than 500K products sold online with over 50M edges. Offline and online evaluations reveal the benefit of using a graph-based approach and the benefits of weighing to produce high quality embeddings and product recommendations.",
    "title": "SWAG: Item Recommendations using Convolutions on Weighted Graphs"
  },
  {
    "arxiv": "1911.11119",
    "counts": {
      "ConvE": 1,
      "GeomE": 1,
      "LINE": 1,
      "SE": 1,
      "subgraph2Vec": 1
    },
    "published": "2019-11-25T18:46:03Z",
    "summary": "Graph kernels are widely used for measuring the similarity between graphs. Many existing graph kernels, which focus on local patterns within graphs rather than their global properties, suffer from significant structure information loss when representing graphs. Some recent global graph kernels, which utilizes the alignment of geometric node embeddings of graphs, yield state-of-the-art performance. However, these graph kernels are not necessarily positive-definite. More importantly, computing the graph kernel matrix will have at least quadratic {time} complexity in terms of the number and the size of the graphs. In this paper, we propose a new family of global alignment graph kernels, which take into account the global properties of graphs by using geometric node embeddings and an associated node transportation based on earth mover's distance. Compared to existing global kernels, the proposed kernel is positive-definite. Our graph kernel is obtained by defining a distribution over \\emph{random graphs}, which can naturally yield random feature approximations. The random feature approximations lead to our graph embeddings, which is named as \"random graph embeddings\" (RGE). In particular, RGE is shown to achieve \\emph{(quasi-)linear scalability} with respect to the number and the size of the graphs. The experimental results on nine benchmark datasets demonstrate that RGE outperforms or matches twelve state-of-the-art graph classification algorithms.",
    "title": "Scalable Global Alignment Graph Kernel Using Random Features: From Node Embedding to Graph Embedding"
  },
  {
    "arxiv": "1911.11140",
    "counts": {
      "ComplEx": 1,
      "ProjE": 1,
      "SE": 1
    },
    "published": "2019-11-25T17:38:57Z",
    "summary": "We present an examination of the metallicity distribution function of the outermost stellar halo of the Galaxy based on an analysis of both local (within 4 kpc of the Sun, ~16,500 stars) and non-local (~21,700 stars) samples. These samples were compiled using spectroscopic metallicities from the Sloan Digital Sky Survey and photometric metallicities from the SkyMapper Southern Survey. We detect a negative metallicity gradient in the outermost halo (r > 35 kpc from the Galactic center), and find that the frequency of very metal-poor ([Fe/H] < -2.0) stars in the outer-halo region reaches up to ~60% in our most distant sample, commensurate with previous theoretical predictions. This result provides clear evidence that the outer-halo formed hierarchically. The retrograde stars in the outermost halo exhibit a roughly constant metallicity, which may be linked to the accretion of the Sequoia progenitor. In contrast, prograde stars in the outermost halo exhibit a strong metallicity-distance dependence, indicating that they likely originated from the accretion of galaxies less massive than the Sequoia progenitor galaxy.",
    "title": "The Metallicity Gradient and Complex Formation History of the Outermost Halo of the Milky Way"
  },
  {
    "arxiv": "1911.11308",
    "counts": {
      "FedE": 1,
      "HypER": 1,
      "LINE": 1,
      "ProjE": 1,
      "SDNE": 1,
      "SE": 1,
      "TransA": 1,
      "node2vec": 1
    },
    "published": "2019-11-26T02:06:57Z",
    "summary": "Graph matching involves combinatorial optimization based on edge-to-edge affinity matrix, which can be generally formulated as Lawler's Quadratic Assignment Problem (QAP). This paper presents a QAP network directly learning with the affinity matrix (equivalently the association graph) whereby the matching problem is translated into a vertex classification task. The association graph is learned by an embedding network for vertex classification, followed by Sinkhorn normalization and a cross-entropy loss for end-to-end learning. We further improve the embedding model on association graph by introducing Sinkhorn based matching-aware constraint, as well as dummy nodes to deal with unequal sizes of graphs. To our best knowledge, this is the first network to directly learn with the general Lawler's QAP. In contrast, recent deep matching methods focus on the learning of node and edge features in two graphs respectively. We also show how to extend our network to hypergraph matching, and matching of multiple graphs. Experimental results on both synthetic graphs and real-world images show its effectiveness. For pure QAP tasks on synthetic data and QAPLIB benchmark, our method can perform competitively and even surpass state-of-the-art graph matching and QAP solvers with notable less time cost. Source code will be made public at https://github.com/Thinklab-SJTU/",
    "title": "Neural Graph Matching Network: Learning Lawler's Quadratic Assignment Problem with Extension to Hypergraph and Multiple-graph Matching"
  },
  {
    "arxiv": "1911.11486",
    "counts": {
      "LINE": 1,
      "ProjE": 1,
      "SE": 1
    },
    "published": "2019-11-26T12:14:01Z",
    "summary": "We formalize networks with evolving structures as temporal networks and propose a generative link prediction model, Generative Link Sequence Modeling (GLSM), to predict future links for temporal networks. GLSM captures the temporal link formation patterns from the observed links with a sequence modeling framework and has the ability to generate the emerging links by inferring from the probability distribution on the potential future links. To avoid overfitting caused by treating each link as a unique token, we propose a self-tokenization mechanism to transform each raw link in the network to an abstract aggregation token automatically. The self-tokenization is seamlessly integrated into the sequence modeling framework, which allows the proposed GLSM model to have the generalization capability to discover link formation patterns beyond raw link sequences. We compare GLSM with the existing state-of-art methods on five real-world datasets. The experimental results demonstrate that GLSM obtains future positive links effectively in a generative fashion while achieving the best performance (2-10\\% improvements on AUC) among other alternatives.",
    "title": "Generative Temporal Link Prediction via Self-tokenized Sequence Modeling"
  },
  {
    "arxiv": "1911.11726",
    "counts": {
      "ComplEx": 1,
      "LINE": 1,
      "SE": 1,
      "metapath2vec": 1,
      "node2vec": 1
    },
    "published": "2019-11-26T18:03:08Z",
    "summary": "Networks are one of the most powerful structures for modeling problems in the real world. Downstream machine learning tasks defined on networks have the potential to solve a variety of problems. With link prediction, for instance, one can predict whether two persons will become friends on a social network. Many machine learning algorithms, however, require that each input example is a real vector. Network embedding encompasses various methods for unsupervised, and sometimes supervised, learning of feature representations of nodes and links in a network. Typically, embedding methods are based on the assumption that the similarity between nodes in the network should be reflected in the learned feature representations. In this paper, we review significant contributions to network embedding in the last decade. In particular, we look at four methods: Spectral Clustering, DeepWalk, Large-scale Information Network Embedding (LINE), and node2vec. We describe each method and list its advantages and shortcomings. In addition, we give examples of real-world machine learning problems on networks in which the embedding is critical in order to maximize the predictive performance of the machine learning task. Finally, we take a look at research trends and state-of-the art methods in the research on network embedding.",
    "title": "Network Embedding: An Overview"
  },
  {
    "arxiv": "1912.00536",
    "counts": {
      "ComplEx": 1,
      "GraphSAGE": 1,
      "LINE": 4,
      "SDNE": 1,
      "SE": 2,
      "node2vec": 3
    },
    "published": "2019-12-02T01:28:08Z",
    "summary": "Graph embedding methods transform high-dimensional and complex graph contents into low-dimensional representations. They are useful for a wide range of graph analysis tasks including link prediction, node classification, recommendation and visualization. Most existing approaches represent graph nodes as point vectors in a low-dimensional embedding space, ignoring the uncertainty present in the real-world graphs. Furthermore, many real-world graphs are large-scale and rich in content (e.g. node attributes). In this work, we propose GLACE, a novel, scalable graph embedding method that preserves both graph structure and node attributes effectively and efficiently in an end-to-end manner. GLACE effectively models uncertainty through Gaussian embeddings, and supports inductive inference of new nodes based on their attributes. In our comprehensive experiments, we evaluate GLACE on real-world graphs, and the results demonstrate that GLACE significantly outperforms state-of-the-art embedding methods on multiple graph analysis tasks.",
    "title": "Gaussian Embedding of Large-scale Attributed Graphs"
  },
  {
    "arxiv": "1912.02068",
    "counts": {
      "ComplEx": 2,
      "ConvE": 1,
      "GeomE": 2,
      "HolE": 1,
      "HypER": 2,
      "LINE": 2,
      "NAM": 1,
      "ProjE": 2,
      "RotH": 2,
      "SE": 2,
      "SimplE": 2,
      "TransA": 1,
      "TransF": 2,
      "TransM": 1
    },
    "published": "2019-12-04T15:49:42Z",
    "summary": "Extremal Graph Theory is a very deep and wide area of modern combinatorics. It is very fast developing, and in this long but relatively short survey we select some of those results which either we feel very important in this field or which are new breakthrough results, or which --- for some other reasons --- are very close to us. Some results discussed here got stronger emphasis, since they are connected to Lov\\'asz (and sometimes to us).",
    "title": "Embedding graphs into larger graphs: results, methods, and problems"
  },
  {
    "arxiv": "1912.05140",
    "counts": {
      "ComplEx": 1,
      "GraphSAGE": 2,
      "HypER": 1,
      "LINE": 1,
      "NAM": 1,
      "SDNE": 2,
      "SE": 2,
      "TransF": 1,
      "node2vec": 2,
      "struc2Vec": 1
    },
    "published": "2019-12-11T07:04:27Z",
    "summary": "Network representation learning has traditionally been used to find lower dimensional vector representations of the nodes in a network. However, there are very important edge driven mining tasks of interest to the classical network analysis community, which have mostly been unexplored in the network embedding space. For applications such as link prediction in homogeneous networks, vector representation (i.e., embedding) of an edge is derived heuristically just by using simple aggregations of the embeddings of the end vertices of the edge. Clearly, this method of deriving edge embedding is suboptimal and there is a need for a dedicated unsupervised approach for embedding edges by leveraging edge properties of the network. Towards this end, we propose a novel concept of converting a network to its weighted line graph which is ideally suited to find the embedding of edges of the original network. We further derive a novel algorithm to embed the line graph, by introducing the concept of collective homophily. To the best of our knowledge, this is the first direct unsupervised approach for edge embedding in homogeneous information networks, without relying on the node embeddings. We validate the edge embeddings on three downstream edge mining tasks. Our proposed optimization framework for edge embedding also generates a set of node embeddings, which are not just the aggregation of edges. Further experimental analysis shows the connection of our framework to the concept of node centrality.",
    "title": "Beyond Node Embedding: A Direct Unsupervised Edge Representation Framework for Homogeneous Networks"
  },
  {
    "arxiv": "1912.08808",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "LINE": 1,
      "NAM": 1,
      "SDNE": 1,
      "SE": 1,
      "TransF": 1,
      "node2vec": 1
    },
    "published": "2019-12-17T21:14:48Z",
    "summary": "Graph embedding has become a key component of many data mining and analysis systems. Current graph embedding approaches either sample a large number of node pairs from a graph to learn node embeddings via stochastic optimization or factorize a high-order proximity/adjacency matrix of the graph via computationally expensive matrix factorization techniques. These approaches typically require significant resources for the learning process and rely on multiple parameters, which limits their applicability in practice. Moreover, most of the existing graph embedding techniques operate effectively in one specific metric space only (e.g., the one produced with cosine similarity), do not preserve higher-order structural features of the input graph and cannot automatically determine a meaningful number of embedding dimensions. Typically, the produced embeddings are not easily interpretable, which complicates further analyses and limits their applicability. To address these issues, we propose DAOR, a highly efficient and parameter-free graph embedding technique producing metric space-robust, compact and interpretable embeddings without any manual tuning. Compared to a dozen state-of-the-art graph embedding algorithms, DAOR yields competitive results on both node classification (which benefits form high-order proximity) and link prediction (which relies on low-order proximity mostly). Unlike existing techniques, however, DAOR does not require any parameter tuning and improves the embeddings generation speed by several orders of magnitude. Our approach has hence the ambition to greatly simplify and speed up data analysis tasks involving graph representation learning.",
    "title": "Bridging the Gap between Community and Node Representations: Graph Embedding via Community Detection"
  },
  {
    "arxiv": "1912.09867",
    "counts": {
      "ConvE": 3,
      "GeomE": 1,
      "LINE": 2,
      "SE": 4,
      "node2vec": 3
    },
    "published": "2019-12-20T15:09:50Z",
    "summary": "We consider the task of few shot link prediction on graphs. The goal is to learn from a distribution over graphs so that a model is able to quickly infer missing edges in a new graph after a small amount of training. We show that current link prediction methods are generally ill-equipped to handle this task. They cannot effectively transfer learned knowledge from one graph to another and are unable to effectively learn from sparse samples of edges. To address this challenge, we introduce a new gradient-based meta learning framework, Meta-Graph. Our framework leverages higher-order gradients along with a learned graph signature function that conditionally generates a graph neural network initialization. Using a novel set of few shot link prediction benchmarks, we show that Meta-Graph can learn to quickly adapt to a new graph using only a small sample of true edges, enabling not only fast adaptation but also improved results at convergence.",
    "title": "Meta-Graph: Few Shot Link Prediction via Meta Learning"
  },
  {
    "arxiv": "2001.00461",
    "counts": {
      "ComplEx": 1,
      "DistMult": 1,
      "FedE": 1,
      "LINE": 1,
      "RESCAL": 1,
      "SE": 1,
      "SimplE": 1,
      "TransE": 1,
      "TransR": 1
    },
    "published": "2020-01-02T14:44:23Z",
    "summary": "We propose a novel method for automatic reasoning on knowledge graphs based on debate dynamics. The main idea is to frame the task of triple classification as a debate game between two reinforcement learning agents which extract arguments -- paths in the knowledge graph -- with the goal to promote the fact being true (thesis) or the fact being false (antithesis), respectively. Based on these arguments, a binary classifier, called the judge, decides whether the fact is true or false. The two agents can be considered as sparse, adversarial feature generators that present interpretable evidence for either the thesis or the antithesis. In contrast to other black-box methods, the arguments allow users to get an understanding of the decision of the judge. Since the focus of this work is to create an explainable method that maintains a competitive predictive accuracy, we benchmark our method on the triple classification and link prediction task. Thereby, we find that our method outperforms several baselines on the benchmark datasets FB15k-237, WN18RR, and Hetionet. We also conduct a survey and find that the extracted arguments are informative for users.",
    "title": "Reasoning on Knowledge Graphs with Debate Dynamics"
  },
  {
    "arxiv": "2001.01015",
    "counts": {
      "ComplEx": 1,
      "HypER": 1,
      "NAM": 2,
      "RotH": 1,
      "SE": 2,
      "TransA": 1
    },
    "published": "2020-01-04T00:26:05Z",
    "summary": "Many real-world relations can be represented by signed networks with positive links (e.g., friendships and trust) and negative links (e.g., foes and distrust). Link prediction helps advance tasks in social network analysis such as recommendation systems. Most existing work on link analysis focuses on unsigned social networks. The existence of negative links piques research interests in investigating whether properties and principles of signed networks differ from those of unsigned networks, and mandates dedicated efforts on link analysis for signed social networks. Recent findings suggest that properties of signed networks substantially differ from those of unsigned networks and negative links can be of significant help in signed link analysis in complementary ways. In this article, we center our discussion on a challenging problem of signed link analysis. Signed link analysis faces the problem of data sparsity, i.e. only a small percentage of signed links are given. This problem can even get worse when negative links are much sparser than positive ones as users are inclined more towards positive disposition rather than negative. We investigate how we can take advantage of other sources of information for signed link analysis. This research is mainly guided by three social science theories, Emotional Information, Diffusion of Innovations, and Individual Personality. Guided by these, we extract three categories of related features and leverage them for signed link analysis. Experiments show the significance of the features gleaned from social theories for signed link prediction and addressing the data sparsity challenge.",
    "title": "Social Science Guided Feature Engineering: A Novel Approach to Signed Link Analysis"
  },
  {
    "arxiv": "2001.02545",
    "counts": {
      "ConvE": 1,
      "NAM": 1,
      "ProjE": 1,
      "SE": 1,
      "TransA": 1,
      "TransF": 1
    },
    "published": "2020-01-08T14:27:36Z",
    "summary": "Java 7 introduced programmable dynamic linking in the form of the invokedynamic framework. Static analysis of code containing programmable dynamic linking has often been cited as a significant source of unsoundness in the analysis of Java programs. For example, Java lambdas, introduced in Java 8, are a very popular feature, which is, however, resistant to static analysis, since it mixes invokedynamic with dynamic code generation. These techniques invalidate static analysis assumptions: programmable linking breaks reasoning about method resolution while dynamically generated code is, by definition, not available statically. In this paper, we show that a static analysis can predictively model uses of invokedynamic while also cooperating with extra rules to handle the runtime code generation of lambdas. Our approach plugs into an existing static analysis and helps eliminate all unsoundness in the handling of lambdas (including associated features such as method references) and generic invokedynamic uses. We evaluate our technique on a benchmark suite of our own and on third-party benchmarks, uncovering all code previously unreachable due to unsoundness, highly efficiently.",
    "title": "Deep Static Modeling of invokedynamic"
  },
  {
    "arxiv": "2001.06752",
    "counts": {
      "ComplEx": 1,
      "LINE": 1,
      "NAM": 1,
      "SE": 1
    },
    "published": "2020-01-19T02:08:28Z",
    "summary": "The quadratic embedding constant (QE constant) of a graph is a new characteristic value of a graph defined through the distance matrix. We derive formulae for the QE constants of the join of two regular graphs, double graphs and certain lexicographic product graphs. Examples include complete bipartite graphs, wheel graphs, friendship graphs, completely split graph, and some graphs associated to strongly regular graphs.",
    "title": "Quadratic Embedding Constants of Graph Joins"
  },
  {
    "arxiv": "2001.07614",
    "counts": {
      "LINE": 1,
      "SE": 1,
      "SimplE": 1,
      "node2vec": 1
    },
    "published": "2020-01-21T15:33:12Z",
    "summary": "Over the last few years, graph autoencoders (AE) and variational autoencoders (VAE) emerged as powerful node embedding methods, with promising performances on challenging tasks such as link prediction and node clustering. Graph AE, VAE and most of their extensions rely on multi-layer graph convolutional networks (GCN) encoders to learn vector space representations of nodes. In this paper, we show that GCN encoders are actually unnecessarily complex for many applications. We propose to replace them by significantly simpler and more interpretable linear models w.r.t. the direct neighborhood (one-hop) adjacency matrix of the graph, involving fewer operations, fewer parameters and no activation function. For the two aforementioned tasks, we show that this simpler approach consistently reaches competitive performances w.r.t. GCN-based graph AE and VAE for numerous real-world graphs, including all benchmark datasets commonly used to evaluate graph AE and VAE. Based on these results, we also question the relevance of repeatedly using these datasets to compare complex graph AE and VAE.",
    "title": "Simple and Effective Graph Autoencoders with One-Hop Linear Models"
  },
  {
    "arxiv": "2001.08503",
    "counts": {
      "ComplEx": 1,
      "LINE": 1,
      "NAM": 2,
      "ProjE": 2,
      "SDNE": 1,
      "SE": 2,
      "node2vec": 1
    },
    "published": "2020-01-16T10:47:40Z",
    "summary": "A collaborative network is a social network that is comprised of experts who cooperate with each other to fulfill a special goal. Analyzing this network yields meaningful information about the expertise of these experts and their subject areas. To perform the analysis, graph embedding techniques have emerged as an effective and promising tool. Graph embedding attempts to represent graph nodes as low-dimensional vectors. In this paper, we propose a graph embedding method, called ExEm, that uses dominating-set theory and deep learning approaches to capture node representations. ExEm finds dominating nodes of the collaborative network and constructs intelligent random walks that comprise of at least two dominating nodes. One dominating node should appear at the beginning of each path sampled to characterize the local neighborhoods. Moreover, the second dominating node reflects the global structure information. To learn the node embeddings, ExEm exploits three embedding methods including Word2vec, fastText and the concatenation of these two. The final result is the low-dimensional vectors of experts, called expert embeddings. The extracted expert embeddings can be applied to many applications. In order to extend these embeddings into the expert recommendation system, we introduce a novel strategy that uses expert vectors to calculate experts' scores and recommend experts. At the end, we conduct extensive experiments to validate the effectiveness of ExEm through assessing its performance over the multi-label classification, link prediction, and recommendation tasks on common datasets and our collected data formed by crawling the vast author Scopus profiles. The experiments show that ExEm outperforms the baselines especially in dense networks.",
    "title": "ExEm: Expert Embedding using dominating set theory with deep learning approaches"
  },
  {
    "arxiv": "2002.00423",
    "counts": {
      "ConvE": 1,
      "GeomE": 1,
      "GraphSAGE": 1,
      "R-GCN": 5,
      "RatE": 1,
      "SE": 7
    },
    "published": "2020-02-02T16:07:15Z",
    "summary": "Automated theorem proving in first-order logic is an active research area which is successfully supported by machine learning. While there have been various proposals for encoding logical formulas into numerical vectors -- from simple strings to more involved graph-based embeddings -- little is known about how these different encodings compare. In this paper, we study and experimentally compare pattern-based embeddings that are applied in current systems with popular graph-based encodings, most of which have not been considered in the theorem proving context before. Our experiments show that the advantages of simpler encoding schemes in terms of runtime are outdone by more complex graph-based embeddings, which yield more efficient search strategies and simpler proofs. To support this, we present a detailed analysis across several dimensions of theorem prover performance beyond just proof completion rate, thus providing empirical evidence to help guide future research on neural-guided theorem proving towards the most promising directions.",
    "title": "An Experimental Study of Formula Embeddings for Automated Theorem Proving in First-Order Logic"
  },
  {
    "arxiv": "2002.04497",
    "counts": {
      "ComplEx": 1,
      "LINE": 1,
      "SE": 2,
      "node2vec": 1
    },
    "published": "2020-02-11T15:58:31Z",
    "summary": "In this paper, we study the fundamental problem of random walk for network embedding. We propose to use non-Markovian random walk, variants of vertex-reinforced random walk (VRRW), to fully use the history of a random walk path. To solve the getting stuck problem of VRRW, we introduce an exploitation-exploration mechanism to help the random walk jump out of the stuck set. The new random walk algorithms share the same convergence property of VRRW and thus can be used to learn stable network embeddings. Experimental results on two link prediction benchmark datasets and three node classification benchmark datasets show that our proposed approach reinforce2vec can outperform state-of-the-art random walk based embedding methods by a large margin.",
    "title": "Vertex-reinforced Random Walk for Network Embedding"
  },
  {
    "arxiv": "2002.07962",
    "counts": {
      "GraphSAGE": 1,
      "LINE": 1,
      "SE": 2,
      "TransD": 1,
      "node2vec": 1
    },
    "published": "2020-02-19T02:05:37Z",
    "summary": "Inductive representation learning on temporal graphs is an important step toward salable machine learning on real-world dynamic networks. The evolving nature of temporal dynamic graphs requires handling new nodes as well as capturing temporal patterns. The node embeddings, which are now functions of time, should represent both the static node features and the evolving topological structures. Moreover, node and topological features can be temporal as well, whose patterns the node embeddings should also capture. We propose the temporal graph attention (TGAT) layer to efficiently aggregate temporal-topological neighborhood features as well as to learn the time-feature interactions. For TGAT, we use the self-attention mechanism as building block and develop a novel functional time encoding technique based on the classical Bochner's theorem from harmonic analysis. By stacking TGAT layers, the network recognizes the node embeddings as functions of time and is able to inductively infer embeddings for both new and observed nodes as the graph evolves. The proposed approach handles both node classification and link prediction task, and can be naturally extended to include the temporal edge features. We evaluate our method with transductive and inductive tasks under temporal settings with two benchmark and one industrial dataset. Our TGAT model compares favorably to state-of-the-art baselines as well as the previous temporal graph embedding approaches.",
    "title": "Inductive Representation Learning on Temporal Graphs"
  },
  {
    "arxiv": "2002.09573",
    "counts": {
      "ConvE": 1,
      "LINE": 1,
      "NAM": 1,
      "SE": 1
    },
    "published": "2020-02-21T23:02:00Z",
    "summary": "In this article, we describe the algorithms for causal structure learning from time series data that won the Causality 4 Climate competition at the Conference on Neural Information Processing Systems 2019 (NeurIPS). We examine how our combination of established ideas achieves competitive performance on semi-realistic and realistic time series data exhibiting common challenges in real-world Earth sciences data. In particular, we discuss a) a rationale for leveraging linear methods to identify causal links in non-linear systems, b) a simulation-backed explanation as to why large regression coefficients may predict causal links better in practice than small p-values and thus why normalising the data may sometimes hinder causal structure learning. For benchmark usage, we detail the algorithms here and provide implementations at https://github.com/sweichwald/tidybench . We propose the presented competition-proven methods for baseline benchmark comparisons to guide the development of novel algorithms for structure learning from time series.",
    "title": "Causal structure learning from time series: Large regression coefficients may predict causal links better in practice than small p-values"
  },
  {
    "arxiv": "2002.10710",
    "counts": {
      "LINE": 1,
      "NAM": 1,
      "SE": 1,
      "TransF": 1
    },
    "published": "2020-02-25T07:49:12Z",
    "summary": "Emotion-cause pair extraction (ECPE), as an emergent natural language processing task, aims at jointly investigating emotions and their underlying causes in documents. It extends the previous emotion cause extraction (ECE) task, yet without requiring a set of pre-given emotion clauses as in ECE. Existing approaches to ECPE generally adopt a two-stage method, i.e., (1) emotion and cause detection, and then (2) pairing the detected emotions and causes. Such pipeline method, while intuitive, suffers from two critical issues, including error propagation across stages that may hinder the effectiveness, and high computational cost that would limit the practical application of the method. To tackle these issues, we propose a multi-task learning model that can extract emotions, causes and emotion-cause pairs simultaneously in an end-to-end manner. Specifically, our model regards pair extraction as a link prediction task, and learns to link from emotion clauses to cause clauses, i.e., the links are directional. Emotion extraction and cause extraction are incorporated into the model as auxiliary tasks, which further boost the pair extraction. Experiments are conducted on an ECPE benchmarking dataset. The results show that our proposed model outperforms a range of state-of-the-art approaches.",
    "title": "An End-to-End Multi-Task Learning to Link Framework for Emotion-Cause Pair Extraction"
  },
  {
    "arxiv": "2002.11522",
    "counts": {
      "ComplEx": 1,
      "HypER": 1,
      "LINE": 1,
      "SDNE": 1,
      "SE": 2,
      "metapath2vec": 1,
      "node2vec": 1,
      "struc2Vec": 1
    },
    "published": "2020-02-25T16:59:09Z",
    "summary": "Network embedding methods map a network's nodes to vectors in an embedding space, in such a way that these representations are useful for estimating some notion of similarity or proximity between pairs of nodes in the network. The quality of these node representations is then showcased through results of downstream prediction tasks. Commonly used benchmark tasks such as link prediction, however, present complex evaluation pipelines and an abundance of design choices. This, together with a lack of standardized evaluation setups can obscure the real progress in the field. In this paper, we aim to shed light on the state-of-the-art of network embedding methods for link prediction and show, using a consistent evaluation pipeline, that only thin progress has been made over the last years. The newly conducted benchmark that we present here, including 17 embedding methods, also shows that many approaches are outperformed even by simple heuristics. Finally, we argue that standardized evaluation tools can repair this situation and boost future progress in this field.",
    "title": "Benchmarking Network Embedding Models for Link Prediction: Are We Making Progress?"
  },
  {
    "arxiv": "2003.00982",
    "counts": {
      "5*": 1,
      "ConvE": 1,
      "HypER": 1,
      "SE": 2,
      "TransF": 2
    },
    "published": "2020-03-02T15:58:46Z",
    "summary": "Graph neural networks (GNNs) have become the standard toolkit for analyzing and learning from data on graphs. As the field grows, it becomes critical to identify key architectures and validate new ideas that generalize to larger, more complex datasets. Unfortunately, it has been increasingly difficult to gauge the effectiveness of new models in the absence of a standardized benchmark with consistent experimental settings. In this paper, we introduce a reproducible GNN benchmarking framework, with the facility for researchers to add new models conveniently for arbitrary datasets. We demonstrate the usefulness of our framework by presenting a principled investigation into the recent Weisfeiler-Lehman GNNs (WL-GNNs) compared to message passing-based graph convolutional networks (GCNs) for a variety of graph tasks, i.e. graph regression/classification and node/link prediction, with medium-scale datasets.",
    "title": "Benchmarking Graph Neural Networks"
  },
  {
    "arxiv": "2003.04508",
    "counts": {
      "LINE": 1,
      "SDNE": 1,
      "SE": 1,
      "TuckER": 1
    },
    "published": "2020-03-10T02:33:14Z",
    "summary": "Graph autoencoders (GAEs) are powerful tools in representation learning for graph embedding. However, the performance of GAEs is very dependent on the quality of the graph structure, i.e., of the adjacency matrix. In other words, GAEs would perform poorly when the adjacency matrix is incomplete or be disturbed. In this paper, two novel unsupervised graph embedding methods, unsupervised graph embedding via adaptive graph learning (BAGE) and unsupervised graph embedding via variational adaptive graph learning (VBAGE) are proposed. The proposed methods expand the application range of GAEs on graph embedding, i.e, on the general datasets without graph structure. Meanwhile, the adaptive learning mechanism can initialize the adjacency matrix without be affected by the parameter. Besides that, the latent representations are embedded in the laplacian graph structure to preserve the topology structure of the graph in the vector space. Moreover, the adjacency matrix can be self-learned for better embedding performance when the original graph structure is incomplete. With adaptive learning, the proposed method is much more robust to the graph structure. Experimental studies on several datasets validate our design and demonstrate that our methods outperform baselines by a wide margin in node clustering, node classification, and graph visualization tasks.",
    "title": "Unsupervised Graph Embedding via Adaptive Graph Learning"
  },
  {
    "arxiv": "2003.05730",
    "counts": {
      "GraphSAGE": 1,
      "LINE": 1,
      "RESCAL": 1,
      "RatE": 1,
      "SE": 1,
      "TransD": 1,
      "TransE": 1,
      "TransR": 1,
      "node2vec": 1
    },
    "published": "2020-03-10T12:48:00Z",
    "summary": "Deep learning models on graphs have achieved remarkable performance in various graph analysis tasks, e.g., node classification, link prediction and graph clustering. However, they expose uncertainty and unreliability against the well-designed inputs, i.e., adversarial examples. Accordingly, a line of studies have emerged for both attack and defense addressed in different graph analysis tasks, leading to the arms race in graph adversarial learning. Despite the booming works, there still lacks a unified problem definition and a comprehensive review. To bridge this gap, we investigate and summarize the existing works on graph adversarial learning tasks systemically. Specifically, we survey and unify the existing works w.r.t. attack and defense in graph analysis tasks, and give appropriate definitions and taxonomies at the same time. Besides, we emphasize the importance of related evaluation metrics, investigate and summarize them comprehensively. Hopefully, our works can provide a comprehensive overview and offer insights for the relevant researchers. More details of our works are available at https://github.com/gitgiter/Graph-Adversarial-Learning.",
    "title": "A Survey of Adversarial Learning on Graphs"
  },
  {
    "arxiv": "2003.05809",
    "counts": {
      "DistMult": 1,
      "FedE": 1,
      "HolE": 1,
      "RESCAL": 1,
      "SE": 1,
      "TransA": 1,
      "TransE": 1,
      "TransH": 1,
      "node2vec": 1
    },
    "published": "2020-03-09T12:57:10Z",
    "summary": "In this paper, we present KGvec2go, a Web API for accessing and consuming graph embeddings in a light-weight fashion in downstream applications. Currently, we serve pre-trained embeddings for four knowledge graphs. We introduce the service and its usage, and we show further that the trained models have semantic value by evaluating them on multiple semantic benchmarks. The evaluation also reveals that the combination of multiple models can lead to a better outcome than the best individual model.",
    "title": "KGvec2go -- Knowledge Graph Embeddings as a Service"
  },
  {
    "arxiv": "2003.08420",
    "counts": {
      "LINE": 1,
      "NAM": 1,
      "ProjE": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2020-03-18T18:21:48Z",
    "summary": "Graph representation learning based on graph neural networks (GNNs) can greatly improve the performance of downstream tasks, such as node and graph classification. However, the general GNN models do not aggregate node information in a hierarchical manner, and can miss key higher-order structural features of many graphs. The hierarchical aggregation also enables the graph representations to be explainable. In addition, supervised graph representation learning requires labeled data, which is expensive and error-prone. To address these issues, we present an unsupervised graph representation learning method, Unsupervised Hierarchical Graph Representation (UHGR), which can generate hierarchical representations of graphs. Our method focuses on maximizing mutual information between \"local\" and high-level \"global\" representations, which enables us to learn the node embeddings and graph embeddings without any labeled data. To demonstrate the effectiveness of the proposed method, we perform the node and graph classification using the learned node and graph embeddings. The results show that the proposed method achieves comparable results to state-of-the-art supervised methods on several benchmarks. In addition, our visualization of hierarchical representations indicates that our method can capture meaningful and interpretable clusters.",
    "title": "Unsupervised Hierarchical Graph Representation Learning by Mutual Information Maximization"
  },
  {
    "arxiv": "2003.12590",
    "counts": {
      "ComplEx": 1,
      "LINE": 1,
      "RESCAL": 1,
      "SE": 1,
      "TransA": 1,
      "TransE": 1,
      "node2vec": 1
    },
    "published": "2020-03-27T18:23:55Z",
    "summary": "Vector representations of graphs and relational structures, whether hand-crafted feature vectors or learned representations, enable us to apply standard data analysis and machine learning techniques to the structures. A wide range of methods for generating such embeddings have been studied in the machine learning and knowledge representation literature. However, vector embeddings have received relatively little attention from a theoretical point of view. Starting with a survey of embedding techniques that have been used in practice, in this paper we propose two theoretical approaches that we see as central for understanding the foundations of vector embeddings. We draw connections between the various approaches and suggest directions for future research.",
    "title": "word2vec, node2vec, graph2vec, X2vec: Towards a Theory of Vector Embeddings of Structured Data"
  },
  {
    "arxiv": "2004.00387",
    "counts": {
      "R-GCN": 2,
      "SE": 5,
      "node2vec": 1
    },
    "published": "2020-03-25T22:53:14Z",
    "summary": "Recent advances in research have demonstrated the effectiveness of knowledge graphs (KG) in providing valuable external knowledge to improve recommendation systems (RS). A knowledge graph is capable of encoding high-order relations that connect two objects with one or multiple related attributes. With the help of the emerging Graph Neural Networks (GNN), it is possible to extract both object characteristics and relations from KG, which is an essential factor for successful recommendations. In this paper, we provide a comprehensive survey of the GNN-based knowledge-aware deep recommender systems. Specifically, we discuss the state-of-the-art frameworks with a focus on their core component, i.e., the graph embedding module, and how they address practical recommendation issues such as scalability, cold-start and so on. We further summarize the commonly-used benchmark datasets, evaluation metrics as well as open-source codes. Finally, we conclude the survey and propose potential research directions in this rapidly growing field.",
    "title": "Deep Learning on Knowledge Graph for Recommender System: A Survey"
  },
  {
    "arxiv": "2004.01024",
    "counts": {
      "GraphSAGE": 2,
      "LINE": 2,
      "SE": 2,
      "metapath2vec": 2,
      "node2vec": 2
    },
    "published": "2020-04-01T17:16:47Z",
    "summary": "Network embedding aims to learn low-dimensional representations of nodes while capturing structure information of networks. It has achieved great success on many tasks of network analysis such as link prediction and node classification. Most of existing network embedding algorithms focus on how to learn static homogeneous networks effectively. However, networks in the real world are more complex, e.g., networks may consist of several types of nodes and edges (called heterogeneous information) and may vary over time in terms of dynamic nodes and edges (called evolutionary patterns). Limited work has been done for network embedding of dynamic heterogeneous networks as it is challenging to learn both evolutionary and heterogeneous information simultaneously. In this paper, we propose a novel dynamic heterogeneous network embedding method, termed as DyHATR, which uses hierarchical attention to learn heterogeneous information and incorporates recurrent neural networks with temporal attention to capture evolutionary patterns. We benchmark our method on four real-world datasets for the task of link prediction. Experimental results show that DyHATR significantly outperforms several state-of-the-art baselines.",
    "title": "Modeling Dynamic Heterogeneous Network for Link Prediction using Hierarchical Attention with Temporal RNN"
  },
  {
    "arxiv": "2004.03819",
    "counts": {
      "ComplEx": 1,
      "LINE": 1,
      "ProjE": 1,
      "SE": 1
    },
    "published": "2020-04-08T05:30:43Z",
    "summary": "Minor embedding heuristics have become an indispensable tool for compiling problems in quadratically unconstrained binary optimization (QUBO) into the hardware graphs of quantum and CMOS annealing processors. While recent embedding heuristics have been developed for annealers of moderate size (about 2000 nodes) the size of the latest CMOS annealing processor (with 102,400 nodes) poses entirely new demands on the embedding heuristic. This raises the question, if recent embedding heuristics can maintain meaningful embedding performance on hardware graphs of increasing size. Here, we develop an improved version of the probabilistic-swap-shift-annealing (PSSA) embedding heuristic [which has recently been demonstrated to outperform the standard embedding heuristic by D-Wave Systems (Cai et al., 2014)] and evaluate its embedding performance on hardware graphs of increasing size. For random-cubic and Barabasi-Albert graphs we find the embedding performance of improved PSSA to consistently exceed the threshold of the best known complete graph embedding by a factor of 3.2 and 2.8, respectively, up to hardware graphs with 102,400 nodes. On the other hand, for random graphs with constant edge density not even improved PSSA can overcome the deterministic threshold guaranteed by the existence of the best known complete graph embedding. Finally, we prove a new upper bound on the maximal embeddable size of complete graphs into hardware graphs of CMOS annealers and show that the embedding performance of its currently best known complete graph embedding has optimal order for hardware graphs with fixed coordination number.",
    "title": "Minor-embedding heuristics for large-scale annealing processors with sparse hardware graphs of up to 102,400 nodes"
  },
  {
    "arxiv": "2004.04926",
    "counts": {
      "ComplEx": 3,
      "ConvE": 1,
      "DistMult": 2,
      "RESCAL": 2,
      "SE": 3,
      "SimplE": 2,
      "TransE": 2,
      "TuckER": 1
    },
    "published": "2020-04-10T07:09:30Z",
    "summary": "Most algorithms for representation learning and link prediction in relational data have been designed for static data. However, the data they are applied to usually evolves with time, such as friend graphs in social networks or user interactions with items in recommender systems. This is also the case for knowledge bases, which contain facts such as (US, has president, B. Obama, [2009-2017]) that are valid only at certain points in time. For the problem of link prediction under temporal constraints, i.e., answering queries such as (US, has president, ?, 2012), we propose a solution inspired by the canonical decomposition of tensors of order 4. We introduce new regularization schemes and present an extension of ComplEx (Trouillon et al., 2016) that achieves state-of-the-art performance. Additionally, we propose a new dataset for knowledge base completion constructed from Wikidata, larger than previous benchmarks by an order of magnitude, as a new reference for evaluating temporal and non-temporal link prediction methods.",
    "title": "Tensor Decompositions for temporal knowledge base completion"
  },
  {
    "arxiv": "2004.11588",
    "counts": {
      "ConvE": 1,
      "HypER": 1,
      "LINE": 1,
      "ProjE": 1,
      "SE": 1
    },
    "published": "2020-04-24T08:01:10Z",
    "summary": "The user review data have been demonstrated to be effective in solving different recommendation problems. Previous review-based recommendation methods usually employ sophisticated compositional models, such as Recurrent Neural Networks (RNN) and Convolutional Neural Networks (CNN), to learn semantic representations from the review data for recommendation. However, these methods mainly capture the local dependency between neighbouring words in a word window, and they treat each review equally. Therefore, they may not be effective in capturing the global dependency between words, and tend to be easily biased by noise review information. In this paper, we propose a novel review-based recommendation model, named Review Graph Neural Network (RGNN). Specifically, RGNN builds a specific review graph for each individual user/item, which provides a global view about the user/item properties to help weaken the biases caused by noise review information. A type-aware graph attention mechanism is developed to learn semantic embeddings of words. Moreover, a personalized graph pooling operator is proposed to learn hierarchical representations of the review graph to form the semantic representation for each user/item. We compared RGNN with state-of-the-art review-based recommendation approaches on two real-world datasets. The experimental results indicate that RGNN consistently outperforms baseline methods, in terms of Mean Square Error (MSE).",
    "title": "Learning Hierarchical Review Graph Representations for Recommendation"
  },
  {
    "arxiv": "2004.14183",
    "counts": {
      "ConvE": 1,
      "GeomE": 1,
      "SE": 1,
      "TransA": 1
    },
    "published": "2020-04-29T13:24:09Z",
    "summary": "We consider the problem of link prediction in networks whose edge structure may vary (sufficiently slowly) over time. This problem, with applications in many important areas including social networks, has two main variants: the first, known as positive link prediction or PLP consists in estimating the appearance of a link in the network. The second, known as negative link prediction or NLP consists in estimating the disappearance of a link in the network. We propose a data-driven approach to estimate the appearance/disappearance of edges. Our solution is based on a regularized optimization problem for which we prove existence and uniqueness of the optimal solution.",
    "title": "Link Prediction: A Graphical Model Approach"
  },
  {
    "arxiv": "2005.00460",
    "counts": {
      "ConvE": 2,
      "HypER": 4,
      "SE": 18,
      "TransF": 6
    },
    "published": "2020-05-01T15:55:50Z",
    "summary": "Medical entity linking is the task of identifying and standardizing medical concepts referred to in an unstructured text. Most of the existing methods adopt a three-step approach of (1) detecting mentions, (2) generating a list of candidate concepts, and finally (3) picking the best concept among them. In this paper, we probe into alleviating the problem of overgeneration of candidate concepts in the candidate generation module, the most under-studied component of medical entity linking. For this, we present MedType, a fully modular system that prunes out irrelevant candidate concepts based on the predicted semantic type of an entity mention. We incorporate MedType into five off-the-shelf toolkits for medical entity linking and demonstrate that it consistently improves entity linking performance across several benchmark datasets. To address the dearth of annotated training data for medical entity linking, we present WikiMed and PubMedDS, two large-scale medical entity linking datasets, and demonstrate that pre-training MedType on these datasets further improves entity linking performance. We make our source code and datasets publicly available for medical entity linking research.",
    "title": "Improving Broad-Coverage Medical Entity Linking with Semantic Type Prediction and Large-Scale Datasets"
  },
  {
    "arxiv": "2005.02419",
    "counts": {
      "FedE": 1,
      "GeomE": 1,
      "HypER": 1,
      "SE": 1
    },
    "published": "2020-05-05T18:00:27Z",
    "summary": "Several semi-analytic models (SAMs) try to explain how galaxies form, evolve and interact inside the dark matter large-scale structure. These SAMs can be tested by comparing their predictions for galaxy-galaxy-galaxy-lensing (G3L), which is weak gravitational lensing around galaxy pairs, with observations. We evaluate the SAMs by Henriques et al. (2015; H15) and by Lagos et al. (2012; L12), implemented in the Millennium Run, by comparing their predictions for G3L to observations at smaller scales than previous studies and also for pairs of lens galaxies from different populations. We compare the G3L signal predicted by the SAMs to measurements in the overlap of the Galaxy And Mass Assembly survey (GAMA), the Kilo-Degree Survey (KiDS), and the VISTA Kilo-degree Infrared Galaxy survey (VIKING), splitting lens galaxies into two colour and five stellar-mass samples. Using an improved G3L estimator, we measure the three-point correlation of the matter distribution for mixed lens pairs with galaxies from different samples, and unmixed lens pairs with galaxies from the same sample. Predictions by the H15 SAM agree with the observations for all colour-selected and all but one stellar-mass-selected sample with 95% confidence. Deviations occur for lenses with stellar masses below $9.5h^{-2}\\mathrm{M}_\\odot$ at scales below $0.2h^{-1}\\mathrm{Mpc}$. Predictions by the L12 SAM for stellar-mass selected samples and red galaxies are significantly higher than observed, while the predicted signal for blue galaxy pairs is too low. The L12 SAM predicts more pairs of small stellar-mass and red galaxies than the H15 SAM and the observations, as well as fewer pairs of blue galaxies. Likely explanations are different treatments of environmental effects by the SAMs and different models of the initial mass function. We conclude that G3L provides a stringent test for models of galaxy formation and evolution.",
    "title": "KiDS+VIKING+GAMA: Testing semi-analytic models of galaxy evolution with galaxy-galaxy-galaxy lensing"
  },
  {
    "arxiv": "2005.02525",
    "counts": {
      "DistMult": 1,
      "LINE": 1,
      "R-GCN": 1,
      "SE": 1
    },
    "published": "2020-05-05T22:46:39Z",
    "summary": "The recent developments and growing interest in neural-symbolic models has shown that hybrid approaches can offer richer models for Artificial Intelligence. The integration of effective relational learning and reasoning methods is one of the key challenges in this direction, as neural learning and symbolic reasoning offer complementary characteristics that can benefit the development of AI systems. Relational labelling or link prediction on knowledge graphs has become one of the main problems in deep learning-based natural language processing research. Moreover, other fields which make use of neural-symbolic techniques may also benefit from such research endeavours. There have been several efforts towards the identification of missing facts from existing ones in knowledge graphs. Two lines of research try and predict knowledge relations between two entities by considering all known facts connecting them or several paths of facts connecting them. We propose a neural-symbolic graph neural network which applies learning over all the paths by feeding the model with the embedding of the minimal subset of the knowledge graph containing such paths. By learning to produce representations for entities and facts corresponding to word embeddings, we show how the model can be trained end-to-end to decode these representations and infer relations between entities in a multitask approach. Our contribution is two-fold: a neural-symbolic methodology leverages the resolution of relational inference in large graphs, and we also demonstrate that such neural-symbolic model is shown more effective than path-based approaches",
    "title": "Neural-Symbolic Relational Reasoning on Graph Models: Effective Link Inference and Computation from Knowledge Bases"
  },
  {
    "arxiv": "2005.07496",
    "counts": {
      "ComplEx": 1,
      "R-GCN": 1,
      "RatE": 1,
      "SE": 1
    },
    "published": "2020-05-13T23:56:38Z",
    "summary": "Dynamic networks are used in a wide range of fields, including social network analysis, recommender systems and epidemiology. Representing complex networks as structures changing over time allow network models to leverage not only structural but also temporal patterns. However, as dynamic network literature stems from diverse fields and makes use of inconsistent terminology, it is challenging to navigate. Meanwhile, graph neural networks (GNNs) have gained a lot of attention in recent years for their ability to perform well on a range of network science tasks, such as link prediction and node classification. Despite the popularity of graph neural networks and the proven benefits of dynamic network models, there has been little focus on graph neural networks for dynamic networks. We aim to provide a review that demystifies dynamic networks, introduces dynamic graph neural networks (DGNNs) and appeals to researchers with a background in either network science or data science. We contribute: (i) a comprehensive dynamic network taxonomy, (ii) a survey of dynamic graph neural networks and (iii) an overview of how dynamic graph neural networks can be used for dynamic link prediction.",
    "title": "Foundations and modelling of dynamic networks using Dynamic Graph Neural Networks: A survey"
  },
  {
    "arxiv": "2005.07654",
    "counts": {
      "ComplEx": 3,
      "ConvE": 2,
      "DistMult": 3,
      "HypER": 1,
      "SE": 6,
      "SimplE": 1
    },
    "published": "2020-05-15T17:15:45Z",
    "summary": "Recently, link prediction algorithms based on neural embeddings have gained tremendous popularity in the Semantic Web community, and are extensively used for knowledge graph completion. While algorithmic advances have strongly focused on efficient ways of learning embeddings, fewer attention has been drawn to the different ways their performance and robustness can be evaluated. In this work we propose an open-source evaluation pipeline, which benchmarks the accuracy of neural embeddings in situations where knowledge graphs may experience semantic and structural changes. We define relation-centric connectivity measures that allow us to connect the link prediction capacity to the structure of the knowledge graph. Such an evaluation pipeline is especially important to simulate the accuracy of embeddings for knowledge graphs that are expected to be frequently updated.",
    "title": "Benchmarking neural embeddings for link prediction in knowledge graphs under semantic and structural changes"
  },
  {
    "arxiv": "2005.14612",
    "counts": {
      "ComplEx": 1,
      "GeomE": 1,
      "GraphSAGE": 1,
      "SE": 1,
      "TransF": 1
    },
    "published": "2020-05-29T14:50:27Z",
    "summary": "Modern graph neural networks (GNNs) learn node embeddings through multilayer local aggregation and achieve great success in applications on assortative graphs. However, tasks on disassortative graphs usually require non-local aggregation. In this work, we propose a simple yet effective non-local aggregation framework with an efficient attention-guided sorting for GNNs. Based on it, we develop various non-local GNNs. We perform thorough experiments to analyze disassortative graph datasets and evaluate our non-local GNNs. Experimental results demonstrate that our non-local GNNs significantly outperform previous state-of-the-art methods on six benchmark datasets of disassortative graphs, in terms of both model performance and efficiency.",
    "title": "Non-Local Graph Neural Networks"
  },
  {
    "arxiv": "2006.03804",
    "counts": {
      "ConvE": 1,
      "HypER": 1,
      "LINE": 1,
      "NAM": 1,
      "SE": 1,
      "TransA": 1
    },
    "published": "2020-06-06T07:28:03Z",
    "summary": "Dynamic networks have intrinsic structural, computational, and multidisciplinary advantages. Link prediction estimates the next relationship in dynamic networks. However, in the current link prediction approaches, only bipartite or non-bipartite but homogeneous networks are considered. The use of adjacency matrix to represent dynamically evolving networks limits the ability to analytically learn from heterogeneous, sparse, or forming networks. In the case of a heterogeneous network, modeling all network states using a binary-valued matrix can be difficult. On the other hand, sparse or currently forming networks have many missing edges, which are represented as zeros, thus introducing class imbalance or noise. We propose a time-parameterized matrix (TP-matrix) and empirically demonstrate its effectiveness in non-bipartite, heterogeneous networks. In addition, we propose a predictive influence index as a measure of a node's boosting or diminishing predictive influence using backward and forward-looking maximization over the temporal space of the n-degree neighborhood. We further propose a new method of canonically representing heterogeneous time-evolving activities as a temporally parameterized network model (TPNM). The new method robustly enables activities to be represented as a form of a network, thus potentially inspiring new link prediction applications, including intelligent business process management systems and context-aware workflow engines. We evaluated our model on four datasets of different network systems. We present results that show the proposed model is more effective in capturing and retaining temporal relationships in dynamically evolving networks. We also show that our model performed better than state-of-the-art link prediction benchmark results for networks that are sensitive to temporal evolution.",
    "title": "Link Prediction for Temporally Consistent Networks"
  },
  {
    "arxiv": "2006.04159",
    "counts": {
      "LINE": 1,
      "NAM": 2,
      "SE": 3,
      "TransF": 1
    },
    "published": "2020-06-07T14:24:32Z",
    "summary": "Learning distributions of graphs can be used for automatic drug discovery, molecular design, complex network analysis, and much more. We present an improved framework for learning generative models of graphs based on the idea of deep state machines. To learn state transition decisions we use a set of graph and node embedding techniques as memory of the state machine. Our analysis is based on learning the distribution of random graph generators for which we provide statistical tests to determine which properties can be learned and how well the original distribution of graphs is represented. We show that the design of the state machine favors specific distributions. Models of graphs of size up to 150 vertices are learned. Code and parameters are publicly available to reproduce our results.",
    "title": "DeepGG: a Deep Graph Generator"
  },
  {
    "arxiv": "2006.05718",
    "counts": {
      "ConvE": 1,
      "LINE": 1,
      "RatE": 1,
      "SE": 1,
      "TransD": 1,
      "TransE": 1
    },
    "published": "2020-06-10T08:20:13Z",
    "summary": "Fraud review detection is a hot research topic inrecent years. The Cold-start is a particularly new but significant problem referring to the failure of a detection system to recognize the authenticity of a new user. State-of-the-art solutions employ a translational knowledge graph embedding approach (TransE) to model the interaction of the components of a review system. However, these approaches suffer from the limitation of TransEin handling N-1 relations and the narrow scope of a single classification task, i.e., detecting fraudsters only. In this paper, we model a review system as a Heterogeneous InformationNetwork (HIN) which enables a unique representation to every component and performs graph inductive learning on the review data through aggregating features of nearby nodes. HIN with graph induction helps to address the camouflage issue (fraudsterswith genuine reviews) which has shown to be more severe when it is coupled with cold-start, i.e., new fraudsters with genuine first reviews. In this research, instead of focusing only on one component, detecting either fraud reviews or fraud users (fraudsters), vector representations are learnt for each component, enabling multi-component classification. In other words, we are able to detect fraud reviews, fraudsters, and fraud-targeted items, thus the name of our approach DFraud3. DFraud3 demonstrates a significant accuracy increase of 13% over the state of the art on Yelp.",
    "title": "DFraud3- Multi-Component Fraud Detection freeof Cold-start"
  },
  {
    "arxiv": "2006.06648",
    "counts": {
      "CompGCN": 2,
      "ComplEx": 5,
      "ConvE": 4,
      "ConvKB": 2,
      "DistMult": 8,
      "GraphSAGE": 1,
      "LINE": 1,
      "R-GCN": 6,
      "RotatE": 4,
      "SE": 7,
      "TransD": 6,
      "TransE": 8,
      "TransH": 1
    },
    "published": "2020-06-11T17:42:46Z",
    "summary": "Many practical graph problems, such as knowledge graph construction and drug-drug interaction prediction, require to handle multi-relational graphs. However, handling real-world multi-relational graphs with Graph Neural Networks (GNNs) is often challenging due to their evolving nature, as new entities (nodes) can emerge over time. Moreover, newly emerged entities often have few links, which makes the learning even more difficult. Motivated by this challenge, we introduce a realistic problem of few-shot out-of-graph link prediction, where we not only predict the links between the seen and unseen nodes as in a conventional out-of-knowledge link prediction task but also between the unseen nodes, with only few edges per node. We tackle this problem with a novel transductive meta-learning framework which we refer to as Graph Extrapolation Networks (GEN). GEN meta-learns both the node embedding network for inductive inference (seen-to-unseen) and the link prediction network for transductive inference (unseen-to-unseen). For transductive link prediction, we further propose a stochastic embedding layer to model uncertainty in the link prediction between unseen entities. We validate our model on multiple benchmark datasets for knowledge graph completion and drug-drug interaction prediction. The results show that our model significantly outperforms relevant baselines for out-of-graph link prediction tasks.",
    "title": "Learning to Extrapolate Knowledge: Transductive Few-shot Out-of-Graph Link Prediction"
  },
  {
    "arxiv": "2006.07331",
    "counts": {
      "CompGCN": 1,
      "ComplEx": 1,
      "DistMult": 1,
      "NTN": 1,
      "QuatE": 1,
      "R-GCN": 1,
      "RotatE": 1,
      "SE": 1,
      "TransD": 1,
      "TransE": 1,
      "TransH": 1
    },
    "published": "2020-06-12T17:12:51Z",
    "summary": "Graph Convolutional Networks (GCNs) have received increasing attention in recent machine learning. How to effectively leverage the rich structural information in complex graphs, such as knowledge graphs with heterogeneous types of entities and relations, is a primary open challenge in the field. Most GCN methods are either restricted to graphs with a homogeneous type of edges (e.g., citation links only), or focusing on representation learning for nodes only instead of jointly optimizing the embeddings of both nodes and edges for target-driven objectives. This paper addresses these limitations by proposing a novel framework, namely the GEneralized Multi-relational Graph Convolutional Networks (GEM-GCN), which combines the power of GCNs in graph-based belief propagation and the strengths of advanced knowledge-base embedding methods, and goes beyond. Our theoretical analysis shows that GEM-GCN offers an elegant unification of several well-known GCN methods as specific cases, with a new perspective of graph convolution. Experimental results on benchmark datasets show the advantageous performance of GEM-GCN over strong baseline methods in the tasks of knowledge graph alignment and entity classification.",
    "title": "Generalized Multi-Relational Graph Convolution Network"
  },
  {
    "arxiv": "2006.09430",
    "counts": {
      "GeomE": 2,
      "GraphSAGE": 2,
      "HypER": 2,
      "LINE": 2,
      "SE": 3
    },
    "published": "2020-06-16T18:23:00Z",
    "summary": "We present Wasserstein Embedding for Graph Learning (WEGL), a novel and fast framework for embedding entire graphs in a vector space, in which various machine learning models are applicable for graph-level prediction tasks. We leverage new insights on defining similarity between graphs as a function of the similarity between their node embedding distributions. Specifically, we use the Wasserstein distance to measure the dissimilarity between node embeddings of different graphs. Unlike prior work, we avoid pairwise calculation of distances between graphs and reduce the computational complexity from quadratic to linear in the number of graphs. WEGL calculates Monge maps from a reference distribution to each node embedding and, based on these maps, creates a fixed-sized vector representation of the graph. We evaluate our new graph embedding approach on various benchmark graph-property prediction tasks, showing state-of-the-art classification performance while having superior computational efficiency. The code is available at https://github.com/navid-naderi/WEGL.",
    "title": "Wasserstein Embedding for Graph Learning"
  },
  {
    "arxiv": "2006.12294",
    "counts": {
      "ComplEx": 1,
      "GeomE": 1,
      "GraphSAGE": 2,
      "HypER": 1,
      "SE": 8,
      "TransF": 1
    },
    "published": "2020-06-22T14:27:02Z",
    "summary": "Graph convolution operator of the GCN model is originally motivated from a localized first-order approximation of spectral graph convolutions. This work stands on a different view; establishing a \\textit{mathematical connection between graph convolution and graph-regularized PCA} (GPCA). Based on this connection, GCN architecture, shaped by stacking graph convolution layers, shares a close relationship with stacking GPCA. We empirically demonstrate that the \\textit{unsupervised} embeddings by GPCA paired with a 1- or 2-layer MLP achieves similar or even better performance than GCN on semi-supervised node classification tasks across five datasets including Open Graph Benchmark \\footnote{\\url{https://ogb.stanford.edu/}}. This suggests that the prowess of GCN is driven by graph based regularization. In addition, we extend GPCA to the (semi-)supervised setting and show that it is equivalent to GPCA on a graph extended with \"ghost\" edges between nodes of the same label. Finally, we capitalize on the discovered relationship to design an effective initialization strategy based on stacking GPCA, enabling GCN to converge faster and achieve robust performance at large number of layers. Notably, the proposed initialization is general-purpose and applies to other GNNs.",
    "title": "Connecting Graph Convolutional Networks and Graph-Regularized PCA"
  },
  {
    "arxiv": "2006.13009",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "GraphSAGE": 1,
      "HypER": 1,
      "LINE": 1,
      "ProjE": 1,
      "SE": 2,
      "TransF": 1
    },
    "published": "2020-06-21T19:49:15Z",
    "summary": "In this paper, we propose an end-to-end graph learning framework, namely Iterative Deep Graph Learning (IDGL), for jointly and iteratively learning graph structure and graph embedding. The key rationale of IDGL is to learn a better graph structure based on better node embeddings, and vice versa (i.e., better node embeddings based on a better graph structure). Our iterative method dynamically stops when the learned graph structure approaches close enough to the graph optimized for the downstream prediction task. In addition, we cast the graph learning problem as a similarity metric learning problem and leverage adaptive graph regularization for controlling the quality of the learned graph. Finally, combining the anchor-based approximation technique, we further propose a scalable version of IDGL, namely IDGL-Anch, which significantly reduces the time and space complexity of IDGL without compromising the performance. Our extensive experiments on nine benchmarks show that our proposed IDGL models can consistently outperform or match the state-of-the-art baselines. Furthermore, IDGL can be more robust to adversarial graphs and cope with both transductive and inductive learning.",
    "title": "Iterative Deep Graph Learning for Graph Neural Networks: Better and Robust Node Embeddings"
  },
  {
    "arxiv": "2007.01594",
    "counts": {
      "ConvE": 1,
      "HypER": 1,
      "NAM": 3,
      "SE": 3,
      "node2vec": 1
    },
    "published": "2020-07-03T10:20:34Z",
    "summary": "Attributed graph embedding, which learns vector representations from graph topology and node features, is a challenging task for graph analysis. Recently, methods based on graph convolutional networks (GCNs) have made great progress on this task. However,existing GCN-based methods have three major drawbacks. Firstly,our experiments indicate that the entanglement of graph convolutional filters and weight matrices will harm both the performance and robustness. Secondly, we show that graph convolutional filters in these methods reveal to be special cases of generalized Laplacian smoothing filters, but they do not preserve optimal low-pass characteristics. Finally, the training objectives of existing algorithms are usually recovering the adjacency matrix or feature matrix, which are not always consistent with real-world applications. To address these issues, we propose Adaptive Graph Encoder (AGE), a novel attributed graph embedding framework. AGE consists of two modules: (1) To better alleviate the high-frequency noises in the node features, AGE first applies a carefully-designed Laplacian smoothing filter. (2) AGE employs an adaptive encoder that iteratively strengthens the filtered features for better node embeddings. We conduct experiments using four public benchmark datasets to validate AGE on node clustering and link prediction tasks. Experimental results show that AGE consistently outperforms state-of-the-art graph embedding methods considerably on these tasks.",
    "title": "Adaptive Graph Encoder for Attributed Graph Embedding"
  },
  {
    "arxiv": "2007.08025",
    "counts": {
      "GeomE": 1,
      "GraphSAGE": 1,
      "LINE": 1,
      "SE": 1,
      "TransD": 1,
      "node2vec": 1
    },
    "published": "2020-07-15T22:36:53Z",
    "summary": "We propose Graph Contrastive Learning (GraphCL), a general framework for learning node representations in a self supervised manner. GraphCL learns node embeddings by maximizing the similarity between the representations of two randomly perturbed versions of the intrinsic features and link structure of the same node's local subgraph. We use graph neural networks to produce two representations of the same node and leverage a contrastive learning loss to maximize agreement between them. In both transductive and inductive learning setups, we demonstrate that our approach significantly outperforms the state-of-the-art in unsupervised learning on a number of node classification benchmarks.",
    "title": "GraphCL: Contrastive Self-Supervised Learning of Graph Representations"
  },
  {
    "arxiv": "2007.08053",
    "counts": {
      "SDNE": 1,
      "SE": 1,
      "TransD": 1,
      "node2vec": 1
    },
    "published": "2020-07-16T00:51:51Z",
    "summary": "Predicting the link between two nodes is a fundamental problem for graph data analytics. In attributed graphs, both the structure and attribute information can be utilized for link prediction. Most existing studies focus on transductive link prediction where both nodes are already in the graph. However, many real-world applications require inductive prediction for new nodes having only attribute information. It is more challenging since the new nodes do not have structure information and cannot be seen during the model training. To solve this problem, we propose a model called DEAL, which consists of three components: two node embedding encoders and one alignment mechanism. The two encoders aim to output the attribute-oriented node embedding and the structure-oriented node embedding, and the alignment mechanism aligns the two types of embeddings to build the connections between the attributes and links. Our model DEAL is versatile in the sense that it works for both inductive and transductive link prediction. Extensive experiments on several benchmark datasets show that our proposed model significantly outperforms existing inductive link prediction methods, and also outperforms the state-of-the-art methods on transductive link prediction.",
    "title": "Inductive Link Prediction for Nodes Having Only Attribute Information"
  },
  {
    "arxiv": "2007.11164",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "HolE": 1,
      "LINE": 1,
      "SE": 1,
      "TranSparse": 1,
      "TransD": 1,
      "TransE": 1,
      "TransF": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2020-07-22T02:20:25Z",
    "summary": "Knowledge graph embedding, which aims to learn the low-dimensional representations of entities and relationships, has attracted considerable research efforts recently. However, most knowledge graph embedding methods focus on the structural relationships in fixed triples while ignoring the temporal information. Currently, existing time-aware graph embedding methods only focus on the factual plausibility, while ignoring the temporal smoothness which models the interactions between a fact and its contexts, and thus can capture fine-granularity temporal relationships. This leads to the limited performance of embedding related applications. To solve this problem, this paper presents a Robustly Time-aware Graph Embedding (RTGE) method by incorporating temporal smoothness. Two major innovations of our paper are presented here. At first, RTGE integrates a measure of temporal smoothness in the learning process of the time-aware graph embedding. Via the proposed additional smoothing factor, RTGE can preserve both structural information and evolutionary patterns of a given graph. Secondly, RTGE provides a general task-oriented negative sampling strategy associated with temporally-aware information, which further improves the adaptive ability of the proposed algorithm and plays an essential role in obtaining superior performance in various tasks. Extensive experiments conducted on multiple benchmark tasks show that RTGE can increase performance in entity/relationship/temporal scoping prediction tasks.",
    "title": "Time-aware Graph Embedding: A temporal smoothness and task-oriented approach"
  },
  {
    "arxiv": "2007.11192",
    "counts": {
      "CompGCN": 2,
      "ComplEx": 2,
      "LINE": 1,
      "MuRE": 1,
      "SE": 3,
      "TransE": 1,
      "TransF": 2,
      "metapath2vec": 4,
      "node2vec": 3
    },
    "published": "2020-07-22T03:48:53Z",
    "summary": "Representation learning methods for heterogeneous networks produce a low-dimensional vector embedding for each node that is typically fixed for all tasks involving the node. Many of the existing methods focus on obtaining a static vector representation for a node in a way that is agnostic to the downstream application where it is being used. In practice, however, downstream tasks such as link prediction require specific contextual information that can be extracted from the subgraphs related to the nodes provided as input to the task. To tackle this challenge, we develop SLiCE, a framework bridging static representation learning methods using global information from the entire graph with localized attention driven mechanisms to learn contextual node representations. We first pre-train our model in a self-supervised manner by introducing higher-order semantic associations and masking nodes, and then fine-tune our model for a specific link prediction task. Instead of training node representations by aggregating information from all semantic neighbors connected via metapaths, we automatically learn the composition of different metapaths that characterize the context for a specific task without the need for any pre-defined metapaths. SLiCE significantly outperforms both static and contextual embedding learning methods on several publicly available benchmark network datasets. We also interpret the semantic association matrix and provide its utility and relevance in making successful link predictions between heterogeneous nodes in the network.",
    "title": "Self-Supervised Learning of Contextual Embeddings for Link Prediction in Heterogeneous Networks"
  },
  {
    "arxiv": "2008.02807",
    "counts": {
      "ComplEx": 1,
      "ProjE": 1,
      "QuatE": 1,
      "SE": 1
    },
    "published": "2020-08-06T18:00:01Z",
    "summary": "We study a class of topological materials which in their momentum-space band structure exhibit three-fold degeneracies known as triple points. Focusing specifically on $\\mathcal{P}\\mathcal{T}$-symmetric crystalline solids with negligible spin-orbit coupling, we find that such triple points can be stabilized by little groups containing a three-, four- or six-fold rotation axis, and we develop a classification of all possible triple points as type-A vs. type-B according to the absence vs. presence of attached nodal-line arcs. Furthermore, by employing the recently discovered non-Abelian band topology, we argue that a rotation-symmetry-breaking strain transforms type-A triple points into multi-band nodal links. Although multi-band nodal-line compositions were previously theoretically conceived and related to topological monopole charges, a practical condensed-matter platform for their manipulation and inspection has hitherto been missing. By reviewing the known triple-point materials with weak spin-orbit coupling, and by performing first-principles calculations to predict new ones, we identify suitable candidates for the realization of multi-band nodal links in applied strain. In particular, we report that an ideal compound to study this phenomenon is Li$_2$NaN, in which the conversion of triple points to multi-band nodal links facilitates largely tunable density of states and optical conductivity with doping and strain, respectively.",
    "title": "From triple-point materials to multiband nodal links"
  },
  {
    "arxiv": "2008.05089",
    "counts": {
      "GraphSAGE": 1,
      "HypER": 1,
      "ProjE": 1,
      "QuatE": 1,
      "SE": 1
    },
    "published": "2020-08-12T03:41:03Z",
    "summary": "Recently, graph neural networks (GNNs) become a principal research direction to learn low-dimensional continuous embeddings of nodes and graphs to predict node and graph labels, respectively. However, Euclidean embeddings have high distortion when using GNNs to model complex graphs such as social networks. Furthermore, existing GNNs are not very efficient with the high number of model parameters when increasing the number of hidden layers. Therefore, we move beyond the Euclidean space to a hyper-complex vector space to improve graph representation quality and reduce the number of model parameters. To this end, we propose quaternion graph neural networks (QGNN) to generalize GCNs within the Quaternion space to learn quaternion embeddings for nodes and graphs. The Quaternion space, a hyper-complex vector space, provides highly meaningful computations through Hamilton product compared to the Euclidean and complex vector spaces. As a result, our QGNN can reduce the model size up to four times and enhance learning better graph representations. Experimental results show that the proposed QGNN produces state-of-the-art accuracies on a range of well-known benchmark datasets for three downstream tasks, including graph classification, semi-supervised node classification, and text (node) classification. Our code is available at: https://github.com/daiquocnguyen/QGNN",
    "title": "Quaternion Graph Neural Networks"
  },
  {
    "arxiv": "2008.06940",
    "counts": {
      "CrossE": 1,
      "LINE": 1,
      "ProjE": 1,
      "RatE": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2020-08-16T15:39:07Z",
    "summary": "Understanding the evolutionary patterns of real-world evolving complex systems such as human interactions, transport networks, biological interactions, and computer networks has important implications in our daily lives. Predicting future links among the nodes in such networks reveals an important aspect of the evolution of temporal networks. To analyse networks, they are mapped to adjacency matrices, however, a single adjacency matrix cannot represent complex relationships (e.g. temporal pattern), and therefore, some approaches consider a simplified representation of temporal networks but in high-dimensional and generally sparse matrices. As a result, adjacency matrices cannot be directly used by machine learning models for making network or node level predictions. To overcome this problem, automated frameworks are proposed for learning low-dimensional vectors for nodes or edges, as state-of-the-art techniques in predicting temporal patterns in networks such as link prediction. However, these models fail to consider temporal dimensions of the networks. This gap motivated us to propose in this research a new node embedding technique which exploits the evolving nature of the networks considering a simple three-layer graph neural network at each time step, and extracting node orientation by Given's angle method. To prove our proposed algorithm's efficiency, we evaluated the efficiency of our proposed algorithm against six state-of-the-art benchmark network embedding models, on four real temporal networks data, and the results show our model outperforms other methods in predicting future links in temporal networks.",
    "title": "TempNodeEmb:Temporal Node Embedding considering temporal edge influence matrix"
  },
  {
    "arxiv": "2008.08879",
    "counts": {
      "MuRP": 1,
      "NAM": 1,
      "SE": 1,
      "TransA": 1,
      "node2vec": 1
    },
    "published": "2020-08-20T10:41:53Z",
    "summary": "The task of inferring the missing links in a graph based on its current structure is referred to as link prediction. Link prediction methods that are based on pairwise node similarity are well-established approaches in the literature. They show good prediction performance in many real-world graphs though they are heuristics and lack of universal applicability. On the other hand, the success of neural networks for classification tasks in various domains leads researchers to study them in graphs. When a neural network can operate directly on the graph, then it is termed as the graph neural network (GNN). GNN is able to learn hidden features from graphs which can be used for link prediction task in graphs. Link predictions based on GNNs have gained much attention of researchers due to their convincing high performance in many real-world graphs. This appraisal paper studies some similarity and GNN-based link prediction approaches in the domain of homogeneous graphs that consists of a single type of (attributed) nodes and single type of pairwise links. We evaluate the studied approaches against several benchmark graphs with different properties from various domains.",
    "title": "A comparative study of similarity-based and GNN-based link prediction approaches"
  },
  {
    "arxiv": "2008.09791",
    "counts": {
      "LINE": 1,
      "ProjE": 1,
      "SE": 7,
      "TransF": 5
    },
    "published": "2020-08-22T09:50:43Z",
    "summary": "Standard video and movie description tasks abstract away from person identities, thus failing to link identities across sentences. We propose a multi-sentence Identity-Aware Video Description task, which overcomes this limitation and requires to re-identify persons locally within a set of consecutive clips. We introduce an auxiliary task of Fill-in the Identity, that aims to predict persons' IDs consistently within a set of clips, when the video descriptions are given. Our proposed approach to this task leverages a Transformer architecture allowing for coherent joint prediction of multiple IDs. One of the key components is a gender-aware textual representation as well an additional gender prediction objective in the main model. This auxiliary task allows us to propose a two-stage approach to Identity-Aware Video Description. We first generate multi-sentence video descriptions, and then apply our Fill-in the Identity model to establish links between the predicted person entities. To be able to tackle both tasks, we augment the Large Scale Movie Description Challenge (LSMDC) benchmark with new annotations suited for our problem statement. Experiments show that our proposed Fill-in the Identity model is superior to several baselines and recent works, and allows us to generate descriptions with locally re-identified people.",
    "title": "Identity-Aware Multi-Sentence Video Description"
  },
  {
    "arxiv": "2008.10021",
    "counts": {
      "ComplEx": 1,
      "GraphSAGE": 1,
      "Motif2Vec": 1,
      "SE": 1
    },
    "published": "2020-08-23T11:56:40Z",
    "summary": "The development of graph neural networks (GCN) makes it possible to learn structural features from evolving complex networks. Even though a wide range of realistic networks are directed ones, few existing works investigated the properties of directed and temporal networks. In this paper, we address the problem of temporal link prediction in directed networks and propose a deep learning model based on GCN and self-attention mechanism, namely TSAM. The proposed model adopts an autoencoder architecture, which utilizes graph attentional layers to capture the structural feature of neighborhood nodes, as well as a set of graph convolutional layers to capture motif features. A graph recurrent unit layer with self-attention is utilized to learn temporal variations in the snapshot sequence. We run comparative experiments on four realistic networks to validate the effectiveness of TSAM. Experimental results show that TSAM outperforms most benchmarks under two evaluation metrics.",
    "title": "TSAM: Temporal Link Prediction in Directed Networks based on Self-Attention Mechanism"
  },
  {
    "arxiv": "2009.01674",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "GraphSAGE": 1,
      "HypER": 1,
      "LINE": 2,
      "SE": 5,
      "node2vec": 3
    },
    "published": "2020-09-03T13:57:18Z",
    "summary": "Unsupervised graph representation learning aims to learn low-dimensional node embeddings without supervision while preserving graph topological structures and node attributive features. Previous graph neural networks (GNN) require a large number of labeled nodes, which may not be accessible in real-world graph data. In this paper, we present a novel cluster-aware graph neural network (CAGNN) model for unsupervised graph representation learning using self-supervised techniques. In CAGNN, we perform clustering on the node embeddings and update the model parameters by predicting the cluster assignments. Moreover, we observe that graphs often contain inter-class edges, which mislead the GNN model to aggregate noisy information from neighborhood nodes. We further refine the graph topology by strengthening intra-class edges and reducing node connections between different classes based on cluster labels, which better preserves cluster structures in the embedding space. We conduct comprehensive experiments on two benchmark tasks using real-world datasets. The results demonstrate the superior performance of the proposed model over existing baseline methods. Notably, our model gains over 7% improvements in terms of accuracy on node clustering over state-of-the-arts.",
    "title": "CAGNN: Cluster-Aware Graph Neural Networks for Unsupervised Graph Representation Learning"
  },
  {
    "arxiv": "2009.05265",
    "counts": {
      "LINE": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2020-09-11T07:49:21Z",
    "summary": "Graph embedding methods are becoming increasingly popular in the machine learning community, where they are widely used for tasks such as node classification and link prediction. Embedding graphs in geometric spaces should aid the identification of network communities as well, because nodes in the same community should be projected close to each other in the geometric space, where they can be detected via standard data clustering algorithms. In this paper, we test the ability of several graph embedding techniques to detect communities on benchmark graphs. We compare their performance against that of traditional community detection algorithms. We find that the performance is comparable, if the parameters of the embedding techniques are suitably chosen. However, the optimal parameter set varies with the specific features of the benchmark graphs, like their size, whereas popular community detection algorithms do not require any parameter. So it is not possible to indicate beforehand good parameter sets for the analysis of real networks. This finding, along with the high computational cost of embedding a network and grouping the points, suggests that, for community detection, current embedding techniques do not represent an improvement over network clustering algorithms.",
    "title": "Community detection in networks using graph embeddings"
  },
  {
    "arxiv": "2009.07392",
    "counts": {
      "LINE": 1,
      "NAM": 1,
      "SE": 1
    },
    "published": "2020-09-15T23:39:13Z",
    "summary": "An ongoing challenge for the requirements engineering of software product lines is to predict whether a new combination of features (units of functionality) will create an unwanted or even hazardous feature interaction. We thus seek to improve and automate the prediction of unwanted feature interactions early in development. In this paper, we show how the detection of unwanted feature interactions in a software product line can be effectively represented as a link prediction problem. Link prediction uses machine learning algorithms and similarity scores among a graph's nodes to identify likely new edges. We here model the software product line features as nodes and the unwanted interactions among the features as edges. We investigate six link-based similarity metrics, some using local and some using global knowledge of the graph, for use in this context. We evaluate our approach on a software product line benchmark in the literature, building six machine-learning models from the graph-based similarity data. Results show that the best ML algorithms achieved an accuracy of 0.75 to 1 for classifying feature interactions as unwanted or wanted in this small study and that global similarity metrics performed better than local similarity metrics. The work shows how link-prediction models can help find missing edges, which represent unwanted feature interactions that are undocumented or unrecognized, earlier in development.",
    "title": "Does Link Prediction Help Detect Feature Interactions in Software Product Lines (SPLs)?"
  },
  {
    "arxiv": "2009.07429",
    "counts": {
      "LINE": 1,
      "ProjE": 1,
      "SE": 1,
      "TACT": 1,
      "node2vec": 1
    },
    "published": "2020-09-16T02:33:32Z",
    "summary": "Job Title Benchmarking (JTB) aims at matching job titles with similar expertise levels across various companies. JTB could provide precise guidance and considerable convenience for both talent recruitment and job seekers for position and salary calibration/prediction. Traditional JTB approaches mainly rely on manual market surveys, which is expensive and labor-intensive. Recently, the rapid development of Online Professional Graph has accumulated a large number of talent career records, which provides a promising trend for data-driven solutions. However, it is still a challenging task since (1) the job title and job transition (job-hopping) data is messy which contains a lot of subjective and non-standard naming conventions for the same position (e.g., Programmer, Software Development Engineer, SDE, Implementation Engineer), (2) there is a large amount of missing title/transition information, and (3) one talent only seeks limited numbers of jobs which brings the incompleteness and randomness modeling job transition patterns. To overcome these challenges, we aggregate all the records to construct a large-scale Job Title Benchmarking Graph (Job-Graph), where nodes denote job titles affiliated with specific companies and links denote the correlations between jobs. We reformulate the JTB as the task of link prediction over the Job-Graph that matched job titles should have links. Along this line, we propose a collective multi-view representation learning method (Job2Vec) by examining the Job-Graph jointly in (1) graph topology view, (2)semantic view, (3) job transition balance view, and (4) job transition duration view. We fuse the multi-view representations in the encode-decode paradigm to obtain a unified optimal representation for the task of link prediction. Finally, we conduct extensive experiments to validate the effectiveness of our proposed method.",
    "title": "Job2Vec: Job Title Benchmarking with Collective Multi-View Representation Learning"
  },
  {
    "arxiv": "2009.07810",
    "counts": {
      "ComplEx": 4,
      "ConvE": 3,
      "DistMult": 1,
      "HypER": 2,
      "LINE": 1,
      "ProjE": 1,
      "RESCAL": 4,
      "SE": 7,
      "TransE": 3,
      "TuckER": 3
    },
    "published": "2020-09-16T17:08:23Z",
    "summary": "We present CoDEx, a set of knowledge graph completion datasets extracted from Wikidata and Wikipedia that improve upon existing knowledge graph completion benchmarks in scope and level of difficulty. In terms of scope, CoDEx comprises three knowledge graphs varying in size and structure, multilingual descriptions of entities and relations, and tens of thousands of hard negative triples that are plausible but verified to be false. To characterize CoDEx, we contribute thorough empirical analyses and benchmarking experiments. First, we analyze each CoDEx dataset in terms of logical relation patterns. Next, we report baseline link prediction and triple classification results on CoDEx for five extensively tuned embedding models. Finally, we differentiate CoDEx from the popular FB15K-237 knowledge graph completion dataset by showing that CoDEx covers more diverse and interpretable content, and is a more difficult link prediction benchmark. Data, code, and pretrained models are available at https://bit.ly/2EPbrJs.",
    "title": "CoDEx: A Comprehensive Knowledge Graph Completion Benchmark"
  },
  {
    "arxiv": "2009.09764",
    "counts": {
      "HypER": 1,
      "LINE": 1,
      "NAM": 1,
      "SE": 2
    },
    "published": "2020-09-21T11:30:07Z",
    "summary": "This article reviews and evaluates models of network evolution based on the notion of structural diversity. We show that diversity is an underlying theme of three principles of network evolution: the preferential attachment model, connectivity and link prediction. We show that in all three cases, a dominant trend towards shrinking diversity is apparent, both theoretically and empirically. In previous work, many kinds of different data have been modeled as networks: social structure, navigational structure, transport infrastructure, communication, etc. Almost all these types of networks are not static structures, but instead dynamic systems that change continuously. Thus, an important question concerns the trends observable in these networks and their interpretation in terms of existing network models. We show in this article that most numerical network characteristics follow statistically significant trends going either up or down, and that these trends can be predicted by considering the notion of diversity. Our work extends previous work observing a shrinking network diameter to measures such as the clustering coefficient, power-law exponent and random walk return probability, and justifies preferential attachment models and link prediction algorithms. We evaluate our hypothesis experimentally using a diverse collection of twenty-seven temporally evolving real-world network datasets.",
    "title": "Modeling the Evolution of Networks as Shrinking Structural Diversity"
  },
  {
    "arxiv": "2009.10367",
    "counts": {
      "GraphSAGE": 1,
      "LINE": 1,
      "ProjE": 1,
      "SDNE": 1,
      "SE": 1,
      "TransA": 1,
      "node2vec": 1
    },
    "published": "2020-09-22T07:49:46Z",
    "summary": "The network embedding problem that maps nodes in a graph to vectors in Euclidean space can be very useful for addressing several important tasks on a graph. Recently, graph neural networks (GNNs) have been proposed for solving such a problem. However, most embedding algorithms and GNNs are difficult to interpret and do not scale well to handle millions of nodes. In this paper, we tackle the problem from a new perspective based on the equivalence of three constrained optimization problems: the network embedding problem, the trace maximization problem of the modularity matrix in a sampled graph, and the matrix factorization problem of the modularity matrix in a sampled graph. The optimal solutions to these three problems are the dominant eigenvectors of the modularity matrix. We proposed two algorithms that belong to a special class of graph convolutional networks (GCNs) for solving these problems: (i) Clustering As Feature Embedding GCN (CAFE-GCN) and (ii) sphere-GCN. Both algorithms are stable trace maximization algorithms, and they yield good approximations of dominant eigenvectors. Moreover, there are linear-time implementations for sparse graphs. In addition to solving the network embedding problem, both proposed GCNs are capable of performing dimensionality reduction. Various experiments are conducted to evaluate our proposed GCNs and show that our proposed GCNs outperform almost all the baseline methods. Moreover, CAFE-GCN could be benefited from the labeled data and have tremendous improvements in various performance metrics.",
    "title": "Explainable, Stable, and Scalable Graph Convolutional Networks for Learning Graph Representation"
  },
  {
    "arxiv": "2009.10800",
    "counts": {
      "ComplEx": 8,
      "ConvE": 3,
      "DistMult": 5,
      "HypER": 1,
      "NAM": 1,
      "RESCAL": 4,
      "RotatE": 9,
      "SE": 3,
      "SimplE": 1,
      "TransE": 9
    },
    "published": "2020-09-22T20:29:27Z",
    "summary": "The problem of knowledge graph (KG) reasoning has been widely explored by traditional rule-based systems and more recently by knowledge graph embedding methods. While logical rules can capture deterministic behavior in a KG they are brittle and mining ones that infer facts beyond the known KG is challenging. Probabilistic embedding methods are effective in capturing global soft statistical tendencies and reasoning with them is computationally efficient. While embedding representations learned from rich training data are expressive, incompleteness and sparsity in real-world KGs can impact their effectiveness. We aim to leverage the complementary properties of both methods to develop a hybrid model that learns both high-quality rules and embeddings simultaneously. Our method uses a cross feedback paradigm wherein, an embedding model is used to guide the search of a rule mining system to mine rules and infer new facts. These new facts are sampled and further used to refine the embedding model. Experiments on multiple benchmark datasets show the effectiveness of our method over other competitive standalone and hybrid baselines. We also show its efficacy in a sparse KG setting and finally explore the connection with negative sampling.",
    "title": "A Hybrid Model for Learning Embeddings and Logical Rules Simultaneously from Knowledge Graphs"
  },
  {
    "arxiv": "2009.10847",
    "counts": {
      "CoKE": 1,
      "CompGCN": 1,
      "ComplEx": 1,
      "ConvE": 1,
      "ConvKB": 1,
      "DistMult": 1,
      "GeomE": 1,
      "HypER": 1,
      "LINE": 1,
      "R-GCN": 1,
      "RotatE": 1,
      "SE": 1,
      "SimplE": 1,
      "TransE": 1,
      "TransF": 1,
      "TransH": 1,
      "TuckER": 1
    },
    "published": "2020-09-22T22:38:54Z",
    "summary": "Hyper-relational knowledge graphs (KGs) (e.g., Wikidata) enable associating additional key-value pairs along with the main triple to disambiguate, or restrict the validity of a fact. In this work, we propose a message passing based graph encoder - StarE capable of modeling such hyper-relational KGs. Unlike existing approaches, StarE can encode an arbitrary number of additional information (qualifiers) along with the main triple while keeping the semantic roles of qualifiers and triples intact. We also demonstrate that existing benchmarks for evaluating link prediction (LP) performance on hyper-relational KGs suffer from fundamental flaws and thus develop a new Wikidata-based dataset - WD50K. Our experiments demonstrate that StarE based LP model outperforms existing approaches across multiple benchmarks. We also confirm that leveraging qualifiers is vital for link prediction with gains up to 25 MRR points compared to triple-based representations.",
    "title": "Message Passing for Hyper-Relational Knowledge Graphs"
  },
  {
    "arxiv": "2010.12256",
    "counts": {
      "ComplEx": 1,
      "GraphSAGE": 1,
      "HypER": 1,
      "SE": 1,
      "TransF": 1
    },
    "published": "2020-10-23T09:37:43Z",
    "summary": "Learning informative representations (aka. embeddings) of users and items is the core of modern recommender systems. Previous works exploit user-item relationships of one-hop neighbors in the user-item interaction graph to improve the quality of representation. Recently, the research of Graph Neural Network (GNN) for recommendation considers the implicit collaborative information of multi-hop neighbors to enrich the representation. However, most works of GNN for recommendation systems do not consider the relational information which implies the expression differences of different neighbors in the neighborhood explicitly. The influence of each neighboring item to the representation of the user's preference can be represented by the correlation between the item and neighboring items of the user. Symmetrically, for a given item, the correlation between one neighboring user and neighboring users can reflect the strength of signal about the item's characteristic. To modeling the implicit correlations of neighbors in graph embedding aggregating, we propose a Neighbor-Aware Graph Attention Network for recommendation task, termed NGAT4Rec. It employs a novel neighbor-aware graph attention layer that assigns different neighbor-aware attention coefficients to different neighbors of a given node by computing the attention among these neighbors pairwisely. Then NGAT4Rec aggregates the embeddings of neighbors according to the corresponding neighbor-aware attention coefficients to generate next layer embedding for every node. Furthermore, we combine more neighbor-aware graph attention layer to gather the influential signals from multi-hop neighbors. We remove feature transformation and nonlinear activation that proved to be useless on collaborative filtering. Extensive experiments on three benchmark datasets show that our model outperforms various state-of-the-art models consistently.",
    "title": "NGAT4Rec: Neighbor-Aware Graph Attention Network For Recommendation"
  },
  {
    "arxiv": "2010.13242",
    "counts": {
      "GraphSAGE": 1,
      "LINE": 1,
      "ProjE": 1,
      "SE": 1,
      "TransA": 1,
      "node2vec": 1
    },
    "published": "2020-10-25T22:39:31Z",
    "summary": "Graph, as an important data representation, is ubiquitous in many real world applications ranging from social network analysis to biology. How to correctly and effectively learn and extract information from graph is essential for a large number of machine learning tasks. Graph embedding is a way to transform and encode the data structure in high dimensional and non-Euclidean feature space to a low dimensional and structural space, which is easily exploited by other machine learning algorithms. We have witnessed a huge surge of such embedding methods, from statistical approaches to recent deep learning methods such as the graph convolutional networks (GCN). Deep learning approaches usually outperform the traditional methods in most graph learning benchmarks by building an end-to-end learning framework to optimize the loss function directly. However, most of the existing GCN methods can only perform convolution operations with node features, while ignoring the handy information in edge features, such as relations in knowledge graphs. To address this problem, we present CensNet, Convolution with Edge-Node Switching graph neural network, for learning tasks in graph-structured data with both node and edge features. CensNet is a general graph embedding framework, which embeds both nodes and edges to a latent feature space. By using line graph of the original undirected graph, the role of nodes and edges are switched, and two novel graph convolution operations are proposed for feature propagation. Experimental results on real-world academic citation networks and quantum chemistry graphs show that our approach achieves or matches the state-of-the-art performance in four graph learning tasks, including semi-supervised node classification, multi-task graph classification, graph regression, and link prediction.",
    "title": "Co-embedding of Nodes and Edges with Graph Neural Networks"
  },
  {
    "arxiv": "2010.13688",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "ProjE": 1,
      "RESCAL": 1,
      "SE": 1,
      "TransE": 1,
      "TransF": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2020-10-26T16:08:13Z",
    "summary": "Neural embedding approaches have become a staple in the fields of computer vision, natural language processing, and more recently, graph analytics. Given the pervasive nature of these algorithms, the natural question becomes how to exploit the embedding spaces to map, or align, embeddings of different data sources. To this end, we survey the current research landscape on word, sentence and knowledge graph embedding algorithms. We provide a classification of the relevant alignment techniques and discuss benchmark datasets used in this field of research. By gathering these diverse approaches into a singular survey, we hope to further motivate research into alignment of embedding spaces of varied data types and sources.",
    "title": "A Survey of Embedding Space Alignment Methods for Language and Knowledge Graphs"
  },
  {
    "arxiv": "2010.16103",
    "counts": {
      "ComplEx": 1,
      "GeomE": 1,
      "GraphSAGE": 1,
      "SE": 2,
      "node2vec": 1
    },
    "published": "2020-10-30T07:04:11Z",
    "summary": "Graph neural networks (GNNs) have achieved great success in recent years. Three most common applications include node classification, link prediction, and graph classification. While there is rich literature on node classification and graph classification, GNN for link prediction is relatively less studied and less understood. One common practice in previous works is to first compute node representations through a GNN, and then directly aggregate two node representations as a link representation. In this paper, we show the limitations of such an approach, and propose a labeling trick to make GNNs learn better link representations. Labeling trick assigns labels to nodes as their additional features according to nodes' relationships with the target link. We show theoretically that GNNs applied to such labeled graphs can learn most expressive link representations. We also show that one state-of-the-art link prediction model, SEAL, exactly uses a labeling trick. Labeling trick brings up to 195% performance gains over plain GNNs, achieving 3 first places on the OGB link prediction leaderboard.",
    "title": "Revisiting Graph Neural Networks for Link Prediction"
  },
  {
    "arxiv": "2011.00745",
    "counts": {
      "ConvE": 1,
      "HypER": 1,
      "LINE": 1,
      "SE": 1
    },
    "published": "2020-11-02T04:44:27Z",
    "summary": "Graph kernel is a powerful tool measuring the similarity between graphs. Most of the existing graph kernels focused on node labels or attributes and ignored graph hierarchical structure information. In order to effectively utilize graph hierarchical structure information, we propose pyramid graph kernel based on optimal transport (OT). Each graph is embedded into hierarchical structures of the pyramid. Then, the OT distance is utilized to measure the similarity between graphs in hierarchical structures. We also utilize the OT distance to measure the similarity between subgraphs and propose subgraph kernel based on OT. The positive semidefinite (p.s.d) of graph kernels based on optimal transport distance is not necessarily possible. We further propose regularized graph kernel based on OT where we add the kernel regularization to the original optimal transport distance to obtain p.s.d kernel matrix. We evaluate the proposed graph kernels on several benchmark classification tasks and compare their performance with the existing state-of-the-art graph kernels. In most cases, our proposed graph kernel algorithms outperform the competing methods.",
    "title": "Transport based Graph Kernels"
  },
  {
    "arxiv": "2011.02260",
    "counts": {
      "R-GCN": 1,
      "SE": 1,
      "TransF": 1,
      "TransR": 1
    },
    "published": "2020-11-04T12:57:47Z",
    "summary": "With the explosive growth of online information, recommender systems play a key role to alleviate such information overload. Due to the important application value of recommender system, there have always been emerging works in this field. In recent years, graph neural network (GNN) techniques have gained considerable interests which can naturally integrate node information and topological structure. Owing to the outperformance of GNN in learning on graph data, GNN methods have been widely applied in many fields. In recommender systems, the main challenge is to learn the efficient user/item embeddings from their interactions and side information if available. Since most of the information essentially has graph structure and GNNs have superiority in representation learning, the field of utilizing graph neural network in recommender systems is flourishing. This article aims to provide a comprehensive review of recent research efforts on graph neural network based recommender systems. Specifically, we provide a taxonomy of graph neural network based recommendation models and state new perspectives pertaining to the development of this field.",
    "title": "Graph Neural Networks in Recommender Systems: A Survey"
  },
  {
    "arxiv": "2011.06391",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "GraphSAGE": 1,
      "LINE": 1,
      "SE": 1
    },
    "published": "2020-11-07T18:06:57Z",
    "summary": "We develop a fused matrix multiplication kernel that unifies sampled dense-dense matrix multiplication and sparse-dense matrix multiplication under a single operation called FusedMM. By using user-defined functions, FusedMM can capture almost all computational patterns needed by popular graph embedding and GNN approaches. FusedMM is an order of magnitude faster than its equivalent kernels in Deep Graph Library. The superior performance of FusedMM comes from the low-level vectorized kernels, a suitable load balancing scheme and an efficient utilization of the memory bandwidth. FusedMM can tune its performance using a code generator and perform equally well on Intel, AMD and ARM processors. FusedMM speeds up an end-to-end graph embedding algorithm by up to 28x on different processors.",
    "title": "FusedMM: A Unified SDDMM-SpMM Kernel for Graph Embedding and Graph Neural Networks"
  },
  {
    "arxiv": "2011.07751",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "R-GCN": 1,
      "RESCAL": 1,
      "SE": 1,
      "SimplE": 1,
      "TransD": 1,
      "TransE": 1,
      "TransH": 1,
      "TuckER": 1
    },
    "published": "2020-11-16T07:05:52Z",
    "summary": "Knowledge graphs have been demonstrated to be an effective tool for numerous intelligent applications. However, a large amount of valuable knowledge still exists implicitly in the knowledge graphs. To enrich the existing knowledge graphs, recent years witness that many algorithms for link prediction and knowledge graphs embedding have been designed to infer new facts. But most of these studies focus on the static knowledge graphs and ignore the temporal information that reflects the validity of knowledge. Developing the model for temporal knowledge graphs completion is an increasingly important task. In this paper, we build a new tensor decomposition model for temporal knowledge graphs completion inspired by the Tucker decomposition of order 4 tensor. We demonstrate that the proposed model is fully expressive and report state-of-the-art results for several public benchmarks. Additionally, we present several regularization schemes to improve the strategy and study their impact on the proposed model. Experimental studies on three temporal datasets (i.e. ICEWS2014, ICEWS2005-15, GDELT) justify our design and demonstrate that our model outperforms baselines with an explicit margin on link prediction task.",
    "title": "Tucker decomposition-based Temporal Knowledge Graph Completion"
  },
  {
    "arxiv": "2011.08431",
    "counts": {
      "CompGCN": 1,
      "ComplEx": 1,
      "ConvE": 1,
      "ConvKB": 1,
      "ConvR": 1,
      "DistMult": 1,
      "R-GCN": 1,
      "SACN": 1,
      "SE": 1,
      "STransE": 1,
      "TransD": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2020-11-14T13:18:55Z",
    "summary": "Most existing knowledge graphs suffer from incompleteness. Embedding knowledge graphs into continuous vector spaces has recently attracted increasing interest in knowledge base completion. However, in most existing embedding methods, only fact triplets are utilized, and logical rules have not been thoroughly studied for the knowledge base completion task. To overcome the problem, we propose an association rules enhanced knowledge graph attention network (AR-KGAT). The AR-KGAT captures both entity and relation features for high-order neighborhoods of any given entity in an end-to-end manner under the graph attention network framework. The major component of AR-KGAT is an encoder of an effective neighborhood aggregator, which addresses the problems by aggregating neighbors with both association-rules-based and graph-based attention weights. Additionally, the proposed model also encapsulates the representations from multi-hop neighbors of nodes to refine their embeddings. The decoder enables AR-KGAT to be translational between entities and relations while keeping the superior link prediction performance. A logic-like inference pattern is utilized as constraints for knowledge graph embedding. Then, the global loss is minimized over both atomic and complex formulas to achieve the embedding task. In this manner, we learn embeddings compatible with triplets and rules, which are certainly more predictive for knowledge acquisition and inference. We conduct extensive experiments on two benchmark datasets: WN18RR and FB15k-237, for two knowledge graph completion tasks: the link prediction and triplet classification to evaluate the proposed AR-KGAT model. The results show that the proposed AR-KGAT model achieves significant and consistent improvements over state-of-the-art methods.",
    "title": "Association Rules Enhanced Knowledge Graph Attention Network"
  },
  {
    "arxiv": "2011.11545",
    "counts": {
      "GraphSAGE": 1,
      "LINE": 1,
      "SDNE": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2020-11-23T16:58:50Z",
    "summary": "Limited by the time complexity of querying k-hop neighbors in a graph database, most graph algorithms cannot be deployed online and execute millisecond-level inference. This problem dramatically limits the potential of applying graph algorithms in certain areas, such as financial fraud detection. Therefore, we propose Asynchronous Propagation Attention Network, an asynchronous continuous time dynamic graph algorithm for real-time temporal graph embedding. Traditional graph models usually execute two serial operations: first graph computation and then model inference. We decouple model inference and graph computation step so that the heavy graph query operations will not damage the speed of model inference. Extensive experiments demonstrate that the proposed method can achieve competitive performance and 8.7 times inference speed improvement in the meantime.",
    "title": "APAN: Asynchronous Propagation Attention Network for Real-time Temporal Graph Embedding"
  },
  {
    "arxiv": "2011.12517",
    "counts": {
      "HypER": 4,
      "LINE": 1,
      "ProjE": 1,
      "SE": 5,
      "TransF": 1
    },
    "published": "2020-11-25T05:09:03Z",
    "summary": "Signed link prediction in social networks aims to reveal the underlying relationships (i.e. links) among users (i.e. nodes) given their existing positive and negative interactions observed. Most of the prior efforts are devoted to learning node embeddings with graph neural networks (GNNs), which preserve the signed network topology by message-passing along edges to facilitate the downstream link prediction task. Nevertheless, the existing graph-based approaches could hardly provide human-intelligible explanations for the following three questions: (1) which neighbors to aggregate, (2) which path to propagate along, and (3) which social theory to follow in the learning process. To answer the aforementioned questions, in this paper, we investigate how to reconcile the \\textit{balance} and \\textit{status} social rules with information theory and develop a unified framework, termed as Signed Infomax Hyperbolic Graph (\\textbf{SIHG}). By maximizing the mutual information between edge polarities and node embeddings, one can identify the most representative neighboring nodes that support the inference of edge sign. Different from existing GNNs that could only group features of friends in the subspace, the proposed SIHG incorporates the signed attention module, which is also capable of pushing hostile users far away from each other to preserve the geometry of antagonism. The polarity of the learned edge attention maps, in turn, provide interpretations of the social theories used in each aggregation. In order to model high-order user relations and complex hierarchies, the node embeddings are projected and measured in a hyperbolic space with a lower distortion. Extensive experiments on four signed network benchmarks demonstrate that the proposed SIHG framework significantly outperforms the state-of-the-arts in signed link prediction.",
    "title": "Interpretable Signed Link Prediction with Signed Infomax Hyperbolic Graph"
  },
  {
    "arxiv": "2011.14211",
    "counts": {
      "HypER": 1,
      "ProjE": 1,
      "SDNE": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2020-11-28T20:16:24Z",
    "summary": "Recent research on graph embedding has achieved success in various applications. Most graph embedding methods preserve the proximity in a graph into a manifold in an embedding space. We argue an important but neglected problem about this proximity-preserving strategy: Graph topology patterns, while preserved well into an embedding manifold by preserving proximity, may distort in the ambient embedding Euclidean space, and hence to detect them becomes difficult for machine learning models. To address the problem, we propose curvature regularization, to enforce flatness for embedding manifolds, thereby preventing the distortion. We present a novel angle-based sectional curvature, termed ABS curvature, and accordingly three kinds of curvature regularization to induce flat embedding manifolds during graph embedding. We integrate curvature regularization into five popular proximity-preserving embedding methods, and empirical results in two applications show significant improvements on a wide range of open graph datasets.",
    "title": "Curvature Regularization to Prevent Distortion in Graph Embedding"
  },
  {
    "arxiv": "2011.14462",
    "counts": {
      "GeomE": 1,
      "MuRP": 1,
      "SE": 1,
      "TransA": 1
    },
    "published": "2020-11-29T23:00:37Z",
    "summary": "Keypoints of objects reflect their concise abstractions, while the corresponding connection links (CL) build the skeleton by detecting the intrinsic relations between keypoints. Existing approaches are typically computationally-intensive, inapplicable for instances belonging to multiple classes, and/or infeasible to simultaneously encode connection information. To address the aforementioned issues, we propose an end-to-end category-implicit Keypoint and Link Prediction Network (KLPNet), which is the first approach for simultaneous semantic keypoint detection (for multi-class instances) and CL rejuvenation. In our KLPNet, a novel Conditional Link Prediction Graph is proposed for link prediction among keypoints that are contingent on a predefined category. Furthermore, a Cross-stage Keypoint Localization Module (CKLM) is introduced to explore feature aggregation for coarse-to-fine keypoint localization. Comprehensive experiments conducted on three publicly available benchmarks demonstrate that our KLPNet consistently outperforms all other state-of-the-art approaches. Furthermore, the experimental results of CL prediction also show the effectiveness of our KLPNet with respect to occlusion problems.",
    "title": "Conditional Link Prediction of Category-Implicit Keypoint Detection"
  },
  {
    "arxiv": "2011.14867",
    "counts": {
      "ComplEx": 1,
      "GeomE": 1,
      "HypER": 1,
      "LINE": 1,
      "ProjE": 1,
      "SE": 1,
      "TransE": 1,
      "metapath2vec": 1,
      "node2vec": 1
    },
    "published": "2020-11-30T15:03:47Z",
    "summary": "Heterogeneous graphs (HGs) also known as heterogeneous information networks have become ubiquitous in real-world scenarios; therefore, HG embedding, which aims to learn representations in a lower-dimension space while preserving the heterogeneous structures and semantics for downstream tasks (e.g., node/graph classification, node clustering, link prediction), has drawn considerable attentions in recent years. In this survey, we perform a comprehensive review of the recent development on HG embedding methods and techniques. We first introduce the basic concepts of HG and discuss the unique challenges brought by the heterogeneity for HG embedding in comparison with homogeneous graph representation learning; and then we systemically survey and categorize the state-of-the-art HG embedding methods based on the information they used in the learning process to address the challenges posed by the HG heterogeneity. In particular, for each representative HG embedding method, we provide detailed introduction and further analyze its pros and cons; meanwhile, we also explore the transformativeness and applicability of different types of HG embedding methods in the real-world industrial environments for the first time. In addition, we further present several widely deployed systems that have demonstrated the success of HG embedding techniques in resolving real-world application problems with broader impacts. To facilitate future research and applications in this area, we also summarize the open-source code, existing graph learning platforms and benchmark datasets. Finally, we explore the additional issues and challenges of HG embedding and forecast the future research directions in this field.",
    "title": "A Survey on Heterogeneous Graph Embedding: Methods, Techniques, Applications and Sources"
  },
  {
    "arxiv": "2012.05442",
    "counts": {
      "ComplEx": 1,
      "LINE": 1,
      "SE": 1,
      "metapath2vec": 1,
      "node2vec": 1
    },
    "published": "2020-12-10T04:03:39Z",
    "summary": "Bipartite graph embedding has recently attracted much attention due to the fact that bipartite graphs are widely used in various application domains. Most previous methods, which adopt random walk-based or reconstruction-based objectives, are typically effective to learn local graph structures. However, the global properties of bipartite graph, including community structures of homogeneous nodes and long-range dependencies of heterogeneous nodes, are not well preserved. In this paper, we propose a bipartite graph embedding called BiGI to capture such global properties by introducing a novel local-global infomax objective. Specifically, BiGI first generates a global representation which is composed of two prototype representations. BiGI then encodes sampled edges as local representations via the proposed subgraph-level attention mechanism. Through maximizing the mutual information between local and global representations, BiGI enables nodes in bipartite graph to be globally relevant. Our model is evaluated on various benchmark datasets for the tasks of top-K recommendation and link prediction. Extensive experiments demonstrate that BiGI achieves consistent and significant improvements over state-of-the-art baselines. Detailed analyses verify the high effectiveness of modeling the global properties of bipartite graph.",
    "title": "Bipartite Graph Embedding via Mutual Information Maximization"
  },
  {
    "arxiv": "2012.06236",
    "counts": {
      "DistMult": 1,
      "HypER": 1,
      "R-GCN": 1,
      "SE": 1
    },
    "published": "2020-12-11T10:52:04Z",
    "summary": "Zero shot learning -- the problem of training and testing on a completely disjoint set of classes -- relies greatly on its ability to transfer knowledge from train classes to test classes. Traditionally semantic embeddings consisting of human defined attributes (HA) or distributed word embeddings (DWE) are used to facilitate this transfer by improving the association between visual and semantic embeddings. In this paper, we take advantage of explicit relations between nodes defined in ConceptNet, a commonsense knowledge graph, to generate commonsense embeddings of the class labels by using a graph convolution network-based autoencoder. Our experiments performed on three standard benchmark datasets surpass the strong baselines when we fuse our commonsense embeddings with existing semantic embeddings i.e. HA and DWE.",
    "title": "Improving Zero Shot Learning Baselines with Commonsense Knowledge"
  },
  {
    "arxiv": "2012.08019",
    "counts": {
      "ConvE": 2,
      "GeomE": 2,
      "KG2E": 2,
      "LINE": 2,
      "SDNE": 2,
      "SE": 4,
      "TransA": 2,
      "node2vec": 2
    },
    "published": "2020-12-15T00:30:22Z",
    "summary": "Graph analytics can lead to better quantitative understanding and control of complex networks, but traditional methods suffer from high computational cost and excessive memory requirements associated with the high-dimensionality and heterogeneous characteristics of industrial size networks. Graph embedding techniques can be effective in converting high-dimensional sparse graphs into low-dimensional, dense and continuous vector spaces, preserving maximally the graph structure properties. Another type of emerging graph embedding employs Gaussian distribution-based graph embedding with important uncertainty estimation. The main goal of graph embedding methods is to pack every node's properties into a vector with a smaller dimension, hence, node similarity in the original complex irregular spaces can be easily quantified in the embedded vector spaces using standard metrics. The generated nonlinear and highly informative graph embeddings in the latent space can be conveniently used to address different downstream graph analytics tasks (e.g., node classification, link prediction, community detection, visualization, etc.). In this Review, we present some fundamental concepts in graph analytics and graph embedding methods, focusing in particular on random walk-based and neural network-based methods. We also discuss the emerging deep learning-based dynamic graph embedding methods. We highlight the distinct advantages of graph embedding methods in four diverse applications, and present implementation details and references to open-source software as well as available databases in the Appendix for the interested readers to start their exploration into graph analytics.",
    "title": "Understanding graph embedding methods and their applications"
  },
  {
    "arxiv": "2012.08752",
    "counts": {
      "ComplEx": 1,
      "GraphSAGE": 1,
      "HypER": 1,
      "LINE": 1,
      "SE": 1,
      "TransF": 1,
      "node2vec": 1
    },
    "published": "2020-12-16T05:50:33Z",
    "summary": "Graph neural networks provide a powerful toolkit for embedding real-world graphs into low-dimensional spaces according to specific tasks. Up to now, there have been several surveys on this topic. However, they usually lay emphasis on different angles so that the readers can not see a panorama of the graph neural networks. This survey aims to overcome this limitation, and provide a comprehensive review on the graph neural networks. First of all, we provide a novel taxonomy for the graph neural networks, and then refer to up to 400 relevant literatures to show the panorama of the graph neural networks. All of them are classified into the corresponding categories. In order to drive the graph neural networks into a new stage, we summarize four future research directions so as to overcome the facing challenges. It is expected that more and more scholars can understand and exploit the graph neural networks, and use them in their research community.",
    "title": "Graph Neural Networks: Taxonomy, Advances and Trends"
  },
  {
    "arxiv": "2012.11147",
    "counts": {
      "ComplEx": 2,
      "DistMult": 2,
      "GraphSAGE": 2,
      "NTN": 2,
      "ProjE": 2,
      "R-GCN": 2,
      "RESCAL": 2,
      "SE": 2,
      "TransE": 2,
      "TransF": 2,
      "TransH": 2,
      "TransR": 2,
      "metapath2vec": 2
    },
    "published": "2020-12-21T06:58:38Z",
    "summary": "Graph Neural Networks (GNNs) are widely used in graph representation learning. However, most GNN methods are designed for either homogeneous or heterogeneous graphs. In this paper, we propose a new model, Hop-Hop Relation-aware Graph Neural Network (HHR-GNN), to unify representation learning for these two types of graphs. HHR-GNN learns a personalized receptive field for each node by leveraging knowledge graph embedding to learn relation scores between the central node's representations at different hops. In neighborhood aggregation, our model simultaneously allows for hop-aware projection and aggregation. This mechanism enables the central node to learn a hop-wise neighborhood mixing that can be applied to both homogeneous and heterogeneous graphs. Experimental results on five benchmarks show the competitive performance of our model compared to state-of-the-art GNNs, e.g., up to 13K faster in terms of time cost per training epoch on large heterogeneous graphs.",
    "title": "Hop-Hop Relation-aware Graph Neural Networks"
  },
  {
    "arxiv": "2012.11957",
    "counts": {
      "ComplEx": 2,
      "ConvE": 4,
      "ConvKB": 2,
      "DistMult": 4,
      "LINE": 1,
      "NAM": 1,
      "R-GCN": 2,
      "RESCAL": 1,
      "SE": 3,
      "TransE": 1,
      "TuckER": 1
    },
    "published": "2020-12-22T12:22:03Z",
    "summary": "Developing link prediction models to automatically complete knowledge graphs has recently been the focus of significant research interest. The current methods for the link prediction taskhavetwonaturalproblems:1)the relation distributions in KGs are usually unbalanced, and 2) there are many unseen relations that occur in practical situations. These two problems limit the training effectiveness and practical applications of the existing link prediction models. We advocate a holistic understanding of KGs and we propose in this work a unified Generalized Relation Learning framework GRL to address the above two problems, which can be plugged into existing link prediction models. GRL conducts a generalized relation learning, which is aware of semantic correlations between relations that serve as a bridge to connect semantically similar relations. After training with GRL, the closeness of semantically similar relations in vector space and the discrimination of dissimilar relations are improved. We perform comprehensive experiments on six benchmarks to demonstrate the superior capability of GRL in the link prediction task. In particular, GRL is found to enhance the existing link prediction models making them insensitive to unbalanced relation distributions and capable of learning unseen relations.",
    "title": "Generalized Relation Learning with Semantic Correlation Awareness for Link Prediction"
  },
  {
    "arxiv": "2012.12931",
    "counts": {
      "HypER": 1,
      "RatE": 1,
      "SE": 5
    },
    "published": "2020-12-23T19:38:21Z",
    "summary": "Graph-Level Outlier Detection (GLOD) is the task of identifying unusual graphs within a graph database, which received little attention compared to node-level detection in a single graph. As propagation based graph embedding by GNNs and graph kernels achieved promising results on another graph-level task, i.e. graph classification, we study applying those models to tackle GLOD. Instead of developing new models, this paper identifies and delves into a fundamental and intriguing issue with applying propagation based models to GLOD, with evaluation conducted on repurposed binary graph classification datasets where one class is down-sampled as outlier. We find that ROC-AUC performance of the models change significantly (flips from high to low) depending on which class is down-sampled. Interestingly, ROC-AUCs on these two variants approximately sum to 1 and their performance gap is amplified with increasing propagations. We carefully study the graph embedding space produced by propagation based models and find two driving factors: (1) disparity between within-class densities which is amplified by propagation, and (2) overlapping support (mixing of embeddings) across classes. Our study sheds light onto the effects of using graph propagation based models and classification datasets for outlier detection for the first time.",
    "title": "Issues with Propagation Based Models for Graph-Level Outlier Detection"
  },
  {
    "arxiv": "2012.15537",
    "counts": {
      "ComplEx": 1,
      "DistMult": 1,
      "GraphSAGE": 1,
      "LINE": 1,
      "SE": 2,
      "SimplE": 1,
      "TransE": 1
    },
    "published": "2020-12-31T10:41:01Z",
    "summary": "Modeling time-evolving knowledge graphs (KGs) has recently gained increasing interest. Here, graph representation learning has become the dominant paradigm for link prediction on temporal KGs. However, the embedding-based approaches largely operate in a black-box fashion, lacking the ability to interpret their predictions. This paper provides a link forecasting framework that reasons over query-relevant subgraphs of temporal KGs and jointly models the structural dependencies and the temporal dynamics. Especially, we propose a temporal relational attention mechanism and a novel reverse representation update scheme to guide the extraction of an enclosing subgraph around the query. The subgraph is expanded by an iterative sampling of temporal neighbors and by attention propagation. Our approach provides human-understandable evidence explaining the forecast. We evaluate our model on four benchmark temporal knowledge graphs for the link forecasting task. While being more explainable, our model obtains a relative improvement of up to 20% on Hits@1 compared to the previous best KG forecasting method. We also conduct a survey with 53 respondents, and the results show that the evidence extracted by the model for link forecasting is aligned with human understanding.",
    "title": "xERTE: Explainable Reasoning on Temporal Knowledge Graphs for Forecasting Future Links"
  },
  {
    "arxiv": "2101.01229",
    "counts": {
      "FedE": 1,
      "GraphSAGE": 1,
      "HypER": 1,
      "LINE": 1,
      "SDNE": 1,
      "SE": 1,
      "TransF": 1,
      "TuckER": 1,
      "node2vec": 1
    },
    "published": "2021-01-04T20:35:26Z",
    "summary": "Embedding static graphs in low-dimensional vector spaces plays a key role in network analytics and inference, supporting applications like node classification, link prediction, and graph visualization. However, many real-world networks present dynamic behavior, including topological evolution, feature evolution, and diffusion. Therefore, several methods for embedding dynamic graphs have been proposed to learn network representations over time, facing novel challenges, such as time-domain modeling, temporal features to be captured, and the temporal granularity to be embedded. In this survey, we overview dynamic graph embedding, discussing its fundamentals and the recent advances developed so far. We introduce the formal definition of dynamic graph embedding, focusing on the problem setting and introducing a novel taxonomy for dynamic graph embedding input and output. We further explore different dynamic behaviors that may be encompassed by embeddings, classifying by topological evolution, feature evolution, and processes on networks. Afterward, we describe existing techniques and propose a taxonomy for dynamic graph embedding techniques based on algorithmic approaches, from matrix and tensor factorization to deep learning, random walks, and temporal point processes. We also elucidate main applications, including dynamic link prediction, anomaly detection, and diffusion prediction, and we further state some promising research directions in the area.",
    "title": "A Survey on Embedding Dynamic Graphs"
  },
  {
    "arxiv": "2101.02390",
    "counts": {
      "ComplEx": 1,
      "GraphSAGE": 3,
      "LINE": 1,
      "RatE": 1,
      "SE": 3,
      "node2vec": 2
    },
    "published": "2021-01-07T06:15:07Z",
    "summary": "Network embedding is aimed at mapping nodes in a network into low-dimensional vector representations. Graph Neural Networks (GNNs) have received widespread attention and lead to state-of-the-art performance in learning node representations. However, most GNNs only work in unsigned networks, where only positive links exist. It is not trivial to transfer these models to signed directed networks, which are widely observed in the real world yet less studied. In this paper, we first review two fundamental sociological theories (i.e., status theory and balance theory) and conduct empirical studies on real-world datasets to analyze the social mechanism in signed directed networks. Guided by related sociological theories, we propose a novel Signed Directed Graph Neural Networks model named SDGNN to learn node embeddings for signed directed networks. The proposed model simultaneously reconstructs link signs, link directions, and signed directed triangles. We validate our model's effectiveness on five real-world datasets, which are commonly used as the benchmark for signed network embedding. Experiments demonstrate the proposed model outperforms existing models, including feature-based methods, network embedding methods, and several GNN methods.",
    "title": "SDGNN: Learning Node Representation for Signed Directed Networks"
  },
  {
    "arxiv": "2101.03091",
    "counts": {
      "NAM": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2021-01-08T16:40:37Z",
    "summary": "Proximity preserving and structural role-based node embeddings have become a prime workhorse of applied graph mining. Novel node embedding techniques are often tested on a restricted set of benchmark datasets. In this paper, we propose a new diverse social network dataset called Twitch Gamers with multiple potential target attributes. Our analysis of the social network and node classification experiments illustrate that Twitch Gamers is suitable for assessing the predictive performance of novel proximity preserving and structural role-based node embedding algorithms.",
    "title": "Twitch Gamers: a Dataset for Evaluating Proximity Preserving and Structural Role-based Node Embeddings"
  },
  {
    "arxiv": "2101.05519",
    "counts": {
      "GeomE": 1,
      "GraphSAGE": 2,
      "HypER": 1,
      "RatE": 1,
      "SE": 3,
      "TransF": 1
    },
    "published": "2021-01-14T09:41:00Z",
    "summary": "Graph convolutional networks have achieved great success on graph-structured data. Many graph convolutional networks can be regarded as low-pass filters for graph signals. In this paper, we propose a new model, BiGCN, which represents a graph neural network as a bi-directional low-pass filter. Specifically, we not only consider the original graph structure information but also the latent correlation between features, thus BiGCN can filter the signals along with both the original graph and a latent feature-connection graph. Our model outperforms previous graph neural networks in the tasks of node classification and link prediction on most of the benchmark datasets, especially when we add noise to the node features.",
    "title": "BiGCN: A Bi-directional Low-Pass Filtering Graph Neural Network"
  },
  {
    "arxiv": "2101.06126",
    "counts": {
      "FedE": 1,
      "SE": 1,
      "TransD": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2021-01-15T14:12:10Z",
    "summary": "Entity Resolution (ER) is a constitutional part for integrating different knowledge graphs in order to identify entities referring to the same real-world object. A promising approach is the use of graph embeddings for ER in order to determine the similarity of entities based on the similarity of their graph neighborhood. The similarity computations for such embeddings translates to calculating the distance between them in the embedding space which is comparatively simple. However, previous work has shown that the use of graph embeddings alone is not sufficient to achieve high ER quality. We therefore propose a more comprehensive ER approach for knowledge graphs called EAGER (Embedding-Assisted Knowledge Graph Entity Resolution) to flexibly utilize both the similarity of graph embeddings and attribute values within a supervised machine learning approach. We evaluate our approach on 23 benchmark datasets with differently sized and structured knowledge graphs and use hypothesis tests to ensure statistical significance of our results. Furthermore we compare our approach with state-of-the-art ER solutions, where our approach yields competitive results for table-oriented ER problems and shallow knowledge graphs but much better results for deeper knowledge graphs.",
    "title": "EAGER: Embedding-Assisted Entity Resolution for Knowledge Graphs"
  },
  {
    "arxiv": "2101.08358",
    "counts": {
      "ComplEx": 1,
      "DistMult": 1,
      "GeomE": 1,
      "HypER": 1,
      "LINE": 2,
      "NAM": 1,
      "SE": 2,
      "TransF": 1,
      "node2vec": 1
    },
    "published": "2021-01-20T23:17:31Z",
    "summary": "We propose a new framework for computing the embeddings of large-scale graphs on a single machine. A graph embedding is a fixed length vector representation for each node (and/or edge-type) in a graph and has emerged as the de-facto approach to apply modern machine learning on graphs. We identify that current systems for learning the embeddings of large-scale graphs are bottlenecked by data movement, which results in poor resource utilization and inefficient training. These limitations require state-of-the-art systems to distribute training across multiple machines. We propose Gaius, a system for efficient training of graph embeddings that leverages partition caching and buffer-aware data orderings to minimize disk access and interleaves data movement with computation to maximize utilization. We compare Gaius against two state-of-the-art industrial systems on a diverse array of benchmarks. We demonstrate that Gaius achieves the same level of accuracy but is up to one order-of magnitude faster. We also show that Gaius can scale training to datasets an order of magnitude beyond a single machine's GPU and CPU memory capacity, enabling training of configurations with more than a billion edges and 550GB of total parameters on a single AWS P3.2xLarge instance.",
    "title": "Learning Massive Graph Embeddings on a Single Machine"
  },
  {
    "arxiv": "2101.10070",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "NTN": 1,
      "RESCAL": 1,
      "RotatE": 1,
      "SE": 1,
      "TransD": 1,
      "TransE": 1,
      "TransG": 1,
      "TransR": 1,
      "node2vec": 1
    },
    "published": "2021-01-25T13:31:29Z",
    "summary": "Embedding entities and relations of a knowledge graph in a low-dimensional space has shown impressive performance in predicting missing links between entities. Although progresses have been achieved, existing methods are heuristically motivated and theoretical understanding of such embeddings is comparatively underdeveloped. This paper extends the random walk model (Arora et al., 2016a) of word embeddings to Knowledge Graph Embeddings (KGEs) to derive a scoring function that evaluates the strength of a relation R between two entities h (head) and t (tail). Moreover, we show that marginal loss minimisation, a popular objective used in much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. Using the derived objective, accurate KGEs are learnt from FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.",
    "title": "RelWalk A Latent Variable Model Approach to Knowledge Graph Embedding"
  },
  {
    "arxiv": "2102.00785",
    "counts": {
      "ComplEx": 1,
      "LINE": 1,
      "SDNE": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2021-02-01T11:50:29Z",
    "summary": "In real-world complex networks, understanding the dynamics of their evolution has been of great interest to the scientific community. Predicting future links is an essential task of social network analysis as the addition or removal of the links over time leads to the network evolution. In a network, links can be categorized as intra-community links if both end nodes of the link belong to the same community, otherwise inter-community links. The existing link-prediction methods have mainly focused on achieving high accuracy for intra-community link prediction. In this work, we propose a network embedding method, called NodeSim, which captures both similarities between the nodes and the community structure while learning the low-dimensional representation of the network. The embedding is learned using the proposed NodeSim random walk, which efficiently explores the diverse neighborhood while keeping the more similar nodes closer in the context of the node. We verify the efficacy of the proposed embedding method over state-of-the-art methods using diverse link prediction. We propose a machine learning model for link prediction that considers both the nodes' embedding and their community information to predict the link between two given nodes. Extensive experimental results on several real-world networks demonstrate the effectiveness of the proposed framework for both inter and intra-community link prediction.",
    "title": "NodeSim: Node Similarity based Network Embedding for Diverse Link Prediction"
  },
  {
    "arxiv": "2102.03135",
    "counts": {
      "GraphSAGE": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2021-02-05T12:26:43Z",
    "summary": "We present Graph Attention Collaborative Similarity Embedding (GACSE), a new recommendation framework that exploits collaborative information in the user-item bipartite graph for representation learning. Our framework consists of two parts: the first part is to learn explicit graph collaborative filtering information such as user-item association through embedding propagation with attention mechanism, and the second part is to learn implicit graph collaborative information such as user-user similarities and item-item similarities through auxiliary loss. We design a new loss function that combines BPR loss with adaptive margin and similarity loss for the similarities learning. Extensive experiments on three benchmarks show that our model is consistently better than the latest state-of-the-art models.",
    "title": "Graph Attention Collaborative Similarity Embedding for Recommender System"
  },
  {
    "arxiv": "2102.04770",
    "counts": {
      "LINE": 1,
      "NAM": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2021-02-09T11:39:06Z",
    "summary": "Representation learning for graphs enables the application of standard machine learning algorithms and data analysis tools to graph data. Replacing discrete unordered objects such as graph nodes by real-valued vectors is at the heart of many approaches to learning from graph data. Such vector representations, or embeddings, capture the discrete relationships in the original data by representing nodes as vectors in a high-dimensional space. In most applications graphs model the relationship between real-life objects and often nodes contain valuable meta-information about the original objects. While being a powerful machine learning tool, embeddings are not able to preserve such node attributes. We address this shortcoming and consider the problem of learning discrete node embeddings such that the coordinates of the node vector representations are graph nodes. This opens the door to designing interpretable machine learning algorithms for graphs as all attributes originally present in the nodes are preserved. We present a framework for coordinated local graph neighborhood sampling (COLOGNE) such that each node is represented by a fixed number of graph nodes, together with their attributes. Individual samples are coordinated and they preserve the similarity between node neighborhoods. We consider different notions of similarity for which we design scalable algorithms. We show theoretical results for all proposed algorithms. Experiments on benchmark graphs evaluate the quality of the designed embeddings and demonstrate how the proposed embeddings can be used in training interpretable machine learning algorithms for graph data.",
    "title": "COLOGNE: Coordinated Local Graph Neighborhood Sampling"
  },
  {
    "arxiv": "2102.09009",
    "counts": {
      "HypER": 3,
      "LINE": 1,
      "NAM": 2,
      "SE": 6,
      "SimplE": 1
    },
    "published": "2021-02-17T20:04:11Z",
    "summary": "Bayesian optimization (BO) is among the most effective and widely-used blackbox optimization methods. BO proposes solutions according to an explore-exploit trade-off criterion encoded in an acquisition function, many of which are computed from the posterior predictive of a probabilistic surrogate model. Prevalent among these is the expected improvement (EI) function. The need to ensure analytical tractability of the predictive often poses limitations that can hinder the efficiency and applicability of BO. In this paper, we cast the computation of EI as a binary classification problem, building on the link between class-probability estimation and density-ratio estimation, and the lesser-known link between density-ratios and EI. By circumventing the tractability constraints, this reformulation provides numerous advantages, not least in terms of expressiveness, versatility, and scalability.",
    "title": "BORE: Bayesian Optimization by Density-Ratio Estimation"
  },
  {
    "arxiv": "2102.10255",
    "counts": {
      "ComplEx": 1,
      "LINE": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2021-02-20T04:33:59Z",
    "summary": "Link prediction is an important learning task for graph-structured data. In this paper, we propose a novel topological approach to characterize interactions between two nodes. Our topological feature, based on the extended persistence homology, encodes rich structural information regarding the multi-hop paths connecting nodes. Based on this feature, we propose a graph neural network method that outperforms state-of-the-arts on different benchmarks. As another contribution, we propose a novel algorithm to more efficiently compute the extended persistent diagrams for graphs. This algorithm can be generally applied to accelerate many other topological methods for graph learning tasks.",
    "title": "Persistence Homology for Link Prediction: An Interactive View"
  },
  {
    "arxiv": "2102.12557",
    "counts": {
      "GeomE": 1,
      "GraphSAGE": 1,
      "SE": 1,
      "node2vec": 1
    },
    "published": "2021-02-24T20:57:16Z",
    "summary": "In this paper, we benchmark several existing graph neural network (GNN) models on different datasets for link predictions. In particular, the graph convolutional network (GCN), GraphSAGE, graph attention network (GAT) as well as variational graph auto-encoder (VGAE) are implemented dedicated to link prediction tasks, in-depth analysis are performed, and results from several different papers are replicated, also a more fair and systematic comparison are provided. Our experiments show these GNN architectures perform similarly on various benchmarks for link prediction tasks.",
    "title": "Benchmarking Graph Neural Networks on Link Prediction"
  },
  {
    "arxiv": "2103.09754",
    "counts": {
      "ComplEx": 1,
      "HypER": 2,
      "SE": 8
    },
    "published": "2021-03-17T16:22:24Z",
    "summary": "Though the multiscale graph learning techniques have enabled advanced feature extraction frameworks, the classic ensemble strategy may show inferior performance while encountering the high homogeneity of the learnt representation, which is caused by the nature of existing graph pooling methods. To cope with this issue, we propose a diversified multiscale graph learning model equipped with two core ingredients: a graph self-correction (GSC) mechanism to generate informative embedded graphs, and a diversity boosting regularizer (DBR) to achieve a comprehensive characterization of the input graph. The proposed GSC mechanism compensates the pooled graph with the lost information during the graph pooling process by feeding back the estimated residual graph, which serves as a plug-in component for popular graph pooling methods. Meanwhile, pooling methods enhanced with the GSC procedure encourage the discrepancy of node embeddings, and thus it contributes to the success of ensemble learning strategy. The proposed DBR instead enhances the ensemble diversity at the graph-level embeddings by leveraging the interaction among individual classifiers. Extensive experiments on popular graph classification benchmarks show that the proposed GSC mechanism leads to significant improvements over state-of-the-art graph pooling methods. Moreover, the ensemble multiscale graph learning models achieve superior enhancement by combining both GSC and DBR.",
    "title": "Diversified Multiscale Graph Learning with Graph Self-Correction"
  },
  {
    "arxiv": "2103.10367",
    "counts": {
      "AnyBURL": 1,
      "CompGCN": 1,
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "FedE": 1,
      "GeomE": 1,
      "HypER": 1,
      "ProjE": 1,
      "R-GCN": 1,
      "RESCAL": 1,
      "SE": 1,
      "TransE": 1
    },
    "published": "2021-03-18T16:46:11Z",
    "summary": "Biomedical knowledge graphs permit an integrative computational approach to reasoning about biological systems. The nature of biological data leads to a graph structure that differs from those typically encountered in benchmarking datasets. To understand the implications this may have on the performance of reasoning algorithms, we conduct an empirical study based on the real-world task of drug repurposing. We formulate this task as a link prediction problem where both compounds and diseases correspond to entities in a knowledge graph. To overcome apparent weaknesses of existing algorithms, we propose a new method, PoLo, that combines policy-guided walks based on reinforcement learning with logical rules. These rules are integrated into the algorithm by using a novel reward function. We apply our method to Hetionet, which integrates biomedical information from 29 prominent bioinformatics databases. Our experiments show that our approach outperforms several state-of-the-art methods for link prediction while providing interpretability.",
    "title": "Neural Multi-Hop Reasoning With Logical Rules on Biomedical Knowledge Graphs"
  },
  {
    "arxiv": "2103.10379",
    "counts": {
      "ComplEx": 1,
      "DistMult": 1,
      "LINE": 1,
      "NAM": 1,
      "QuatE": 1,
      "RotatE": 1,
      "SE": 1,
      "SimplE": 1,
      "TransD": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2021-03-18T17:08:33Z",
    "summary": "Despite the importance and abundance of temporal knowledge graphs, most of the current research has been focused on reasoning on static graphs. In this paper, we study the challenging problem of inference over temporal knowledge graphs. In particular, the task of temporal link prediction. In general, this is a difficult task due to data non-stationarity, data heterogeneity, and its complex temporal dependencies. We propose Chronological Rotation embedding (ChronoR), a novel model for learning representations for entities, relations, and time. Learning dense representations is frequently used as an efficient and versatile method to perform reasoning on knowledge graphs. The proposed model learns a k-dimensional rotation transformation parametrized by relation and time, such that after each fact's head entity is transformed using the rotation, it falls near its corresponding tail entity. By using high dimensional rotation as its transformation operator, ChronoR captures rich interaction between the temporal and multi-relational characteristics of a Temporal Knowledge Graph. Experimentally, we show that ChronoR is able to outperform many of the state-of-the-art methods on the benchmark datasets for temporal knowledge graph link prediction.",
    "title": "ChronoR: Rotation Based Temporal Knowledge Graph Embedding"
  }
]