[
  {
    "arxiv": "1911.04910",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "ConvKB": 1,
      "DistMult": 1,
      "QuatE": 1,
      "R-GCN": 1,
      "RotatE": 1,
      "SACN": 1,
      "TransD": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1,
      "TuckER": 1
    },
    "published": "2019-11-09T07:02:33Z",
    "summary": "Translational distance-based knowledge graph embedding has shown progressive improvements on the link prediction task, from TransE to the latest state-of-the-art RotatE. However, N-1, 1-N and N-N predictions still remain challenging. In this work, we propose a novel translational distance-based approach for knowledge graph link prediction. The proposed method includes two-folds, first we extend the RotatE from 2D complex domain to high dimension space with orthogonal transforms to model relations for better modeling capacity. Second, the graph context is explicitly modeled via two directed context representations. These context representations are used as part of the distance scoring function to measure the plausibility of the triples during training and inference. The proposed approach effectively improves prediction accuracy on the difficult N-1, 1-N and N-N cases for knowledge graph link prediction task. The experimental results show that it achieves better performance on two benchmark data sets compared to the baseline RotatE, especially on data set (FB15k-237) with many high in-degree connection nodes.",
    "title": "Orthogonal Relation Transforms with Graph Context Modeling for Knowledge Graph Embedding"
  },
  {
    "arxiv": "2005.00545",
    "counts": {
      "AttH": 6,
      "ComplEx": 4,
      "ConvE": 2,
      "ConvKB": 1,
      "DistMult": 2,
      "MuRE": 1,
      "MuRP": 5,
      "QuatE": 1,
      "R-GCN": 1,
      "RESCAL": 1,
      "RotatE": 5,
      "SE": 1,
      "TuckER": 2
    },
    "published": "2020-05-01T18:00:02Z",
    "summary": "Knowledge graph (KG) embeddings learn low-dimensional representations of entities and relations to predict missing facts. KGs often exhibit hierarchical and logical patterns which must be preserved in the embedding space. For hierarchical data, hyperbolic embedding methods have shown promise for high-fidelity and parsimonious representations. However, existing hyperbolic embedding methods do not account for the rich logical patterns in KGs. In this work, we introduce a class of hyperbolic KG embedding models that simultaneously capture hierarchical and logical patterns. Our approach combines hyperbolic reflections and rotations with attention to model complex relational patterns. Experimental results on standard KG benchmarks show that our method improves over previous Euclidean- and hyperbolic-based efforts by up to 6.1% in mean reciprocal rank (MRR) in low dimensions. Furthermore, we observe that different geometric transformations capture different types of relations while attention-based transformations generalize to multiple relations. In high dimensions, our approach yields new state-of-the-art MRRs of 49.6% on WN18RR and 57.7% on YAGO3-10.",
    "title": "Low-Dimensional Hyperbolic Knowledge Graph Embeddings"
  },
  {
    "arxiv": "2011.08431",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "ConvKB": 1,
      "ConvR": 1,
      "DistMult": 1,
      "R-GCN": 1,
      "SACN": 1,
      "STransE": 1,
      "TransD": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2020-11-14T13:18:55Z",
    "summary": "Most existing knowledge graphs suffer from incompleteness. Embedding knowledge graphs into continuous vector spaces has recently attracted increasing interest in knowledge base completion. However, in most existing embedding methods, only fact triplets are utilized, and logical rules have not been thoroughly studied for the knowledge base completion task. To overcome the problem, we propose an association rules enhanced knowledge graph attention network (AR-KGAT). The AR-KGAT captures both entity and relation features for high-order neighborhoods of any given entity in an end-to-end manner under the graph attention network framework. The major component of AR-KGAT is an encoder of an effective neighborhood aggregator, which addresses the problems by aggregating neighbors with both association-rules-based and graph-based attention weights. Additionally, the proposed model also encapsulates the representations from multi-hop neighbors of nodes to refine their embeddings. The decoder enables AR-KGAT to be translational between entities and relations while keeping the superior link prediction performance. A logic-like inference pattern is utilized as constraints for knowledge graph embedding. Then, the global loss is minimized over both atomic and complex formulas to achieve the embedding task. In this manner, we learn embeddings compatible with triplets and rules, which are certainly more predictive for knowledge acquisition and inference. We conduct extensive experiments on two benchmark datasets: WN18RR and FB15k-237, for two knowledge graph completion tasks: the link prediction and triplet classification to evaluate the proposed AR-KGAT model. The results show that the proposed AR-KGAT model achieves significant and consistent improvements over state-of-the-art methods.",
    "title": "Association Rules Enhanced Knowledge Graph Attention Network"
  },
  {
    "arxiv": "1903.11406",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "ER-MLP": 1,
      "NTN": 1,
      "RESCAL": 1,
      "SE": 1,
      "TransA": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2019-03-27T13:09:16Z",
    "summary": "Knowledge graph is a popular format for representing knowledge, with many applications to semantic search engines, question-answering systems, and recommender systems. Real-world knowledge graphs are usually incomplete, so knowledge graph embedding methods, such as Canonical decomposition/Parallel factorization (CP), DistMult, and ComplEx, have been proposed to address this issue. These methods represent entities and relations as embedding vectors in semantic space and predict the links between them. The embedding vectors themselves contain rich semantic information and can be used in other applications such as data analysis. However, mechanisms in these models and the embedding vectors themselves vary greatly, making it difficult to understand and compare them. Given this lack of understanding, we risk using them ineffectively or incorrectly, particularly for complicated models, such as CP, with two role-based embedding vectors, or the state-of-the-art ComplEx model, with complex-valued embedding vectors. In this paper, we propose a multi-embedding interaction mechanism as a new approach to uniting and generalizing these models. We derive them theoretically via this mechanism and provide empirical analyses and comparisons between them. We also propose a new multi-embedding model based on quaternion algebra and show that it achieves promising results using popular benchmarks. Source code is available on github at https://github.com/tranhungnghiep/AnalyzingKGEmbeddings",
    "title": "Analyzing Knowledge Graph Embedding Methods from a Multi-Embedding Interaction Perspective"
  },
  {
    "arxiv": "1909.03821",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "RESCAL": 1,
      "TorusE": 1,
      "TransA": 1,
      "TransAt": 1,
      "TransD": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2019-09-09T12:58:16Z",
    "summary": "Knowledge graphs are useful for many artificial intelligence tasks but often have missing data. Hence, a method for completing knowledge graphs is required. Existing approaches include embedding models, the Path Ranking Algorithm, and rule evaluation models. However, these approaches have limitations. For example, all the information is mixed and difficult to interpret in embedding models, and traditional rule evaluation models are basically slow. In this paper, we provide an integrated view of various approaches and combine them to compensate for their limitations. We first unify state-of-the-art embedding models, such as ComplEx and TorusE, reinterpreting them as a variant of translation-based models. Then, we show that these models utilize paths for link prediction and propose a method for evaluating rules based on this idea. Finally, we combine an embedding model and observed feature models to predict missing triples. This is possible because all of these models utilize paths. We also conduct experiments, including link prediction tasks, with standard datasets to evaluate our method and framework. The experiments show that our method can evaluate rules faster than traditional methods and that our framework outperforms state-of-the-art models in terms of link prediction.",
    "title": "Combination of Unified Embedding Model and Observed Features for Knowledge Graph Completion"
  },
  {
    "arxiv": "1911.08776",
    "counts": {
      "ComplEx": 1,
      "DistMult": 1,
      "LiteralE": 1,
      "NTN": 1,
      "RESCAL": 1,
      "RotatE": 1,
      "SE": 1,
      "SimplE": 1,
      "TransE": 1,
      "TransH": 1,
      "TuckER": 1
    },
    "published": "2019-11-20T09:05:11Z",
    "summary": "As an efficient model for knowledge organization, the knowledge graph has been widely adopted in several fields, e.g., biomedicine, sociology, and education. And there is a steady trend of learning embedding representations of knowledge graphs to facilitate knowledge graph construction and downstream tasks. In general, knowledge graph embedding techniques aim to learn vectorized representations which preserve the structural information of the graph. And conventional embedding learning models rely on structural relationships among entities and relations. However, in educational knowledge graphs, structural relationships are not the focus. Instead, rich literals of the graphs are more valuable. In this paper, we focus on this problem and propose a novel model for embedding learning of educational knowledge graphs. Our model considers both structural and literal information and jointly learns embedding representations. Three experimental graphs were constructed based on an educational knowledge graph which has been applied in real-world teaching. We conducted two experiments on the three graphs and other common benchmark graphs. The experimental results proved the effectiveness of our model and its superiority over other baselines when processing educational knowledge graphs.",
    "title": "Joint Embedding Learning of Educational Knowledge Graphs"
  },
  {
    "arxiv": "2009.10847",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "ConvKB": 1,
      "DistMult": 1,
      "R-GCN": 1,
      "RotatE": 1,
      "SE": 1,
      "SimplE": 1,
      "TransE": 1,
      "TransH": 1,
      "TuckER": 1
    },
    "published": "2020-09-22T22:38:54Z",
    "summary": "Hyper-relational knowledge graphs (KGs) (e.g., Wikidata) enable associating additional key-value pairs along with the main triple to disambiguate, or restrict the validity of a fact. In this work, we propose a message passing based graph encoder - StarE capable of modeling such hyper-relational KGs. Unlike existing approaches, StarE can encode an arbitrary number of additional information (qualifiers) along with the main triple while keeping the semantic roles of qualifiers and triples intact. We also demonstrate that existing benchmarks for evaluating link prediction (LP) performance on hyper-relational KGs suffer from fundamental flaws and thus develop a new Wikidata-based dataset - WD50K. Our experiments demonstrate that StarE based LP model outperforms existing approaches across multiple benchmarks. We also confirm that leveraging qualifiers is vital for link prediction with gains up to 25 MRR points compared to triple-based representations.",
    "title": "Message Passing for Hyper-Relational Knowledge Graphs"
  },
  {
    "arxiv": "2101.10070",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "NTN": 1,
      "RESCAL": 1,
      "RotatE": 1,
      "SE": 1,
      "TransD": 1,
      "TransE": 1,
      "TransG": 1,
      "TransR": 1
    },
    "published": "2021-01-25T13:31:29Z",
    "summary": "Embedding entities and relations of a knowledge graph in a low-dimensional space has shown impressive performance in predicting missing links between entities. Although progresses have been achieved, existing methods are heuristically motivated and theoretical understanding of such embeddings is comparatively underdeveloped. This paper extends the random walk model (Arora et al., 2016a) of word embeddings to Knowledge Graph Embeddings (KGEs) to derive a scoring function that evaluates the strength of a relation R between two entities h (head) and t (tail). Moreover, we show that marginal loss minimisation, a popular objective used in much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. Using the derived objective, accurate KGEs are learnt from FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.",
    "title": "RelWalk A Latent Variable Model Approach to Knowledge Graph Embedding"
  },
  {
    "arxiv": "2007.11164",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "HolE": 1,
      "TranSparse": 1,
      "TransD": 1,
      "TransE": 1,
      "TransF": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2020-07-22T02:20:25Z",
    "summary": "Knowledge graph embedding, which aims to learn the low-dimensional representations of entities and relationships, has attracted considerable research efforts recently. However, most knowledge graph embedding methods focus on the structural relationships in fixed triples while ignoring the temporal information. Currently, existing time-aware graph embedding methods only focus on the factual plausibility, while ignoring the temporal smoothness which models the interactions between a fact and its contexts, and thus can capture fine-granularity temporal relationships. This leads to the limited performance of embedding related applications. To solve this problem, this paper presents a Robustly Time-aware Graph Embedding (RTGE) method by incorporating temporal smoothness. Two major innovations of our paper are presented here. At first, RTGE integrates a measure of temporal smoothness in the learning process of the time-aware graph embedding. Via the proposed additional smoothing factor, RTGE can preserve both structural information and evolutionary patterns of a given graph. Secondly, RTGE provides a general task-oriented negative sampling strategy associated with temporally-aware information, which further improves the adaptive ability of the proposed algorithm and plays an essential role in obtaining superior performance in various tasks. Extensive experiments conducted on multiple benchmark tasks show that RTGE can increase performance in entity/relationship/temporal scoping prediction tasks.",
    "title": "Time-aware Graph Embedding: A temporal smoothness and task-oriented approach"
  },
  {
    "arxiv": "2008.07723",
    "counts": {
      "ComplEx": 1,
      "ConvE": 3,
      "ConvKB": 3,
      "DistMult": 3,
      "RotatE": 2,
      "SE": 4,
      "SimplE": 3,
      "TransE": 3,
      "TransR": 2,
      "TuckER": 1
    },
    "published": "2020-08-18T03:34:09Z",
    "summary": "Link prediction is the task of predicting missing connections between entities in the knowledge graph (KG). While various forms of models are proposed for the link prediction task, most of them are designed based on a few known relation patterns in several well-known datasets. Due to the diversity and complexity nature of the real-world KGs, it is inherently difficult to design a model that fits all datasets well. To address this issue, previous work has tried to use Automated Machine Learning (AutoML) to search for the best model for a given dataset. However, their search space is limited only to bilinear model families. In this paper, we propose a novel Neural Architecture Search (NAS) framework for the link prediction task. First, the embeddings of the input triplet are refined by the Representation Search Module. Then, the prediction score is searched within the Score Function Search Module. This framework entails a more general search space, which enables us to take advantage of several mainstream model families, and thus it can potentially achieve better performance. We relax the search space to be continuous so that the architecture can be optimized efficiently using gradient-based search strategies. Experimental results on several benchmark datasets demonstrate the effectiveness of our method compared with several state-of-the-art approaches.",
    "title": "NASE: Learning Knowledge Graph Embedding for Link Prediction via Neural Architecture Search"
  },
  {
    "arxiv": "2011.07751",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "R-GCN": 1,
      "RESCAL": 1,
      "SimplE": 1,
      "TransD": 1,
      "TransE": 1,
      "TransH": 1,
      "TuckER": 1
    },
    "published": "2020-11-16T07:05:52Z",
    "summary": "Knowledge graphs have been demonstrated to be an effective tool for numerous intelligent applications. However, a large amount of valuable knowledge still exists implicitly in the knowledge graphs. To enrich the existing knowledge graphs, recent years witness that many algorithms for link prediction and knowledge graphs embedding have been designed to infer new facts. But most of these studies focus on the static knowledge graphs and ignore the temporal information that reflects the validity of knowledge. Developing the model for temporal knowledge graphs completion is an increasingly important task. In this paper, we build a new tensor decomposition model for temporal knowledge graphs completion inspired by the Tucker decomposition of order 4 tensor. We demonstrate that the proposed model is fully expressive and report state-of-the-art results for several public benchmarks. Additionally, we present several regularization schemes to improve the strategy and study their impact on the proposed model. Experimental studies on three temporal datasets (i.e. ICEWS2014, ICEWS2005-15, GDELT) justify our design and demonstrate that our model outperforms baselines with an explicit margin on link prediction task.",
    "title": "Tucker decomposition-based Temporal Knowledge Graph Completion"
  },
  {
    "arxiv": "2103.10379",
    "counts": {
      "ComplEx": 1,
      "DistMult": 1,
      "QuatE": 1,
      "RotatE": 1,
      "SE": 1,
      "SimplE": 1,
      "TransD": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2021-03-18T17:08:33Z",
    "summary": "Despite the importance and abundance of temporal knowledge graphs, most of the current research has been focused on reasoning on static graphs. In this paper, we study the challenging problem of inference over temporal knowledge graphs. In particular, the task of temporal link prediction. In general, this is a difficult task due to data non-stationarity, data heterogeneity, and its complex temporal dependencies. We propose Chronological Rotation embedding (ChronoR), a novel model for learning representations for entities, relations, and time. Learning dense representations is frequently used as an efficient and versatile method to perform reasoning on knowledge graphs. The proposed model learns a k-dimensional rotation transformation parametrized by relation and time, such that after each fact's head entity is transformed using the rotation, it falls near its corresponding tail entity. By using high dimensional rotation as its transformation operator, ChronoR captures rich interaction between the temporal and multi-relational characteristics of a Temporal Knowledge Graph. Experimentally, we show that ChronoR is able to outperform many of the state-of-the-art methods on the benchmark datasets for temporal knowledge graph link prediction.",
    "title": "ChronoR: Rotation Based Temporal Knowledge Graph Embedding"
  },
  {
    "arxiv": "1506.00999",
    "counts": {
      "LFM": 1,
      "NTN": 1,
      "RESCAL": 1,
      "SE": 1,
      "SME": 1,
      "TATEC": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2015-06-02T19:34:19Z",
    "summary": "This paper tackles the problem of endogenous link prediction for Knowledge Base completion. Knowledge Bases can be represented as directed graphs whose nodes correspond to entities and edges to relationships. Previous attempts either consist of powerful systems with high capacity to model complex connectivity patterns, which unfortunately usually end up overfitting on rare relationships, or in approaches that trade capacity for simplicity in order to fairly model all relationships, frequent or not. In this paper, we propose Tatec a happy medium obtained by complementing a high-capacity model with a simpler one, both pre-trained separately and then combined. We present several variants of this model with different kinds of regularization and combination strategies and show that this approach outperforms existing methods on different types of relationships by achieving state-of-the-art results on four benchmarks of the literature.",
    "title": "Combining Two And Three-Way Embeddings Models for Link Prediction in Knowledge Bases"
  },
  {
    "arxiv": "1512.01370",
    "counts": {
      "LFM": 1,
      "NTN": 1,
      "RESCAL": 1,
      "SE": 1,
      "SME": 1,
      "Structured Embedding": 1,
      "TransA": 1,
      "TransE": 1,
      "TransH": 1
    },
    "published": "2015-12-04T11:09:55Z",
    "summary": "Knowledge graph embedding aims to represent entities and relations in a large-scale knowledge graph as elements in a continuous vector space. Existing methods, e.g., TransE and TransH, learn embedding representation by defining a global margin-based loss function over the data. However, the optimal loss function is determined during experiments whose parameters are examined among a closed set of candidates. Moreover, embeddings over two knowledge graphs with different entities and relations share the same set of candidate loss functions, ignoring the locality of both graphs. This leads to the limited performance of embedding related applications. In this paper, we propose a locally adaptive translation method for knowledge graph embedding, called TransA, to find the optimal loss function by adaptively determining its margin over different knowledge graphs. Experiments on two benchmark data sets demonstrate the superiority of the proposed method, as compared to the-state-of-the-art ones.",
    "title": "Locally Adaptive Translation for Knowledge Graph Embedding"
  },
  {
    "arxiv": "1911.00055",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "HolE": 1,
      "R-GCN": 1,
      "RESCAL": 1,
      "RotatE": 1,
      "TransE": 1,
      "TuckER": 1
    },
    "published": "2019-10-31T18:51:33Z",
    "summary": "In this paper, we study the problem of learning probabilistic logical rules for inductive and interpretable link prediction. Despite the importance of inductive link prediction, most previous works focused on transductive link prediction and cannot manage previously unseen entities. Moreover, they are black-box models that are not easily explainable for humans. We propose DRUM, a scalable and differentiable approach for mining first-order logical rules from knowledge graphs which resolves these problems. We motivate our method by making a connection between learning confidence scores for each rule and low-rank tensor approximation. DRUM uses bidirectional RNNs to share useful information across the tasks of learning rules for different relations. We also empirically demonstrate the efficiency of DRUM over existing rule mining methods for inductive link prediction on a variety of benchmark datasets.",
    "title": "DRUM: End-To-End Differentiable Rule Mining On Knowledge Graphs"
  },
  {
    "arxiv": "2006.07331",
    "counts": {
      "ComplEx": 1,
      "DistMult": 1,
      "NTN": 1,
      "QuatE": 1,
      "R-GCN": 1,
      "RotatE": 1,
      "TransD": 1,
      "TransE": 1,
      "TransH": 1
    },
    "published": "2020-06-12T17:12:51Z",
    "summary": "Graph Convolutional Networks (GCNs) have received increasing attention in recent machine learning. How to effectively leverage the rich structural information in complex graphs, such as knowledge graphs with heterogeneous types of entities and relations, is a primary open challenge in the field. Most GCN methods are either restricted to graphs with a homogeneous type of edges (e.g., citation links only), or focusing on representation learning for nodes only instead of jointly optimizing the embeddings of both nodes and edges for target-driven objectives. This paper addresses these limitations by proposing a novel framework, namely the GEneralized Multi-relational Graph Convolutional Networks (GEM-GCN), which combines the power of GCNs in graph-based belief propagation and the strengths of advanced knowledge-base embedding methods, and goes beyond. Our theoretical analysis shows that GEM-GCN offers an elegant unification of several well-known GCN methods as specific cases, with a new perspective of graph convolution. Experimental results on benchmark datasets show the advantageous performance of GEM-GCN over strong baseline methods in the tasks of knowledge graph alignment and entity classification.",
    "title": "Generalized Multi-Relational Graph Convolution Network"
  },
  {
    "arxiv": "2006.13774",
    "counts": {
      "ComplEx": 5,
      "DistMult": 5,
      "MuRP": 2,
      "RESCAL": 1,
      "RotatE": 5,
      "SE": 1,
      "SimplE": 5,
      "TransE": 5,
      "TuckER": 3
    },
    "published": "2020-06-24T14:47:33Z",
    "summary": "Much of biomedical and healthcare data is encoded in discrete, symbolic form such as text and medical codes. There is a wealth of expert-curated biomedical domain knowledge stored in knowledge bases and ontologies, but the lack of reliable methods for learning knowledge representation has limited their usefulness in machine learning applications. While text-based representation learning has significantly improved in recent years through advances in natural language processing, attempts to learn biomedical concept embeddings so far have been lacking. A recent family of models called knowledge graph embeddings have shown promising results on general domain knowledge graphs, and we explore their capabilities in the biomedical domain. We train several state-of-the-art knowledge graph embedding models on the SNOMED-CT knowledge graph, provide a benchmark with comparison to existing methods and in-depth discussion on best practices, and make a case for the importance of leveraging the multi-relational nature of knowledge graphs for learning biomedical knowledge representation. The embeddings, code, and materials will be made available to the communitY.",
    "title": "Benchmark and Best Practices for Biomedical Knowledge Graph Embeddings"
  },
  {
    "arxiv": "1702.06879",
    "counts": {
      "ComplEx": 1,
      "DistMult": 1,
      "HolE": 1,
      "NTN": 1,
      "RESCAL": 1,
      "SE": 1,
      "SME": 1,
      "TransE": 1
    },
    "published": "2017-02-22T16:28:11Z",
    "summary": "In statistical relational learning, knowledge graph completion deals with automatically understanding the structure of large knowledge graphs---labeled directed graphs---and predicting missing relationships---labeled edges. State-of-the-art embedding models propose different trade-offs between modeling expressiveness, and time and space complexity. We reconcile both expressiveness and complexity through the use of complex-valued embeddings and explore the link between such complex-valued embeddings and unitary diagonalization. We corroborate our approach theoretically and show that all real square matrices---thus all possible relation/adjacency matrices---are the real part of some unitarily diagonalizable matrix. This results opens the door to a lot of other applications of square matrices factorization. Our approach based on complex embeddings is arguably simple, as it only involves a Hermitian dot product, the complex counterpart of the standard dot product between real vectors, whereas other methods resort to more and more complicated composition functions to increase their expressiveness. The proposed complex embeddings are scalable to large data sets as it remains linear in both space and time, while consistently outperforming alternative approaches on standard link prediction benchmarks.",
    "title": "Knowledge Graph Completion via Complex Tensor Factorization"
  },
  {
    "arxiv": "2006.06648",
    "counts": {
      "ComplEx": 5,
      "ConvE": 4,
      "ConvKB": 2,
      "DistMult": 8,
      "R-GCN": 6,
      "RotatE": 4,
      "TransE": 8,
      "TransH": 1
    },
    "published": "2020-06-11T17:42:46Z",
    "summary": "Many practical graph problems, such as knowledge graph construction and drug-drug interaction prediction, require to handle multi-relational graphs. However, handling real-world multi-relational graphs with Graph Neural Networks (GNNs) is often challenging due to their evolving nature, as new entities (nodes) can emerge over time. Moreover, newly emerged entities often have few links, which makes the learning even more difficult. Motivated by this challenge, we introduce a realistic problem of few-shot out-of-graph link prediction, where we not only predict the links between the seen and unseen nodes as in a conventional out-of-knowledge link prediction task but also between the unseen nodes, with only few edges per node. We tackle this problem with a novel transductive meta-learning framework which we refer to as Graph Extrapolation Networks (GEN). GEN meta-learns both the node embedding network for inductive inference (seen-to-unseen) and the link prediction network for transductive inference (unseen-to-unseen). For transductive link prediction, we further propose a stochastic embedding layer to model uncertainty in the link prediction between unseen entities. We validate our model on multiple benchmark datasets for knowledge graph completion and drug-drug interaction prediction. The results show that our model significantly outperforms relevant baselines for out-of-graph link prediction tasks.",
    "title": "Learning to Extrapolate Knowledge: Transductive Few-shot Out-of-Graph Link Prediction"
  },
  {
    "arxiv": "2010.13688",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "RESCAL": 1,
      "SE": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2020-10-26T16:08:13Z",
    "summary": "Neural embedding approaches have become a staple in the fields of computer vision, natural language processing, and more recently, graph analytics. Given the pervasive nature of these algorithms, the natural question becomes how to exploit the embedding spaces to map, or align, embeddings of different data sources. To this end, we survey the current research landscape on word, sentence and knowledge graph embedding algorithms. We provide a classification of the relevant alignment techniques and discuss benchmark datasets used in this field of research. By gathering these diverse approaches into a singular survey, we hope to further motivate research into alignment of embedding spaces of varied data types and sources.",
    "title": "A Survey of Embedding Space Alignment Methods for Language and Knowledge Graphs"
  },
  {
    "arxiv": "2012.11957",
    "counts": {
      "ComplEx": 2,
      "ConvE": 4,
      "ConvKB": 2,
      "DistMult": 4,
      "R-GCN": 2,
      "RESCAL": 1,
      "TransE": 1,
      "TuckER": 1
    },
    "published": "2020-12-22T12:22:03Z",
    "summary": "Developing link prediction models to automatically complete knowledge graphs has recently been the focus of significant research interest. The current methods for the link prediction taskhavetwonaturalproblems:1)the relation distributions in KGs are usually unbalanced, and 2) there are many unseen relations that occur in practical situations. These two problems limit the training effectiveness and practical applications of the existing link prediction models. We advocate a holistic understanding of KGs and we propose in this work a unified Generalized Relation Learning framework GRL to address the above two problems, which can be plugged into existing link prediction models. GRL conducts a generalized relation learning, which is aware of semantic correlations between relations that serve as a bridge to connect semantically similar relations. After training with GRL, the closeness of semantically similar relations in vector space and the discrimination of dissimilar relations are improved. We perform comprehensive experiments on six benchmarks to demonstrate the superior capability of GRL in the link prediction task. In particular, GRL is found to enhance the existing link prediction models making them insensitive to unbalanced relation distributions and capable of learning unseen relations.",
    "title": "Generalized Relation Learning with Semantic Correlation Awareness for Link Prediction"
  },
  {
    "arxiv": "2103.10367",
    "counts": {
      "AnyBURL": 1,
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "R-GCN": 1,
      "RESCAL": 1,
      "SE": 1,
      "TransE": 1
    },
    "published": "2021-03-18T16:46:11Z",
    "summary": "Biomedical knowledge graphs permit an integrative computational approach to reasoning about biological systems. The nature of biological data leads to a graph structure that differs from those typically encountered in benchmarking datasets. To understand the implications this may have on the performance of reasoning algorithms, we conduct an empirical study based on the real-world task of drug repurposing. We formulate this task as a link prediction problem where both compounds and diseases correspond to entities in a knowledge graph. To overcome apparent weaknesses of existing algorithms, we propose a new method, PoLo, that combines policy-guided walks based on reinforcement learning with logical rules. These rules are integrated into the algorithm by using a novel reward function. We apply our method to Hetionet, which integrates biomedical information from 29 prominent bioinformatics databases. Our experiments show that our approach outperforms several state-of-the-art methods for link prediction while providing interpretability.",
    "title": "Neural Multi-Hop Reasoning With Logical Rules on Biomedical Knowledge Graphs"
  },
  {
    "arxiv": "1606.06357",
    "counts": {
      "ComplEx": 1,
      "DistMult": 1,
      "HolE": 1,
      "NTN": 1,
      "RESCAL": 1,
      "SME": 1,
      "TransE": 1
    },
    "published": "2016-06-20T22:52:48Z",
    "summary": "In statistical relational learning, the link prediction problem is key to automatically understand the structure of large knowledge bases. As in previous studies, we propose to solve this problem through latent factorization. However, here we make use of complex valued embeddings. The composition of complex embeddings can handle a large variety of binary relations, among them symmetric and antisymmetric relations. Compared to state-of-the-art models such as Neural Tensor Network and Holographic Embeddings, our approach based on complex embeddings is arguably simpler, as it only uses the Hermitian dot product, the complex counterpart of the standard dot product between real vectors. Our approach is scalable to large datasets as it remains linear in both space and time, while consistently outperforming alternative approaches on standard link prediction benchmarks.",
    "title": "Complex Embeddings for Simple Link Prediction"
  },
  {
    "arxiv": "1904.12052",
    "counts": {
      "DistMult": 2,
      "RESCAL": 2,
      "TransA": 2,
      "TransD": 2,
      "TransE": 2,
      "TransH": 2,
      "TransR": 2
    },
    "published": "2019-04-26T21:12:19Z",
    "summary": "Knowledge graph embedding (KGE) is a technique for learning continuous embeddings for entities and relations in the knowledge graph.Due to its benefit to a variety of downstream tasks such as knowledge graph completion, question answering and recommendation, KGE has gained significant attention recently. Despite its effectiveness in a benign environment, KGE' robustness to adversarial attacks is not well-studied. Existing attack methods on graph data cannot be directly applied to attack the embeddings of knowledge graph due to its heterogeneity. To fill this gap, we propose a collection of data poisoning attack strategies, which can effectively manipulate the plausibility of arbitrary targeted facts in a knowledge graph by adding or deleting facts on the graph. The effectiveness and efficiency of the proposed attack strategies are verified by extensive evaluations on two widely-used benchmarks.",
    "title": "Data Poisoning Attack against Knowledge Graph Embedding"
  },
  {
    "arxiv": "1906.00137",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "SE": 1,
      "SimplE": 1,
      "TransE": 1,
      "TransH": 1
    },
    "published": "2019-06-01T03:03:15Z",
    "summary": "Knowledge graphs store facts using relations between two entities. In this work, we address the question of link prediction in knowledge hypergraphs where relations are defined on any number of entities. While techniques exist (such as reification) that convert non-binary relations into binary ones, we show that current embedding-based methods for knowledge graph completion do not work well out of the box for knowledge graphs obtained through these techniques. To overcome this, we introduce HSimplE and HypE, two embedding-based methods that work directly with knowledge hypergraphs. In both models, the prediction is a function of the relation embedding, the entity embeddings and their corresponding positions in the relation. We also develop public datasets, benchmarks and baselines for hypergraph prediction and show experimentally that the proposed models are more effective than the baselines.",
    "title": "Knowledge Hypergraphs: Prediction Beyond Binary Relations"
  },
  {
    "arxiv": "1908.10611",
    "counts": {
      "ConvE": 1,
      "SE": 1,
      "STransE": 1,
      "TransD": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2019-08-28T09:49:15Z",
    "summary": "Low-dimensional embeddings of knowledge graphs and behavior graphs have proved remarkably powerful in varieties of tasks, from predicting unobserved edges between entities to content recommendation. The two types of graphs can contain distinct and complementary information for the same entities/nodes. However, previous works focus either on knowledge graph embedding or behavior graph embedding while few works consider both in a unified way. Here we present BEM , a Bayesian framework that incorporates the information from knowledge graphs and behavior graphs. To be more specific, BEM takes as prior the pre-trained embeddings from the knowledge graph, and integrates them with the pre-trained embeddings from the behavior graphs via a Bayesian generative model. BEM is able to mutually refine the embeddings from both sides while preserving their own topological structures. To show the superiority of our method, we conduct a range of experiments on three benchmark datasets: node classification, link prediction, triplet classification on two small datasets related to Freebase, and item recommendation on a large-scale e-commerce dataset.",
    "title": "Bayes EMbedding (BEM): Refining Representation by Integrating Knowledge Graphs and Behavior-specific Networks"
  },
  {
    "arxiv": "1909.01515",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "RESCAL": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2019-09-04T01:35:47Z",
    "summary": "Link prediction is an important way to complete knowledge graphs (KGs), while embedding-based methods, effective for link prediction in KGs, perform poorly on relations that only have a few associative triples. In this work, we propose a Meta Relational Learning (MetaR) framework to do the common but challenging few-shot link prediction in KGs, namely predicting new triples about a relation by only observing a few associative triples. We solve few-shot link prediction by focusing on transferring relation-specific meta information to make model learn the most important knowledge and learn faster, corresponding to relation meta and gradient meta respectively in MetaR. Empirically, our model achieves state-of-the-art results on few-shot link prediction KG benchmarks.",
    "title": "Meta Relational Learning for Few-Shot Link Prediction in Knowledge Graphs"
  },
  {
    "arxiv": "2001.00461",
    "counts": {
      "ComplEx": 1,
      "DistMult": 1,
      "RESCAL": 1,
      "SE": 1,
      "SimplE": 1,
      "TransE": 1,
      "TransR": 1
    },
    "published": "2020-01-02T14:44:23Z",
    "summary": "We propose a novel method for automatic reasoning on knowledge graphs based on debate dynamics. The main idea is to frame the task of triple classification as a debate game between two reinforcement learning agents which extract arguments -- paths in the knowledge graph -- with the goal to promote the fact being true (thesis) or the fact being false (antithesis), respectively. Based on these arguments, a binary classifier, called the judge, decides whether the fact is true or false. The two agents can be considered as sparse, adversarial feature generators that present interpretable evidence for either the thesis or the antithesis. In contrast to other black-box methods, the arguments allow users to get an understanding of the decision of the judge. Since the focus of this work is to create an explainable method that maintains a competitive predictive accuracy, we benchmark our method on the triple classification and link prediction task. Thereby, we find that our method outperforms several baselines on the benchmark datasets FB15k-237, WN18RR, and Hetionet. We also conduct a survey and find that the extracted arguments are informative for users.",
    "title": "Reasoning on Knowledge Graphs with Debate Dynamics"
  },
  {
    "arxiv": "2003.05809",
    "counts": {
      "DistMult": 1,
      "HolE": 1,
      "RESCAL": 1,
      "SE": 1,
      "TransA": 1,
      "TransE": 1,
      "TransH": 1
    },
    "published": "2020-03-09T12:57:10Z",
    "summary": "In this paper, we present KGvec2go, a Web API for accessing and consuming graph embeddings in a light-weight fashion in downstream applications. Currently, we serve pre-trained embeddings for four knowledge graphs. We introduce the service and its usage, and we show further that the trained models have semantic value by evaluating them on multiple semantic benchmarks. The evaluation also reveals that the combination of multiple models can lead to a better outcome than the best individual model.",
    "title": "KGvec2go -- Knowledge Graph Embeddings as a Service"
  },
  {
    "arxiv": "2004.04926",
    "counts": {
      "ComplEx": 3,
      "ConvE": 1,
      "DistMult": 1,
      "RESCAL": 2,
      "SE": 1,
      "SimplE": 2,
      "TransE": 2
    },
    "published": "2020-04-10T07:09:30Z",
    "summary": "Most algorithms for representation learning and link prediction in relational data have been designed for static data. However, the data they are applied to usually evolves with time, such as friend graphs in social networks or user interactions with items in recommender systems. This is also the case for knowledge bases, which contain facts such as (US, has president, B. Obama, [2009-2017]) that are valid only at certain points in time. For the problem of link prediction under temporal constraints, i.e., answering queries such as (US, has president, ?, 2012), we propose a solution inspired by the canonical decomposition of tensors of order 4. We introduce new regularization schemes and present an extension of ComplEx (Trouillon et al., 2016) that achieves state-of-the-art performance. Additionally, we propose a new dataset for knowledge base completion constructed from Wikidata, larger than previous benchmarks by an order of magnitude, as a new reference for evaluating temporal and non-temporal link prediction methods.",
    "title": "Tensor Decompositions for temporal knowledge base completion"
  },
  {
    "arxiv": "2009.07810",
    "counts": {
      "ComplEx": 4,
      "ConvE": 3,
      "DistMult": 1,
      "RESCAL": 4,
      "SE": 1,
      "TransE": 3,
      "TuckER": 3
    },
    "published": "2020-09-16T17:08:23Z",
    "summary": "We present CoDEx, a set of knowledge graph completion datasets extracted from Wikidata and Wikipedia that improve upon existing knowledge graph completion benchmarks in scope and level of difficulty. In terms of scope, CoDEx comprises three knowledge graphs varying in size and structure, multilingual descriptions of entities and relations, and tens of thousands of hard negative triples that are plausible but verified to be false. To characterize CoDEx, we contribute thorough empirical analyses and benchmarking experiments. First, we analyze each CoDEx dataset in terms of logical relation patterns. Next, we report baseline link prediction and triple classification results on CoDEx for five extensively tuned embedding models. Finally, we differentiate CoDEx from the popular FB15K-237 knowledge graph completion dataset by showing that CoDEx covers more diverse and interpretable content, and is a more difficult link prediction benchmark. Data, code, and pretrained models are available at https://bit.ly/2EPbrJs.",
    "title": "CoDEx: A Comprehensive Knowledge Graph Completion Benchmark"
  },
  {
    "arxiv": "2009.10800",
    "counts": {
      "ComplEx": 8,
      "ConvE": 3,
      "DistMult": 5,
      "RESCAL": 4,
      "RotatE": 9,
      "SimplE": 1,
      "TransE": 9
    },
    "published": "2020-09-22T20:29:27Z",
    "summary": "The problem of knowledge graph (KG) reasoning has been widely explored by traditional rule-based systems and more recently by knowledge graph embedding methods. While logical rules can capture deterministic behavior in a KG they are brittle and mining ones that infer facts beyond the known KG is challenging. Probabilistic embedding methods are effective in capturing global soft statistical tendencies and reasoning with them is computationally efficient. While embedding representations learned from rich training data are expressive, incompleteness and sparsity in real-world KGs can impact their effectiveness. We aim to leverage the complementary properties of both methods to develop a hybrid model that learns both high-quality rules and embeddings simultaneously. Our method uses a cross feedback paradigm wherein, an embedding model is used to guide the search of a rule mining system to mine rules and infer new facts. These new facts are sampled and further used to refine the embedding model. Experiments on multiple benchmark datasets show the effectiveness of our method over other competitive standalone and hybrid baselines. We also show its efficacy in a sparse KG setting and finally explore the connection with negative sampling.",
    "title": "A Hybrid Model for Learning Embeddings and Logical Rules Simultaneously from Knowledge Graphs"
  },
  {
    "arxiv": "2012.11147",
    "counts": {
      "DistMult": 2,
      "NTN": 2,
      "R-GCN": 2,
      "RESCAL": 2,
      "TransE": 2,
      "TransH": 2,
      "TransR": 2
    },
    "published": "2020-12-21T06:58:38Z",
    "summary": "Graph Neural Networks (GNNs) are widely used in graph representation learning. However, most GNN methods are designed for either homogeneous or heterogeneous graphs. In this paper, we propose a new model, Hop-Hop Relation-aware Graph Neural Network (HHR-GNN), to unify representation learning for these two types of graphs. HHR-GNN learns a personalized receptive field for each node by leveraging knowledge graph embedding to learn relation scores between the central node's representations at different hops. In neighborhood aggregation, our model simultaneously allows for hop-aware projection and aggregation. This mechanism enables the central node to learn a hop-wise neighborhood mixing that can be applied to both homogeneous and heterogeneous graphs. Experimental results on five benchmarks show the competitive performance of our model compared to state-of-the-art GNNs, e.g., up to 13K faster in terms of time cost per training epoch on large heterogeneous graphs.",
    "title": "Hop-Hop Relation-aware Graph Neural Networks"
  },
  {
    "arxiv": "1510.04935",
    "counts": {
      "ER-MLP": 1,
      "HolE": 1,
      "SE": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2015-10-16T16:29:07Z",
    "summary": "Learning embeddings of entities and relations is an efficient and versatile method to perform machine learning on relational data such as knowledge graphs. In this work, we propose holographic embeddings (HolE) to learn compositional vector space representations of entire knowledge graphs. The proposed method is related to holographic models of associative memory in that it employs circular correlation to create compositional representations. By using correlation as the compositional operator HolE can capture rich interactions but simultaneously remains efficient to compute, easy to train, and scalable to very large datasets. In extensive experiments we show that holographic embeddings are able to outperform state-of-the-art methods for link prediction in knowledge graphs and relational learning benchmark datasets.",
    "title": "Holographic Embeddings of Knowledge Graphs"
  },
  {
    "arxiv": "1707.07596",
    "counts": {
      "ComplEx": 3,
      "DistMult": 3,
      "SE": 1,
      "TransE": 2,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2017-07-24T15:00:55Z",
    "summary": "In adversarial training, a set of models learn together by pursuing competing goals, usually defined on single data instances. However, in relational learning and other non-i.i.d domains, goals can also be defined over sets of instances. For example, a link predictor for the is-a relation needs to be consistent with the transitivity property: if is-a(x_1, x_2) and is-a(x_2, x_3) hold, is-a(x_1, x_3) needs to hold as well. Here we use such assumptions for deriving an inconsistency loss, measuring the degree to which the model violates the assumptions on an adversarially-generated set of examples. The training objective is defined as a minimax problem, where an adversary finds the most offending adversarial examples by maximising the inconsistency loss, and the model is trained by jointly minimising a supervised loss and the inconsistency loss on the adversarial examples. This yields the first method that can use function-free Horn clauses (as in Datalog) to regularise any neural link predictor, with complexity independent of the domain size. We show that for several link prediction models, the optimisation problem faced by the adversary has efficient closed-form solutions. Experiments on link prediction benchmarks indicate that given suitable prior knowledge, our method can significantly improve neural link predictors on all relevant metrics.",
    "title": "Adversarial Sets for Regularising Neural Link Predictors"
  },
  {
    "arxiv": "1911.04053",
    "counts": {
      "ComplEx": 1,
      "ConvE": 1,
      "DistMult": 1,
      "RESCAL": 1,
      "RotatE": 1,
      "TransE": 1
    },
    "published": "2019-11-11T03:15:22Z",
    "summary": "This paper studies the problem of predicting missing relationships between entities in knowledge graphs through learning their representations. Currently, the majority of existing link prediction models employ simple but intuitive scoring functions and relatively small embedding size so that they could be applied to large-scale knowledge graphs. However, these properties also restrict the ability to learn more expressive and robust features. Therefore, diverging from most of the prior works which focus on designing new objective functions, we propose, DeCom, a simple but effective mechanism to boost the performance of existing link predictors such as DistMult, ComplEx, etc, through extracting more expressive features while preventing overfitting by adding just a few extra parameters. Specifically, embeddings of entities and relationships are first decompressed to a more expressive and robust space by decompressing functions, then knowledge graph embedding models are trained in this new feature space. Experimental results on several benchmark knowledge graphs and advanced link prediction systems demonstrate the generalization and effectiveness of our method. Especially, RESCAL + DeCom achieves state-of-the-art performance on the FB15k-237 benchmark across all evaluation metrics. In addition, we also show that compared with DeCom, explicitly increasing the embedding size significantly increase the number of parameters but could not achieve promising performance improvement.",
    "title": "Decompressing Knowledge Graph Representations for Link Prediction"
  },
  {
    "arxiv": "1802.03638",
    "counts": {
      "ComplEx": 1,
      "DistMult": 1,
      "HolE": 1,
      "SE": 1,
      "TransE": 1
    },
    "published": "2018-02-10T18:46:54Z",
    "summary": "Graph representations of large knowledge bases may comprise billions of edges. Usually built upon human-generated ontologies, several knowledge bases do not feature declared ontological rules and are far from being complete. Current rule mining approaches rely on schemata or store the graph in-memory, which can be unfeasible for large graphs. In this paper, we introduce HornConcerto, an algorithm to discover Horn clauses in large graphs without the need of a schema. Using a standard fact-based confidence score, we can mine close Horn rules having an arbitrary body size. We show that our method can outperform existing approaches in terms of runtime and memory consumption and mine high-quality rules for the link prediction task, achieving state-of-the-art results on a widely-used benchmark. Moreover, we find that rules alone can perform inference significantly faster than embedding-based methods and achieve accuracies on link prediction comparable to resource-demanding approaches such as Markov Logic Networks.",
    "title": "Beyond Markov Logic: Efficient Mining of Prediction Rules in Large Graphs"
  },
  {
    "arxiv": "1904.12211",
    "counts": {
      "ComplEx": 1,
      "DistMult": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2019-04-27T20:40:03Z",
    "summary": "Knowledge graphs (KGs), i.e. representation of information as a semantic graph, provide a significant test bed for many tasks including question answering, recommendation, and link prediction. Various amount of scholarly metadata have been made vailable as knowledge graphs from the diversity of data providers and agents. However, these high-quantities of data remain far from quality criteria in terms of completeness while growing at a rapid pace. Most of the attempts in completing such KGs are following traditional data digitization, harvesting and collaborative curation approaches. Whereas, advanced AI-related approaches such as embedding models - specifically designed for such tasks - are usually evaluated for standard benchmarks such as Freebase and Wordnet. The tailored nature of such datasets prevents those approaches to shed the lights on more accurate discoveries. Application of such models on domain-specific KGs takes advantage of enriched meta-data and provides accurate results where the underlying domain can enormously benefit. In this work, the TransE embedding model is reconciled for a specific link prediction task on scholarly metadata. The results show a significant shift in the accuracy and performance evaluation of the model on a dataset with scholarly metadata. The newly proposed version of TransE obtains 99.9% for link prediction task while original TransE gets 95%. In terms of accuracy and Hit@10, TransE outperforms other embedding models such as ComplEx, TransH and TransR experimented over scholarly knowledge graphs",
    "title": "Soft Marginal TransE for Scholarly Knowledge Graph Completion"
  },
  {
    "arxiv": "2012.15537",
    "counts": {
      "ComplEx": 1,
      "DistMult": 1,
      "SE": 2,
      "SimplE": 1,
      "TransE": 1
    },
    "published": "2020-12-31T10:41:01Z",
    "summary": "Modeling time-evolving knowledge graphs (KGs) has recently gained increasing interest. Here, graph representation learning has become the dominant paradigm for link prediction on temporal KGs. However, the embedding-based approaches largely operate in a black-box fashion, lacking the ability to interpret their predictions. This paper provides a link forecasting framework that reasons over query-relevant subgraphs of temporal KGs and jointly models the structural dependencies and the temporal dynamics. Especially, we propose a temporal relational attention mechanism and a novel reverse representation update scheme to guide the extraction of an enclosing subgraph around the query. The subgraph is expanded by an iterative sampling of temporal neighbors and by attention propagation. Our approach provides human-understandable evidence explaining the forecast. We evaluate our model on four benchmark temporal knowledge graphs for the link forecasting task. While being more explainable, our model obtains a relative improvement of up to 20% on Hits@1 compared to the previous best KG forecasting method. We also conduct a survey with 53 respondents, and the results show that the evidence extracted by the model for link forecasting is aligned with human understanding.",
    "title": "xERTE: Explainable Reasoning on Temporal Knowledge Graphs for Forecasting Future Links"
  },
  {
    "arxiv": "1905.10674",
    "counts": {
      "RESCAL": 1,
      "SE": 1,
      "TransD": 3,
      "TransE": 2
    },
    "published": "2019-05-25T21:13:27Z",
    "summary": "Learning high-quality node embeddings is a key building block for machine learning models that operate on graph data, such as social networks and recommender systems. However, existing graph embedding techniques are unable to cope with fairness constraints, e.g., ensuring that the learned representations do not correlate with certain attributes, such as age or gender. Here, we introduce an adversarial framework to enforce fairness constraints on graph embeddings. Our approach is compositional---meaning that it can flexibly accommodate different combinations of fairness constraints during inference. For instance, in the context of social recommendations, our framework would allow one user to request that their recommendations are invariant to both their age and gender, while also allowing another user to request invariance to just their age. Experiments on standard knowledge graph and recommender system benchmarks highlight the utility of our proposed framework.",
    "title": "Compositional Fairness Constraints for Graph Embeddings"
  },
  {
    "arxiv": "1907.01068",
    "counts": {
      "ComplEx": 6,
      "DistMult": 6,
      "SE": 1,
      "TransE": 1
    },
    "published": "2019-07-01T20:40:37Z",
    "summary": "Knowledge graph embeddings rank among the most successful methods for link prediction in knowledge graphs, i.e., the task of completing an incomplete collection of relational facts. A downside of these models is their strong sensitivity to model hyperparameters, in particular regularizers, which have to be extensively tuned to reach good performance [Kadlec et al., 2017]. We propose an efficient method for large scale hyperparameter tuning by interpreting these models in a probabilistic framework. After a model augmentation that introduces per-entity hyperparameters, we use a variational expectation-maximization approach to tune thousands of such hyperparameters with minimal additional cost. Our approach is agnostic to details of the model and results in a new state of the art in link prediction on standard benchmark data.",
    "title": "Augmenting and Tuning Knowledge Graph Embeddings"
  },
  {
    "arxiv": "1909.02930",
    "counts": {
      "SE": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2019-09-06T14:29:00Z",
    "summary": "In order to facilitate the accesses of general users to knowledge graphs, an increasing effort is being exerted to construct graph-structured queries of given natural language questions. At the core of the construction is to deduce the structure of the target query and determine the vertices/edges which constitute the query. Existing query construction methods rely on question understanding and conventional graph-based algorithms which lead to inefficient and degraded performances facing complex natural language questions over knowledge graphs with large scales. In this paper, we focus on this problem and propose a novel framework standing on recent knowledge graph embedding techniques. Our framework first encodes the underlying knowledge graph into a low-dimensional embedding space by leveraging generalized local knowledge graphs. Given a natural language question, the learned embedding representations of the knowledge graph are utilized to compute the query structure and assemble vertices/edges into the target query. Extensive experiments were conducted on the benchmark dataset, and the results demonstrate that our framework outperforms state-of-the-art baseline models regarding effectiveness and efficiency.",
    "title": "Structured Query Construction via Knowledge Graph Embedding"
  },
  {
    "arxiv": "2101.06126",
    "counts": {
      "TransD": 1,
      "TransE": 1,
      "TransH": 1,
      "TransR": 1
    },
    "published": "2021-01-15T14:12:10Z",
    "summary": "Entity Resolution (ER) is a constitutional part for integrating different knowledge graphs in order to identify entities referring to the same real-world object. A promising approach is the use of graph embeddings for ER in order to determine the similarity of entities based on the similarity of their graph neighborhood. The similarity computations for such embeddings translates to calculating the distance between them in the embedding space which is comparatively simple. However, previous work has shown that the use of graph embeddings alone is not sufficient to achieve high ER quality. We therefore propose a more comprehensive ER approach for knowledge graphs called EAGER (Embedding-Assisted Knowledge Graph Entity Resolution) to flexibly utilize both the similarity of graph embeddings and attribute values within a supervised machine learning approach. We evaluate our approach on 23 benchmark datasets with differently sized and structured knowledge graphs and use hypothesis tests to ensure statistical significance of our results. Furthermore we compare our approach with state-of-the-art ER solutions, where our approach yields competitive results for table-oriented ER problems and shallow knowledge graphs but much better results for deeper knowledge graphs.",
    "title": "EAGER: Embedding-Assisted Entity Resolution for Knowledge Graphs"
  },
  {
    "arxiv": "1609.03145",
    "counts": {
      "HolE": 1,
      "RESCAL": 1,
      "TransE": 1
    },
    "published": "2016-09-11T10:14:18Z",
    "summary": "We provide a survey on relational models. Relational models describe complete networked {domains by taking into account global dependencies in the data}. Relational models can lead to more accurate predictions if compared to non-relational machine learning approaches. Relational models typically are based on probabilistic graphical models, e.g., Bayesian networks, Markov networks, or latent variable models. Relational models have applications in social networks analysis, the modeling of knowledge graphs, bioinformatics, recommendation systems, natural language processing, medical decision support, and linked data.",
    "title": "Relational Models"
  },
  {
    "arxiv": "1807.05127",
    "counts": {
      "ComplEx": 2,
      "DistMult": 1,
      "RESCAL": 1
    },
    "published": "2018-07-13T15:15:41Z",
    "summary": "Extraction from raw text to a knowledge base of entities and fine-grained types is often cast as prediction into a flat set of entity and type labels, neglecting the rich hierarchies over types and entities contained in curated ontologies. Previous attempts to incorporate hierarchical structure have yielded little benefit and are restricted to shallow ontologies. This paper presents new methods using real and complex bilinear mappings for integrating hierarchical information, yielding substantial improvement over flat predictions in entity linking and fine-grained entity typing, and achieving new state-of-the-art results for end-to-end models on the benchmark FIGER dataset. We also present two new human-annotated datasets containing wide and deep hierarchies which we will release to the community to encourage further research in this direction: MedMentions, a collection of PubMed abstracts in which 246k mentions have been mapped to the massive UMLS ontology; and TypeNet, which aligns Freebase types with the WordNet hierarchy to obtain nearly 2k entity types. In experiments on all three datasets we show substantial gains from hierarchy-aware training.",
    "title": "Hierarchical Losses and New Resources for Fine-grained Entity Typing and Linking"
  },
  {
    "arxiv": "1909.11042",
    "counts": {
      "HolE": 1,
      "ProjE": 1,
      "TransE": 1
    },
    "published": "2019-09-24T16:52:18Z",
    "summary": "Deep learning currently dominates the benchmarks for various NLP tasks and, at the basis of such systems, words are frequently represented as embeddings --vectors in a low dimensional space-- learned from large text corpora and various algorithms have been proposed to learn both word and concept embeddings. One of the claimed benefits of such embeddings is that they capture knowledge about semantic relations. Such embeddings are most often evaluated through tasks such as predicting human-rated similarity and analogy which only test a few, often ill-defined, relations. In this paper, we propose a method for (i) reliably generating word and concept pair datasets for a wide number of relations by using a knowledge graph and (ii) evaluating to what extent pre-trained embeddings capture those relations. We evaluate the approach against a proprietary and a public knowledge graph and analyze the results, showing which lexico-semantic relational knowledge is captured by current embedding learning approaches.",
    "title": "Assessing the Lexico-Semantic Relational Knowledge Captured by Word and Concept Embeddings"
  },
  {
    "arxiv": "2003.05730",
    "counts": {
      "RESCAL": 1,
      "TransE": 1,
      "TransR": 1
    },
    "published": "2020-03-10T12:48:00Z",
    "summary": "Deep learning models on graphs have achieved remarkable performance in various graph analysis tasks, e.g., node classification, link prediction and graph clustering. However, they expose uncertainty and unreliability against the well-designed inputs, i.e., adversarial examples. Accordingly, a line of studies have emerged for both attack and defense addressed in different graph analysis tasks, leading to the arms race in graph adversarial learning. Despite the booming works, there still lacks a unified problem definition and a comprehensive review. To bridge this gap, we investigate and summarize the existing works on graph adversarial learning tasks systemically. Specifically, we survey and unify the existing works w.r.t. attack and defense in graph analysis tasks, and give appropriate definitions and taxonomies at the same time. Besides, we emphasize the importance of related evaluation metrics, investigate and summarize them comprehensively. Hopefully, our works can provide a comprehensive overview and offer insights for the relevant researchers. More details of our works are available at https://github.com/gitgiter/Graph-Adversarial-Learning.",
    "title": "A Survey of Adversarial Learning on Graphs"
  },
  {
    "arxiv": "2005.07654",
    "counts": {
      "ComplEx": 3,
      "ConvE": 1,
      "DistMult": 3
    },
    "published": "2020-05-15T17:15:45Z",
    "summary": "Recently, link prediction algorithms based on neural embeddings have gained tremendous popularity in the Semantic Web community, and are extensively used for knowledge graph completion. While algorithmic advances have strongly focused on efficient ways of learning embeddings, fewer attention has been drawn to the different ways their performance and robustness can be evaluated. In this work we propose an open-source evaluation pipeline, which benchmarks the accuracy of neural embeddings in situations where knowledge graphs may experience semantic and structural changes. We define relation-centric connectivity measures that allow us to connect the link prediction capacity to the structure of the knowledge graph. Such an evaluation pipeline is especially important to simulate the accuracy of embeddings for knowledge graphs that are expected to be frequently updated.",
    "title": "Benchmarking neural embeddings for link prediction in knowledge graphs under semantic and structural changes"
  },
  {
    "arxiv": "2011.02260",
    "counts": {
      "R-GCN": 1,
      "SE": 1,
      "TransR": 1
    },
    "published": "2020-11-04T12:57:47Z",
    "summary": "With the explosive growth of online information, recommender systems play a key role to alleviate such information overload. Due to the important application value of recommender system, there have always been emerging works in this field. In recent years, graph neural network (GNN) techniques have gained considerable interests which can naturally integrate node information and topological structure. Owing to the outperformance of GNN in learning on graph data, GNN methods have been widely applied in many fields. In recommender systems, the main challenge is to learn the efficient user/item embeddings from their interactions and side information if available. Since most of the information essentially has graph structure and GNNs have superiority in representation learning, the field of utilizing graph neural network in recommender systems is flourishing. This article aims to provide a comprehensive review of recent research efforts on graph neural network based recommender systems. Specifically, we provide a taxonomy of graph neural network based recommendation models and state new perspectives pertaining to the development of this field.",
    "title": "Graph Neural Networks in Recommender Systems: A Survey"
  },
  {
    "arxiv": "2012.06236",
    "counts": {
      "DistMult": 1,
      "R-GCN": 1,
      "SE": 1
    },
    "published": "2020-12-11T10:52:04Z",
    "summary": "Zero shot learning -- the problem of training and testing on a completely disjoint set of classes -- relies greatly on its ability to transfer knowledge from train classes to test classes. Traditionally semantic embeddings consisting of human defined attributes (HA) or distributed word embeddings (DWE) are used to facilitate this transfer by improving the association between visual and semantic embeddings. In this paper, we take advantage of explicit relations between nodes defined in ConceptNet, a commonsense knowledge graph, to generate commonsense embeddings of the class labels by using a graph convolution network-based autoencoder. Our experiments performed on three standard benchmark datasets surpass the strong baselines when we fuse our commonsense embeddings with existing semantic embeddings i.e. HA and DWE.",
    "title": "Improving Zero Shot Learning Baselines with Commonsense Knowledge"
  }
]